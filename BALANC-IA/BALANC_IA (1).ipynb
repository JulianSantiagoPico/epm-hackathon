{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README del Notebook: Balance Virtual y Pron√≥stico de Entrada por V√°lvula\n",
    "Este notebook construye un Balance Virtual de Gas en la red secundaria (v√°lvulas de anillo), pronosticando el Volumen Corregido de Entrada en los periodos sin macromedici√≥n y recalculando p√©rdidas e √≠ndices asociados. Adem√°s, genera res√∫menes comparativos y visualizaciones por v√°lvula.\n",
    "\n",
    "## Objetivos\n",
    "- Integrar fuentes de datos hist√≥ricas (balances, macromedici√≥n, usuarios).\n",
    "- Construir un dataset maestro con variables de entrada/salida y contexto.\n",
    "- Entrenar modelos por v√°lvula y pronosticar `VOLUMEN_ENTRADA_FINAL` tras la fecha de retiro del macromedidor.\n",
    "- Recalcular `PERDIDAS_FINAL` e `INDICE_PERDIDAS_FINAL` en el horizonte de pron√≥stico.\n",
    "- Generar res√∫menes y comparativos por v√°lvula; crear gr√°ficas de seguimiento.\n",
    "\n",
    "## Datos de entrada requeridos (csv en la carpeta del notebook)\n",
    "- `Balances.csv`: hist√≥rico de balance por v√°lvula (columnas esperadas incluyen A√ëO, MES o nombre de mes, ENTRADA_VOLUMEN_MEDIDO_MES, SALIDA_CONSUMO_FACTURADO_MES, DIFERENCIA_PERDIDAS, INDICE_PERDIDAS, PRESION_PROMEDIO_MES, TEMPERATURA_PROMEDIO_MES, FACTOR_CORRECCION_PROMEDIO_MES, CODIGO VALVULA REFERENCIA).\n",
    "- `Variables_Macromedici√≥n_Teleges.csv`: macromedici√≥n minuto a minuto (campos `ESTAMPA_TIEMPO`, `CODIGO VALVULA REFERENCIA`, `PRESION`, `TEMPERATURA`, `KPT`, `VOLUMEN_CORREGIDO`).\n",
    "- `Variables_Usuarios.csv`: consumos por usuario y periodo (campos `ID_USUARIO`, `PERIODO`, `CONSUMO`, `PRESION_SISTEMA`, `KPT_SISTEMA`, `GRUPO_USUARIO`, `ESTRATO`, `CLASE_SERVICIO`, `CODIGO VALVULA REFERENCIA`).\n",
    "- `Datos_Entrada.csv`: fechas de retiro por v√°lvula y cantidad de periodos a pronosticar (campos `CODIGO VALVULA REFERENCIA`, `FECHA RETIRO/TRASLADO`, `CANTIDAD_PERIODOS_PRONOSTICO`).\n",
    "\n",
    "## Flujo del notebook (celdas principales)\n",
    "1) Carga e instalaci√≥n de librer√≠as (Celdas 4‚Äì6).\n",
    "2) Carga de datasets iniciales (Celda 8).\n",
    "3) Agregaci√≥n de macromedici√≥n a mensual (Celda 10):\n",
    "   - Genera `Macromedicion_Mensual.csv` y `Macromedicion_Mensual_Simple.csv`.\n",
    "   - Estad√≠sticas por v√°lvula y periodo.\n",
    "4) Agregaci√≥n de usuarios por v√°lvula/mes (Celda 11):\n",
    "   - Genera `Usuarios_Por_Valvula.csv` y `Usuarios_Por_Valvula_Simple.csv`.\n",
    "   - Resumen estad√≠stico por v√°lvula.\n",
    "5) Construcci√≥n del Dataset Maestro (Celda 12):\n",
    "   - Unifica macromedici√≥n mensual y usuarios; integra balance hist√≥rico.\n",
    "   - Crea variables consolidadas: `VOLUMEN_ENTRADA_FINAL`, `VOLUMEN_SALIDA_FINAL`, `PERDIDAS_FINAL`, `INDICE_PERDIDAS_FINAL`, `PRESION_FINAL`, `TEMPERATURA_FINAL`, `KPT_FINAL`.\n",
    "   - Marca `TIENE_MACROMEDIDOR`, `PERIODO_A_PREDECIR`, `MESES_DESDE_RETIRO`.\n",
    "   - Genera: `Dataset_Maestro_Balances.csv`, `Dataset_Train.csv` (periodos con macromedidor), `Dataset_Prediccion.csv` (periodos a predecir), `Resumen_Valvulas.csv`.\n",
    "6) Verificaci√≥n del dataset de entrenamiento (Celda 13).\n",
    "7) Entrenamiento y Pron√≥stico (Celda 15):\n",
    "   - Modelos por v√°lvula: `Prophet` (serie de tiempo) y `LightGBM` (features).\n",
    "   - Umbrales flexibles: se entrena Prophet si hay ‚â•6 puntos; LightGBM si hay ‚â•6 puntos y features suficientes.\n",
    "   - Fallback ingenuo (media de √∫ltimos 3 valores) cuando la historia es corta o hay fallos.\n",
    "   - Guardados: `Pronosticos.csv` con `PRED_ENTRADA`, `PRED_SALIDA`, `PRED_PERDIDAS`, `PRED_INDICE_PERDIDAS`; `Metrics.csv` con m√©tricas de LightGBM por v√°lvula si hubo test temporal.\n",
    "8) Fusi√≥n de pron√≥sticos con el dataset maestro (Celda 16):\n",
    "   - Reemplaza `VOLUMEN_ENTRADA_FINAL` y `VOLUMEN_SALIDA_FINAL` en periodos a predecir.\n",
    "   - Recalcula `PERDIDAS_FINAL` e `INDICE_PERDIDAS_FINAL`.\n",
    "   - Guarda `Predicciones_Con_Balance.csv`.\n",
    "9) Verificaci√≥n integral de datos (Celda 18): historia, periodos a predecir, retiro vs √∫ltimo periodo, v√°lvulas con poca historia.\n",
    "10) Resumen por v√°lvula y gr√°ficas (Celdas 19‚Äì21):\n",
    "    - `Resumen_Pronostico_Valvulas.csv` con totales y promedios del horizonte de pron√≥stico.\n",
    "    - Gr√°ficas por v√°lvula (HTML y PNG) en `graficas_valvulas/`: Entrada vs Salida; √çndice de P√©rdidas.\n",
    "11) Tabla comparativa (Celda 22):\n",
    "    - `Comparativo_Valvulas.csv` con KPIs, rankings y m√©tricas (si disponibles).\n",
    "    - Genera `Resumen_Pronostico_Valvulas.csv` autom√°ticamente si falta (a partir de `Predicciones_Con_Balance.csv`).\n",
    "12) Dashboard consolidado (Celdas 23‚Äì24):\n",
    "    - `graficas_valvulas/dashboard.html` con tabla comparativa y iframes de gr√°ficas.\n",
    "13) Limpieza opcional (Celdas 25‚Äì26):\n",
    "    - Bandera `MODO_LIMPIEZA = True` para borrar derivados y gr√°ficas tras la validaci√≥n.\n",
    "\n",
    "## Archivos generados (salidas)\n",
    "- `Macromedicion_Mensual.csv`, `Macromedicion_Mensual_Simple.csv`: agregaciones de macromedici√≥n.\n",
    "- `Usuarios_Por_Valvula.csv`, `Usuarios_Por_Valvula_Simple.csv`: consumos y promedios por v√°lvula.\n",
    "- `Dataset_Maestro_Balances.csv`: dataset final consolidado.\n",
    "- `Dataset_Train.csv`: periodos con macromedidor (para entrenamiento).\n",
    "- `Dataset_Prediccion.csv`: periodos a predecir (tras retiro).\n",
    "- `Pronosticos.csv`: pron√≥sticos por v√°lvula y periodo (entrada/salida/p√©rdidas/√≠ndice).\n",
    "- `Metrics.csv`: m√©tricas LightGBM por v√°lvula (si hubo test).\n",
    "- `Predicciones_Con_Balance.csv`: dataset maestro con valores pronosticados.\n",
    "- `Resumen_Pronostico_Valvulas.csv`: resumen KPIs del horizonte de pron√≥stico por v√°lvula.\n",
    "- `Comparativo_Valvulas.csv`: tabla comparativa con rankings e indicadores.\n",
    "- `graficas_valvulas/*`: HTML y PNG de gr√°ficas por v√°lvula, y `dashboard.html`.\n",
    "\n",
    "## Par√°metros y banderas\n",
    "- `MODO_LIMPIEZA` (Celda 26): True para eliminar derivados y gr√°ficas; False para conservar salidas.\n",
    "- Umbrales de entrenamiento: Prophet y LightGBM requieren ‚â•6 puntos; fallback si no se cumplen.\n",
    "\n",
    "## C√≥mo ejecutar end-to-end\n",
    "1) Asegura que los cuatro datasets de entrada est√©n presentes (`Balances.csv`, `Variables_Macromedici√≥n_Teleges.csv`, `Variables_Usuarios.csv`, `Datos_Entrada.csv`).\n",
    "2) Ejecuta secuencialmente todas las celdas (de 4 a 24) para crear agregados, maestro, entrenar y fusionar.\n",
    "3) Revisa las salidas clave: `Predicciones_Con_Balance.csv`, `Pronosticos.csv`, `Comparativo_Valvulas.csv`, `graficas_valvulas/dashboard.html`.\n",
    "4) Opcional: ejecuta la Celda 26 con `MODO_LIMPIEZA = True` para limpiar derivados tras validar.\n",
    "\n",
    "## Soluci√≥n de problemas (FAQ)\n",
    "- FileNotFoundError de `Resumen_Pronostico_Valvulas.csv`: la Celda 22 lo genera autom√°ticamente a partir de `Predicciones_Con_Balance.csv`. Asegura haber ejecutado la Celda 16 primero.\n",
    "- Errores de resta con strings al fusionar: la Celda 16 normaliza tipos num√©ricos (`decimal=','` y `to_numeric`).\n",
    "- Series con muy pocos puntos: se usa fallback ingenuo; `VALVULA_5` es un ejemplo con historia <6.\n",
    "- Prophet con pocas observaciones: se reduce `n_changepoints` autom√°ticamente; si falla, se usa fallback.\n",
    "- Diferencias de formato decimal: todas las lecturas usan `sep=';'` y `decimal=','` para consistencia.\n",
    "\n",
    "## Notas y criterios\n",
    "- No se modifican los archivos iniciales; los derivados se regeneran en cada corrida.\n",
    "- Las m√©tricas de LightGBM s√≥lo se calculan si existe test temporal (‚â•2 puntos).\n",
    "- Los gr√°ficos y dashboard son opcionales; se pueden limpiar con `MODO_LIMPIEZA`.\n",
    "- El comparativo ordena por menor `% de p√©rdidas sobre entrada` y `INDICE_PERDIDAS_MEAN`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qayc66C12jqK"
   },
   "source": [
    "# Karly Velasquez Acosta - 3023368928 - velasquezacostakarly@gmail.com\n",
    "# Julian Santiago Pico Pinzon - 3043089479 - julpic08@gmail.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f60Rnj4L25Y5"
   },
   "source": [
    "\n",
    "## Descripci√≥n de los datos\n",
    "\n",
    "El objetivo principal de este proyecto es desarrollar un Modelo Predictivo de Series de Tiempo que pueda estimar el Volumen Corregido (Entrada) de gas en puntos de la red secundaria (v√°lvulas de anillo) donde la medici√≥n f√≠sica en tiempo real ha cesado.\n",
    "\n",
    "Este pron√≥stico de volumen de entrada permitir√° calcular un Balance Virtual de Gas al compararlo con el consumo facturado de los usuarios (Volumen Salida), identificando y cuantificando las p√©rdidas o desbalances en el sistema\n",
    "\n",
    "## proposito\n",
    "\n",
    "- Pronosticar el Volumen Corregido para cada v√°lvula de anillo en el horizonte de pron√≥stico (a partir de la fecha de retiro del macromedidor).\n",
    "\n",
    "- Comparar y Evaluar el desempe√±o de tres niveles de modelos: SARIMA (Cl√°sico), LightGBM (ML Potente), y TFT (Deep Learning Avanzado).\n",
    "\n",
    "- Realizar el Balance Virtual y determinar el √çndice de P√©rdidas (%) proyectado para el periodo sin medici√≥n."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "792CWisy4ICc"
   },
   "source": [
    "#Cargar librerias e instalar librerias\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wnM7rGId4XiX",
    "outputId": "d0f1a2dd-2edb-4837-d154-ec91db84ce4f"
   },
   "outputs": [],
   "source": [
    "#!pip install lightgbm\n",
    "#!pip install prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kwR7_B3eyFdX"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karly\\AppData\\Roaming\\Python\\Python313\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from xgboost import XGBRegressor\n",
    "from prophet import Prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "jHxhVXRk4gxe"
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sXQMLCEh4m_I"
   },
   "source": [
    "#Cargar conjunto de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zQy5CR044jcq",
    "outputId": "ab0d0a0c-8396-4c92-f79d-672257874fd1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carga de datos exitosa\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    df_balances = pd.read_csv('Balances.csv', sep=';', encoding='latin-1')\n",
    "    df_datos_entrada = pd.read_csv('Datos_Entrada.csv', sep=';', encoding='latin-1')\n",
    "    df_macromedicion = pd.read_csv('Variables_Macromedici√≥n_Teleges.csv', sep=';', encoding='latin-1')\n",
    "    df_usuarios = pd.read_csv('Variables_Usuarios.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "    print(\"Carga de datos exitosa\")\n",
    "except Exception as e:\n",
    "    print(f\"Error al cargar los archivos: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0QqKkTF6AxT"
   },
   "source": [
    "#Analizar y visualizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1JG_DM1-2j-B",
    "outputId": "54a4017b-4845-4e34-d24f-eddc8898c865"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGREGACI√ìN MACROMEDICI√ìN: MINUTO A MINUTO ‚Üí MENSUAL\n",
      "================================================================================\n",
      "\n",
      "1. Cargando datos...\n",
      "   ‚úì Datos cargados: (565502, 6)\n",
      "   ‚úì Columnas: ['CODIGO VALVULA REFERENCIA', 'ESTAMPA_TIEMPO', 'PRESION', 'TEMPERATURA', 'KPT', 'VOLUMEN_CORREGIDO']\n",
      "\n",
      "2. Convirtiendo tipos de datos...\n",
      "   ‚úì PRESION convertido a num√©rico\n",
      "   ‚úì TEMPERATURA convertido a num√©rico\n",
      "   ‚úì KPT convertido a num√©rico\n",
      "   ‚úì VOLUMEN_CORREGIDO convertido a num√©rico\n",
      "\n",
      "   Rango de fechas: 2024-05-18 00:00:00 ‚Üí 2025-07-16 00:00:00\n",
      "   V√°lvulas √∫nicas: 5\n",
      "\n",
      "3. Agregando datos por mes...\n",
      "   ‚úì Agregaci√≥n completada: (32, 22)\n",
      "\n",
      "4. Resumen de datos agregados:\n",
      "\n",
      "   Registros por v√°lvula:\n",
      "VALVULA\n",
      "VALVULA_1    7\n",
      "VALVULA_2    8\n",
      "VALVULA_3    7\n",
      "VALVULA_4    6\n",
      "VALVULA_5    4\n",
      "dtype: int64\n",
      "\n",
      "   Rango temporal por v√°lvula:\n",
      "          Primer_Mes √öltimo_Mes  Total_Meses\n",
      "VALVULA                                     \n",
      "VALVULA_1    2024-07    2025-01            7\n",
      "VALVULA_2    2024-05    2024-12            8\n",
      "VALVULA_3    2025-01    2025-07            7\n",
      "VALVULA_4    2024-06    2024-11            6\n",
      "VALVULA_5    2024-07    2024-10            4\n",
      "\n",
      "   Estad√≠sticas de volumen total por mes:\n",
      "count       32.000000\n",
      "mean     10938.508387\n",
      "std      12554.850458\n",
      "min         66.500000\n",
      "25%        855.227500\n",
      "50%       3184.475000\n",
      "75%      23744.737500\n",
      "max      34337.060000\n",
      "Name: VOLUMEN_TOTAL_MES, dtype: float64\n",
      "\n",
      "   Muestra de datos (primeros 10 registros):\n",
      "     VALVULA  PERIODO  PRESION_PROMEDIO  TEMPERATURA_PROMEDIO  KPT_PROMEDIO  \\\n",
      "0  VALVULA_1  2024-07          3.944109             27.059417      4.609774   \n",
      "1  VALVULA_1  2024-08          3.937439             26.362392      4.614912   \n",
      "2  VALVULA_1  2024-09          3.940262             26.677404      4.611172   \n",
      "3  VALVULA_1  2024-10          4.002022             23.850760      4.718949   \n",
      "4  VALVULA_1  2024-11          4.011459             22.335760      4.753011   \n",
      "5  VALVULA_1  2024-12          4.018756             22.696449      4.753749   \n",
      "6  VALVULA_1  2025-01          4.020314             22.699529      4.755932   \n",
      "7  VALVULA_2  2024-05          4.569781             26.426148      5.217764   \n",
      "8  VALVULA_2  2024-06          4.558949             25.925556      5.216329   \n",
      "9  VALVULA_2  2024-07          4.561469             28.122179      5.178793   \n",
      "\n",
      "   VOLUMEN_TOTAL_MES  NUM_REGISTROS  \n",
      "0              66.50          14397  \n",
      "1             405.53          43278  \n",
      "2             292.32          43069  \n",
      "3             584.93          43853  \n",
      "4             373.87          43163  \n",
      "5             337.83          43637  \n",
      "6             233.63          28346  \n",
      "7            1346.87          20158  \n",
      "8            2246.85          24471  \n",
      "9            2130.26          20117  \n",
      "\n",
      "5. Guardando resultados...\n",
      "   ‚úì Archivo guardado: Macromedicion_Mensual.csv\n",
      "   ‚úì Archivo simplificado: Macromedicion_Mensual_Simple.csv\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO ‚úì\n",
      "================================================================================\n",
      "\n",
      "Dimensiones finales: (32, 22)\n",
      "Columnas creadas: ['VALVULA', 'PERIODO', 'A√ëO', 'MES', 'PRESION_PROMEDIO', 'PRESION_DESVIACION', 'PRESION_MIN', 'PRESION_MAX', 'TEMPERATURA_PROMEDIO', 'TEMPERATURA_DESVIACION', 'TEMPERATURA_MIN', 'TEMPERATURA_MAX', 'KPT_PROMEDIO', 'KPT_DESVIACION', 'KPT_MIN', 'KPT_MAX', 'VOLUMEN_TOTAL_MES', 'VOLUMEN_PROMEDIO', 'VOLUMEN_DESVIACION', 'VOLUMEN_MIN', 'VOLUMEN_MAX', 'NUM_REGISTROS']\n",
      "\n",
      "Archivos generados:\n",
      "  ‚Ä¢ Macromedicion_Mensual.csv (completo con estad√≠sticas)\n",
      "  ‚Ä¢ Macromedicion_Mensual_Simple.csv (solo promedios)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGREGACI√ìN MACROMEDICI√ìN: MINUTO A MINUTO ‚Üí MENSUAL\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CARGAR Y PREPARAR DATOS\n",
    "# ============================================================================\n",
    "print(\"\\n1. Cargando datos...\")\n",
    "df = pd.read_csv('Variables_Macromedici√≥n_Teleges.csv', sep=';', encoding='latin-1')\n",
    "print(f\"   ‚úì Datos cargados: {df.shape}\")\n",
    "print(f\"   ‚úì Columnas: {list(df.columns)}\")\n",
    "\n",
    "# Limpiar nombres de columnas\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# ============================================================================\n",
    "# CONVERTIR FECHA Y COLUMNAS NUM√âRICAS\n",
    "# ============================================================================\n",
    "print(\"\\n2. Convirtiendo tipos de datos...\")\n",
    "\n",
    "# Convertir fecha\n",
    "df['ESTAMPA_TIEMPO'] = pd.to_datetime(df['ESTAMPA_TIEMPO'],\n",
    "                                      format='%d/%m/%Y %H:%M',\n",
    "                                      errors='coerce')\n",
    "\n",
    "# Funci√≥n para convertir coma decimal a punto\n",
    "def to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    try:\n",
    "        return float(str(value).replace(',', '.'))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir columnas num√©ricas\n",
    "numeric_cols = ['PRESION', 'TEMPERATURA', 'KPT', 'VOLUMEN_CORREGIDO']\n",
    "for col in numeric_cols:\n",
    "    df[col] = df[col].apply(to_numeric)\n",
    "    print(f\"   ‚úì {col} convertido a num√©rico\")\n",
    "\n",
    "# Crear columnas de periodo\n",
    "df['A√ëO_MES'] = df['ESTAMPA_TIEMPO'].dt.to_period('M')\n",
    "df['A√ëO'] = df['ESTAMPA_TIEMPO'].dt.year\n",
    "df['MES'] = df['ESTAMPA_TIEMPO'].dt.month\n",
    "\n",
    "print(f\"\\n   Rango de fechas: {df['ESTAMPA_TIEMPO'].min()} ‚Üí {df['ESTAMPA_TIEMPO'].max()}\")\n",
    "print(f\"   V√°lvulas √∫nicas: {df['CODIGO VALVULA REFERENCIA'].nunique()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# AGREGACI√ìN MENSUAL\n",
    "# ============================================================================\n",
    "print(\"\\n3. Agregando datos por mes...\")\n",
    "\n",
    "# Definir agregaciones\n",
    "agregaciones = {\n",
    "    'PRESION': ['mean', 'std', 'min', 'max'],\n",
    "    'TEMPERATURA': ['mean', 'std', 'min', 'max'],\n",
    "    'KPT': ['mean', 'std', 'min', 'max'],\n",
    "    'VOLUMEN_CORREGIDO': ['sum', 'mean', 'std', 'min', 'max'],  # SUMA es el total del mes\n",
    "    'ESTAMPA_TIEMPO': 'count'  # Cantidad de registros\n",
    "}\n",
    "\n",
    "# Agrupar por v√°lvula y mes\n",
    "df_mensual = df.groupby(['CODIGO VALVULA REFERENCIA', 'A√ëO_MES']).agg(agregaciones).reset_index()\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_mensual.columns = ['_'.join(col).strip('_') if col[1] else col[0]\n",
    "                      for col in df_mensual.columns.values]\n",
    "\n",
    "# Renombrar columnas para mayor claridad\n",
    "df_mensual.rename(columns={\n",
    "    'CODIGO VALVULA REFERENCIA': 'VALVULA',\n",
    "    'ESTAMPA_TIEMPO_count': 'NUM_REGISTROS',\n",
    "    'PRESION_mean': 'PRESION_PROMEDIO',\n",
    "    'PRESION_std': 'PRESION_DESVIACION',\n",
    "    'PRESION_min': 'PRESION_MIN',\n",
    "    'PRESION_max': 'PRESION_MAX',\n",
    "    'TEMPERATURA_mean': 'TEMPERATURA_PROMEDIO',\n",
    "    'TEMPERATURA_std': 'TEMPERATURA_DESVIACION',\n",
    "    'TEMPERATURA_min': 'TEMPERATURA_MIN',\n",
    "    'TEMPERATURA_max': 'TEMPERATURA_MAX',\n",
    "    'KPT_mean': 'KPT_PROMEDIO',\n",
    "    'KPT_std': 'KPT_DESVIACION',\n",
    "    'KPT_min': 'KPT_MIN',\n",
    "    'KPT_max': 'KPT_MAX',\n",
    "    'VOLUMEN_CORREGIDO_sum': 'VOLUMEN_TOTAL_MES',\n",
    "    'VOLUMEN_CORREGIDO_mean': 'VOLUMEN_PROMEDIO',\n",
    "    'VOLUMEN_CORREGIDO_std': 'VOLUMEN_DESVIACION',\n",
    "    'VOLUMEN_CORREGIDO_min': 'VOLUMEN_MIN',\n",
    "    'VOLUMEN_CORREGIDO_max': 'VOLUMEN_MAX'\n",
    "}, inplace=True)\n",
    "\n",
    "# Convertir periodo a formato legible\n",
    "df_mensual['PERIODO'] = df_mensual['A√ëO_MES'].astype(str)\n",
    "df_mensual['A√ëO'] = df_mensual['A√ëO_MES'].dt.year\n",
    "df_mensual['MES'] = df_mensual['A√ëO_MES'].dt.month\n",
    "\n",
    "# Reordenar columnas\n",
    "columnas_orden = ['VALVULA', 'PERIODO', 'A√ëO', 'MES'] + \\\n",
    "                 [col for col in df_mensual.columns if col not in ['VALVULA', 'PERIODO', 'A√ëO', 'MES', 'A√ëO_MES']]\n",
    "df_mensual = df_mensual[columnas_orden]\n",
    "\n",
    "print(f\"   ‚úì Agregaci√≥n completada: {df_mensual.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ESTAD√çSTICAS Y VALIDACI√ìN\n",
    "# ============================================================================\n",
    "print(\"\\n4. Resumen de datos agregados:\")\n",
    "print(\"\\n   Registros por v√°lvula:\")\n",
    "print(df_mensual.groupby('VALVULA').size())\n",
    "\n",
    "print(\"\\n   Rango temporal por v√°lvula:\")\n",
    "rango = df_mensual.groupby('VALVULA')['PERIODO'].agg(['min', 'max', 'count'])\n",
    "rango.columns = ['Primer_Mes', '√öltimo_Mes', 'Total_Meses']\n",
    "print(rango)\n",
    "\n",
    "print(\"\\n   Estad√≠sticas de volumen total por mes:\")\n",
    "print(df_mensual['VOLUMEN_TOTAL_MES'].describe())\n",
    "\n",
    "print(\"\\n   Muestra de datos (primeros 10 registros):\")\n",
    "print(df_mensual[['VALVULA', 'PERIODO', 'PRESION_PROMEDIO', 'TEMPERATURA_PROMEDIO',\n",
    "                  'KPT_PROMEDIO', 'VOLUMEN_TOTAL_MES', 'NUM_REGISTROS']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# GUARDAR RESULTADOS\n",
    "# ============================================================================\n",
    "print(\"\\n5. Guardando resultados...\")\n",
    "\n",
    "# Guardar archivo principal\n",
    "df_mensual.to_csv('Macromedicion_Mensual.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Archivo guardado: Macromedicion_Mensual.csv\")\n",
    "\n",
    "# Guardar versi√≥n simplificada (solo promedios)\n",
    "df_simple = df_mensual[['VALVULA', 'PERIODO', 'A√ëO', 'MES',\n",
    "                        'PRESION_PROMEDIO', 'TEMPERATURA_PROMEDIO',\n",
    "                        'KPT_PROMEDIO', 'VOLUMEN_TOTAL_MES', 'NUM_REGISTROS']]\n",
    "df_simple.to_csv('Macromedicion_Mensual_Simple.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Archivo simplificado: Macromedicion_Mensual_Simple.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESO COMPLETADO ‚úì\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDimensiones finales: {df_mensual.shape}\")\n",
    "print(f\"Columnas creadas: {list(df_mensual.columns)}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(\"  ‚Ä¢ Macromedicion_Mensual.csv (completo con estad√≠sticas)\")\n",
    "print(\"  ‚Ä¢ Macromedicion_Mensual_Simple.csv (solo promedios)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "88VnZPqV2rWZ",
    "outputId": "ef01c109-eaf0-4b63-83e6-07c4923ade0d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AGREGACI√ìN USUARIOS: POR USUARIO ‚Üí POR V√ÅLVULA Y MES\n",
      "================================================================================\n",
      "\n",
      "1. Cargando datos...\n",
      "   ‚úì Datos cargados: (6768, 10)\n",
      "   ‚úì Columnas: ['CODIGO VALVULA REFERENCIA', 'ID_USUARIO', 'GRUPO_USUARIO', 'ESTRATO', 'CLASE_SERVICIO', 'PRESION_SISTEMA', 'KPT_SISTEMA', 'TIPO_MEDIDOR', 'PERIODO', 'CONSUMO']\n",
      "\n",
      "   Total registros: 6,768\n",
      "   V√°lvulas √∫nicas: 5\n",
      "   Usuarios √∫nicos: 443\n",
      "   Periodos: 202407 ‚Üí 202511\n",
      "\n",
      "2. Convirtiendo columnas num√©ricas...\n",
      "   ‚úì PRESION_SISTEMA convertido a num√©rico\n",
      "   ‚úì KPT_SISTEMA convertido a num√©rico\n",
      "   ‚úì CONSUMO convertido a num√©rico\n",
      "\n",
      "3. Agregando por v√°lvula y mes...\n",
      "   ‚úì Agregaci√≥n completada: (72, 21)\n",
      "\n",
      "4. Resumen de datos agregados:\n",
      "\n",
      "   Registros por v√°lvula:\n",
      "VALVULA\n",
      "VALVULA_1    15\n",
      "VALVULA_2    17\n",
      "VALVULA_3     9\n",
      "VALVULA_4    16\n",
      "VALVULA_5    15\n",
      "dtype: int64\n",
      "\n",
      "   Rango temporal por v√°lvula:\n",
      "          Primer_Periodo √öltimo_Periodo  Total_Meses\n",
      "VALVULA                                             \n",
      "VALVULA_1         202409         202511           15\n",
      "VALVULA_2         202407         202511           17\n",
      "VALVULA_3         202503         202511            9\n",
      "VALVULA_4         202408         202511           16\n",
      "VALVULA_5         202409         202511           15\n",
      "\n",
      "   Estad√≠sticas de consumo total por v√°lvula:\n",
      "           count          mean          std        min          25%  \\\n",
      "VALVULA                                                               \n",
      "VALVULA_1   15.0    465.193733    82.982616    272.899    419.06050   \n",
      "VALVULA_2   17.0   2380.169059   692.281659   1494.091   1735.91600   \n",
      "VALVULA_3    9.0  30542.143211  3396.812048  24800.214  28208.26100   \n",
      "VALVULA_4   16.0  31832.259500  3883.601751  22252.931  29229.71025   \n",
      "VALVULA_5   15.0   4906.777600   238.405287   4491.895   4760.62400   \n",
      "\n",
      "                   50%         75%        max  \n",
      "VALVULA                                        \n",
      "VALVULA_1    483.64300    505.6000    596.549  \n",
      "VALVULA_2   2230.31900   2709.1370   3630.169  \n",
      "VALVULA_3  30485.17756  32674.8430  36357.732  \n",
      "VALVULA_4  32942.98100  34024.1540  39198.657  \n",
      "VALVULA_5   4925.48300   4979.6115   5483.756  \n",
      "\n",
      "   Muestra de datos (primeros 10 registros):\n",
      "     VALVULA PERIODO  CONSUMO_TOTAL_VALVULA  NUM_USUARIOS  PRESION_PROMEDIO  \\\n",
      "0  VALVULA_1  202409                377.786             1              0.16   \n",
      "1  VALVULA_1  202410                443.825             1              0.16   \n",
      "2  VALVULA_1  202411                430.229             1              0.16   \n",
      "3  VALVULA_1  202412                407.892             1              0.16   \n",
      "4  VALVULA_1  202501                483.643             1              0.16   \n",
      "5  VALVULA_1  202502                272.899             1              0.16   \n",
      "6  VALVULA_1  202503                457.422             1              0.16   \n",
      "7  VALVULA_1  202504                486.557             1              0.16   \n",
      "8  VALVULA_1  202505                387.497             1              0.16   \n",
      "9  VALVULA_1  202506                502.096             1              0.16   \n",
      "\n",
      "   KPT_PROMEDIO  \n",
      "0       0.98925  \n",
      "1       0.98925  \n",
      "2       0.98925  \n",
      "3       0.98925  \n",
      "4       0.98925  \n",
      "5       0.98925  \n",
      "6       0.98925  \n",
      "7       0.98925  \n",
      "8       0.98925  \n",
      "9       0.98925  \n",
      "\n",
      "5. Guardando resultados...\n",
      "   ‚úì Archivo completo: Usuarios_Por_Valvula.csv\n",
      "   ‚úì Archivo simplificado: Usuarios_Por_Valvula_Simple.csv\n",
      "   ‚úì Resumen estad√≠stico: Resumen_Por_Valvula.csv\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO ‚úì\n",
      "================================================================================\n",
      "\n",
      "Dimensiones finales: (72, 21)\n",
      "Columnas creadas: ['VALVULA', 'PERIODO', 'A√ëO', 'MES', 'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS', 'CONSUMO_PROMEDIO_USUARIO', 'CONSUMO_DESVIACION_USUARIO', 'CONSUMO_MIN_USUARIO', 'CONSUMO_MAX_USUARIO', 'PRESION_PROMEDIO', 'PRESION_DESVIACION', 'PRESION_MIN', 'PRESION_MAX', 'KPT_PROMEDIO', 'KPT_DESVIACION', 'KPT_MIN', 'KPT_MAX', 'GRUPO_MODAL', 'ESTRATO_MODAL', 'CLASE_SERVICIO_MODAL']\n",
      "\n",
      "Archivos generados:\n",
      "  ‚Ä¢ Usuarios_Por_Valvula.csv (completo con estad√≠sticas)\n",
      "  ‚Ä¢ Usuarios_Por_Valvula_Simple.csv (solo promedios y totales)\n",
      "  ‚Ä¢ Resumen_Por_Valvula.csv (resumen por v√°lvula)\n",
      "\n",
      "üí° Nota: CONSUMO_TOTAL_VALVULA es la suma de consumos de todos los usuarios\n",
      "         (equivale al volumen de salida en el balance)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AGREGACI√ìN USUARIOS: POR USUARIO ‚Üí POR V√ÅLVULA Y MES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# CARGAR DATOS\n",
    "# ============================================================================\n",
    "print(\"\\n1. Cargando datos...\")\n",
    "df = pd.read_csv('Variables_Usuarios.csv', sep=';', encoding='latin-1')\n",
    "print(f\"   ‚úì Datos cargados: {df.shape}\")\n",
    "print(f\"   ‚úì Columnas: {list(df.columns)}\")\n",
    "\n",
    "# Limpiar nombres de columnas\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "print(f\"\\n   Total registros: {len(df):,}\")\n",
    "print(f\"   V√°lvulas √∫nicas: {df['CODIGO VALVULA REFERENCIA'].nunique()}\")\n",
    "print(f\"   Usuarios √∫nicos: {df['ID_USUARIO'].nunique()}\")\n",
    "print(f\"   Periodos: {df['PERIODO'].min()} ‚Üí {df['PERIODO'].max()}\")\n",
    "\n",
    "# ============================================================================\n",
    "# CONVERTIR COLUMNAS NUM√âRICAS\n",
    "# ============================================================================\n",
    "print(\"\\n2. Convirtiendo columnas num√©ricas...\")\n",
    "\n",
    "# Funci√≥n para convertir coma decimal a punto\n",
    "def to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    try:\n",
    "        return float(str(value).replace(',', '.'))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir columnas num√©ricas\n",
    "numeric_cols = ['PRESION_SISTEMA', 'KPT_SISTEMA', 'CONSUMO']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].apply(to_numeric)\n",
    "        print(f\"   ‚úì {col} convertido a num√©rico\")\n",
    "\n",
    "# ============================================================================\n",
    "# AGREGAR POR V√ÅLVULA Y MES\n",
    "# ============================================================================\n",
    "print(\"\\n3. Agregando por v√°lvula y mes...\")\n",
    "\n",
    "# Definir agregaciones\n",
    "agregaciones = {\n",
    "    'CONSUMO': ['sum', 'mean', 'std', 'min', 'max'],  # SUMA es el total de consumo de la v√°lvula\n",
    "    'PRESION_SISTEMA': ['mean', 'std', 'min', 'max'],\n",
    "    'KPT_SISTEMA': ['mean', 'std', 'min', 'max'],\n",
    "    'ID_USUARIO': 'count',  # Cantidad de usuarios\n",
    "    'GRUPO_USUARIO': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'ESTRATO': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'CLASE_SERVICIO': lambda x: x.mode()[0] if len(x.mode()) > 0 else x.iloc[0]\n",
    "}\n",
    "\n",
    "# Agrupar\n",
    "df_valvula = df.groupby(['CODIGO VALVULA REFERENCIA', 'PERIODO']).agg(agregaciones).reset_index()\n",
    "\n",
    "# Aplanar nombres de columnas\n",
    "df_valvula.columns = ['_'.join(col).strip('_') if col[1] else col[0]\n",
    "                      for col in df_valvula.columns.values]\n",
    "\n",
    "# Renombrar columnas para mayor claridad\n",
    "df_valvula.rename(columns={\n",
    "    'CODIGO VALVULA REFERENCIA': 'VALVULA',\n",
    "    'CONSUMO_sum': 'CONSUMO_TOTAL_VALVULA',  # Este es el volumen de salida\n",
    "    'CONSUMO_mean': 'CONSUMO_PROMEDIO_USUARIO',\n",
    "    'CONSUMO_std': 'CONSUMO_DESVIACION_USUARIO',\n",
    "    'CONSUMO_min': 'CONSUMO_MIN_USUARIO',\n",
    "    'CONSUMO_max': 'CONSUMO_MAX_USUARIO',\n",
    "    'PRESION_SISTEMA_mean': 'PRESION_PROMEDIO',\n",
    "    'PRESION_SISTEMA_std': 'PRESION_DESVIACION',\n",
    "    'PRESION_SISTEMA_min': 'PRESION_MIN',\n",
    "    'PRESION_SISTEMA_max': 'PRESION_MAX',\n",
    "    'KPT_SISTEMA_mean': 'KPT_PROMEDIO',\n",
    "    'KPT_SISTEMA_std': 'KPT_DESVIACION',\n",
    "    'KPT_SISTEMA_min': 'KPT_MIN',\n",
    "    'KPT_SISTEMA_max': 'KPT_MAX',\n",
    "    'ID_USUARIO_count': 'NUM_USUARIOS',\n",
    "    'GRUPO_USUARIO_<lambda>': 'GRUPO_MODAL',\n",
    "    'ESTRATO_<lambda>': 'ESTRATO_MODAL',\n",
    "    'CLASE_SERVICIO_<lambda>': 'CLASE_SERVICIO_MODAL'\n",
    "}, inplace=True)\n",
    "\n",
    "# Crear columnas de a√±o y mes\n",
    "df_valvula['PERIODO'] = df_valvula['PERIODO'].astype(str)\n",
    "df_valvula['A√ëO'] = df_valvula['PERIODO'].str[:4].astype(int)\n",
    "df_valvula['MES'] = df_valvula['PERIODO'].str[4:6].astype(int)\n",
    "\n",
    "# Reordenar columnas\n",
    "columnas_orden = ['VALVULA', 'PERIODO', 'A√ëO', 'MES',\n",
    "                 'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS'] + \\\n",
    "                 [col for col in df_valvula.columns\n",
    "                  if col not in ['VALVULA', 'PERIODO', 'A√ëO', 'MES',\n",
    "                                'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS']]\n",
    "df_valvula = df_valvula[columnas_orden]\n",
    "\n",
    "print(f\"   ‚úì Agregaci√≥n completada: {df_valvula.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# ESTAD√çSTICAS Y VALIDACI√ìN\n",
    "# ============================================================================\n",
    "print(\"\\n4. Resumen de datos agregados:\")\n",
    "\n",
    "print(\"\\n   Registros por v√°lvula:\")\n",
    "print(df_valvula.groupby('VALVULA').size())\n",
    "\n",
    "print(\"\\n   Rango temporal por v√°lvula:\")\n",
    "rango = df_valvula.groupby('VALVULA')['PERIODO'].agg(['min', 'max', 'count'])\n",
    "rango.columns = ['Primer_Periodo', '√öltimo_Periodo', 'Total_Meses']\n",
    "print(rango)\n",
    "\n",
    "print(\"\\n   Estad√≠sticas de consumo total por v√°lvula:\")\n",
    "print(df_valvula.groupby('VALVULA')['CONSUMO_TOTAL_VALVULA'].describe())\n",
    "\n",
    "print(\"\\n   Muestra de datos (primeros 10 registros):\")\n",
    "print(df_valvula[['VALVULA', 'PERIODO', 'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS',\n",
    "                  'PRESION_PROMEDIO', 'KPT_PROMEDIO']].head(10))\n",
    "\n",
    "# ============================================================================\n",
    "# GUARDAR RESULTADOS\n",
    "# ============================================================================\n",
    "print(\"\\n5. Guardando resultados...\")\n",
    "\n",
    "# Guardar archivo completo\n",
    "df_valvula.to_csv('Usuarios_Por_Valvula.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Archivo completo: Usuarios_Por_Valvula.csv\")\n",
    "\n",
    "# Guardar versi√≥n simplificada (solo promedios y totales)\n",
    "df_simple = df_valvula[['VALVULA', 'PERIODO', 'A√ëO', 'MES',\n",
    "                        'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS',\n",
    "                        'PRESION_PROMEDIO', 'KPT_PROMEDIO',\n",
    "                        'GRUPO_MODAL', 'CLASE_SERVICIO_MODAL']]\n",
    "df_simple.to_csv('Usuarios_Por_Valvula_Simple.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Archivo simplificado: Usuarios_Por_Valvula_Simple.csv\")\n",
    "\n",
    "# Guardar resumen estad√≠stico\n",
    "resumen = df_valvula.groupby('VALVULA').agg({\n",
    "    'CONSUMO_TOTAL_VALVULA': ['sum', 'mean'],\n",
    "    'NUM_USUARIOS': 'mean',\n",
    "    'PRESION_PROMEDIO': 'mean',\n",
    "    'KPT_PROMEDIO': 'mean',\n",
    "    'PERIODO': 'count'\n",
    "}).reset_index()\n",
    "resumen.columns = ['_'.join(col).strip('_') for col in resumen.columns.values]\n",
    "resumen.to_csv('Resumen_Por_Valvula.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Resumen estad√≠stico: Resumen_Por_Valvula.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESO COMPLETADO ‚úì\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDimensiones finales: {df_valvula.shape}\")\n",
    "print(f\"Columnas creadas: {list(df_valvula.columns)}\")\n",
    "print(f\"\\nArchivos generados:\")\n",
    "print(\"  ‚Ä¢ Usuarios_Por_Valvula.csv (completo con estad√≠sticas)\")\n",
    "print(\"  ‚Ä¢ Usuarios_Por_Valvula_Simple.csv (solo promedios y totales)\")\n",
    "print(\"  ‚Ä¢ Resumen_Por_Valvula.csv (resumen por v√°lvula)\")\n",
    "print(f\"\\nüí° Nota: CONSUMO_TOTAL_VALVULA es la suma de consumos de todos los usuarios\")\n",
    "print(\"         (equivale al volumen de salida en el balance)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ic4TiQgf3Ua2",
    "outputId": "152dbd4b-6f31-4d53-8db9-31c3db1ef808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CREACI√ìN DE DATASET MAESTRO DE BALANCES\n",
      "================================================================================\n",
      "\n",
      "1. Cargando datasets...\n",
      "   ‚úì Balances hist√≥ricos: (26, 14)\n",
      "   ‚úì Datos entrada: (5, 11)\n",
      "   ‚úì Macromedici√≥n mensual: (32, 9)\n",
      "   ‚úì Usuarios por v√°lvula: (72, 10)\n",
      "\n",
      "2. Procesando fechas de retiro del macromedidor...\n",
      "\n",
      "   Informaci√≥n de retiro por v√°lvula:\n",
      "     VALVULA FECHA_RETIRO PERIODO_RETIRO  CANTIDAD_PERIODOS_PRONOSTICO\n",
      "0  VALVULA_1   2025-07-21         202507                           9.0\n",
      "1  VALVULA_2   2024-12-02         202412                          10.0\n",
      "2  VALVULA_3   2025-06-24         202506                           3.0\n",
      "3  VALVULA_4   2024-11-22         202411                          11.0\n",
      "4  VALVULA_5   2024-10-04         202410                          12.0\n",
      "\n",
      "3. Preparando balances hist√≥ricos...\n",
      "   Ejemplo de periodos creados: ['202502', '202501', '202412', '202411', '202410']\n",
      "   ‚úì Balances hist√≥ricos procesados: (26, 10)\n",
      "\n",
      "4. Preparando macromedici√≥n mensual...\n",
      "   ‚úì Macromedici√≥n mensual procesada: (32, 7)\n",
      "\n",
      "5. Preparando usuarios por v√°lvula...\n",
      "   ‚úì Usuarios procesados: (72, 6)\n",
      "\n",
      "6. Uniendo todos los datasets...\n",
      "   ‚úì Uni√≥n macro + usuarios: (82, 11)\n",
      "   ‚úì Uni√≥n con balances hist√≥ricos: (82, 19)\n",
      "\n",
      "7. Creando variables finales...\n",
      "\n",
      "   Registros antes de filtrar: 82\n",
      "   Registros despu√©s de filtrar NaN: 82\n",
      "\n",
      "   Muestras de PERIODO: ['202407' '202408' '202409' '202410' '202411' '202412' '202501' '202502'\n",
      " '202503' '202504']\n",
      "   Registros con formato v√°lido (6 d√≠gitos): 82\n",
      "   Registros con formato inv√°lido: 0\n",
      "\n",
      "8. Identificando periodos con/sin macromedidor...\n",
      "   ‚úì Variables de identificaci√≥n creadas\n",
      "\n",
      "9. Seleccionando columnas finales...\n",
      "   ‚úì Dataset final: (82, 22)\n",
      "\n",
      "10. Resumen del dataset maestro:\n",
      "\n",
      "   Registros por v√°lvula:\n",
      "VALVULA\n",
      "VALVULA_1    17\n",
      "VALVULA_2    19\n",
      "VALVULA_3    11\n",
      "VALVULA_4    18\n",
      "VALVULA_5    17\n",
      "dtype: int64\n",
      "\n",
      "   Periodos con/sin macromedidor:\n",
      "           Sin_Macro  Con_Macro\n",
      "VALVULA                        \n",
      "VALVULA_1         10          7\n",
      "VALVULA_2         11          8\n",
      "VALVULA_3          4          7\n",
      "VALVULA_4         12          6\n",
      "VALVULA_5         13          4\n",
      "\n",
      "   Rango temporal por v√°lvula:\n",
      "          Fecha_Inicio  Fecha_Fin  Total_Meses\n",
      "VALVULA                                       \n",
      "VALVULA_1   2024-07-01 2025-11-01           17\n",
      "VALVULA_2   2024-05-01 2025-11-01           19\n",
      "VALVULA_3   2025-01-01 2025-11-01           11\n",
      "VALVULA_4   2024-06-01 2025-11-01           18\n",
      "VALVULA_5   2024-07-01 2025-11-01           17\n",
      "\n",
      "   Periodos a predecir por v√°lvula:\n",
      "VALVULA\n",
      "VALVULA_1     4\n",
      "VALVULA_2    11\n",
      "VALVULA_3     5\n",
      "VALVULA_4    12\n",
      "VALVULA_5    13\n",
      "dtype: int64\n",
      "\n",
      "11. Guardando resultados...\n",
      "   ‚úì Dataset maestro completo: Dataset_Maestro_Balances.csv\n",
      "   ‚úì Dataset entrenamiento: Dataset_Train.csv ((32, 22))\n",
      "   ‚úì Dataset predicci√≥n: Dataset_Prediccion.csv ((45, 22))\n",
      "   ‚úì Resumen: Resumen_Valvulas.csv\n",
      "\n",
      "================================================================================\n",
      "PROCESO COMPLETADO ‚úì\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset maestro creado con 82 registros y 22 columnas\n",
      "\n",
      "üìù Archivos generados:\n",
      "   ‚Ä¢ Dataset_Maestro_Balances.csv - Dataset completo\n",
      "   ‚Ä¢ Dataset_Train.csv - Solo per√≠odos con macromedidor (entrenamiento)\n",
      "   ‚Ä¢ Dataset_Prediccion.csv - Solo per√≠odos a predecir\n",
      "   ‚Ä¢ Resumen_Valvulas.csv - Resumen por v√°lvula\n",
      "\n",
      "üéØ Variable objetivo a predecir: VOLUMEN_ENTRADA_FINAL\n",
      "   (en per√≠odos donde PERIODO_A_PREDECIR = True)\n",
      "\n",
      "üìã Muestra del dataset (√∫ltimos 10 registros):\n",
      "      VALVULA PERIODO  VOLUMEN_ENTRADA_FINAL  VOLUMEN_SALIDA_FINAL  \\\n",
      "72  VALVULA_5  202502                    NaN              4935.425   \n",
      "73  VALVULA_5  202503                    NaN              4866.239   \n",
      "74  VALVULA_5  202504                    NaN              4944.441   \n",
      "75  VALVULA_5  202505                    NaN              4845.262   \n",
      "76  VALVULA_5  202506                    NaN              5483.756   \n",
      "77  VALVULA_5  202507                    NaN              4925.483   \n",
      "78  VALVULA_5  202508                    NaN              5105.857   \n",
      "79  VALVULA_5  202509                    NaN              4679.096   \n",
      "80  VALVULA_5  202510                    NaN              4994.496   \n",
      "81  VALVULA_5  202511                    NaN              5177.004   \n",
      "\n",
      "    INDICE_PERDIDAS_FINAL  TIENE_MACROMEDIDOR  PERIODO_A_PREDECIR  \n",
      "72                    NaN               False                True  \n",
      "73                    NaN               False                True  \n",
      "74                    NaN               False                True  \n",
      "75                    NaN               False                True  \n",
      "76                    NaN               False                True  \n",
      "77                    NaN               False                True  \n",
      "78                    NaN               False                True  \n",
      "79                    NaN               False                True  \n",
      "80                    NaN               False                True  \n",
      "81                    NaN               False                True  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\karly\\AppData\\Local\\Temp\\ipykernel_17652\\3477150713.py:303: FutureWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_maestro['MESES_DESDE_RETIRO'] = df_maestro.groupby('VALVULA', group_keys=False).apply(calcular_meses_retiro).values\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"CREACI√ìN DE DATASET MAESTRO DE BALANCES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 1: CARGAR TODOS LOS DATASETS\n",
    "# ============================================================================\n",
    "print(\"\\n1. Cargando datasets...\")\n",
    "\n",
    "df_balances = pd.read_csv('Balances.csv', sep=';', encoding='latin-1')\n",
    "df_datos_entrada = pd.read_csv('Datos_Entrada.csv', sep=';', encoding='latin-1')\n",
    "df_macro = pd.read_csv('Macromedicion_Mensual_Simple.csv', sep=';', encoding='latin-1')\n",
    "df_usuarios = pd.read_csv('Usuarios_Por_Valvula_Simple.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "print(f\"   ‚úì Balances hist√≥ricos: {df_balances.shape}\")\n",
    "print(f\"   ‚úì Datos entrada: {df_datos_entrada.shape}\")\n",
    "print(f\"   ‚úì Macromedici√≥n mensual: {df_macro.shape}\")\n",
    "print(f\"   ‚úì Usuarios por v√°lvula: {df_usuarios.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 2: PREPARAR DATOS DE ENTRADA (FECHAS DE RETIRO)\n",
    "# ============================================================================\n",
    "print(\"\\n2. Procesando fechas de retiro del macromedidor...\")\n",
    "\n",
    "df_datos_entrada.columns = df_datos_entrada.columns.str.strip()\n",
    "\n",
    "# Funci√≥n de conversi√≥n num√©rica\n",
    "def to_numeric(value):\n",
    "    if pd.isna(value):\n",
    "        return np.nan\n",
    "    if isinstance(value, (int, float)):\n",
    "        return float(value)\n",
    "    try:\n",
    "        return float(str(value).replace(',', '.'))\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Convertir fecha de retiro\n",
    "for formato in ['%d/%m/%Y', '%Y-%m-%d', '%d-%m-%Y']:\n",
    "    try:\n",
    "        df_datos_entrada['FECHA_RETIRO'] = pd.to_datetime(\n",
    "            df_datos_entrada['FECHA RETIRO/TRASLADO'],\n",
    "            format=formato,\n",
    "            errors='coerce'\n",
    "        )\n",
    "        if df_datos_entrada['FECHA_RETIRO'].notna().sum() > 0:\n",
    "            break\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "df_datos_entrada['VALVULA'] = df_datos_entrada['CODIGO VALVULA REFERENCIA']\n",
    "df_datos_entrada['PERIODO_RETIRO'] = df_datos_entrada['FECHA_RETIRO'].dt.to_period('M').astype(str).str.replace('-', '')\n",
    "df_datos_entrada['CANTIDAD_PERIODOS_PRONOSTICO'] = df_datos_entrada['CANTIDAD_PERIODOS_PRONOSTICO'].apply(to_numeric)\n",
    "\n",
    "print(\"\\n   Informaci√≥n de retiro por v√°lvula:\")\n",
    "print(df_datos_entrada[['VALVULA', 'FECHA_RETIRO', 'PERIODO_RETIRO', 'CANTIDAD_PERIODOS_PRONOSTICO']])\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 3: PREPARAR BALANCES HIST√ìRICOS\n",
    "# ============================================================================\n",
    "print(\"\\n3. Preparando balances hist√≥ricos...\")\n",
    "\n",
    "df_balances.columns = df_balances.columns.str.strip()\n",
    "\n",
    "# Convertir columnas num√©ricas\n",
    "numeric_cols_bal = ['ENTRADA_VOLUMEN_MEDIDO_MES', 'SALIDA_CONSUMO_FACTURADO_MES',\n",
    "                    'DIFERENCIA_PERDIDAS', 'INDICE_PERDIDAS',\n",
    "                    'PRESION_PROMEDIO_MES', 'TEMPERATURA_PROMEDIO_MES',\n",
    "                    'FACTOR_CORRECCION_PROMEDIO_MES']\n",
    "\n",
    "for col in numeric_cols_bal:\n",
    "    if col in df_balances.columns:\n",
    "        df_balances[col] = df_balances[col].apply(to_numeric)\n",
    "\n",
    "# Crear PERIODO desde A√ëO y MES\n",
    "df_balances['VALVULA'] = df_balances['CODIGO VALVULA REFERENCIA']\n",
    "\n",
    "# Mapeo de meses en espa√±ol a n√∫meros\n",
    "meses_map = {\n",
    "    'enero': '01', 'febrero': '02', 'marzo': '03', 'abril': '04',\n",
    "    'mayo': '05', 'junio': '06', 'julio': '07', 'agosto': '08',\n",
    "    'septiembre': '09', 'octubre': '10', 'noviembre': '11', 'diciembre': '12'\n",
    "}\n",
    "\n",
    "# Si MES est√° en texto, convertir a n√∫mero\n",
    "if df_balances['MES'].dtype == 'object':\n",
    "    df_balances['MES_NUM'] = df_balances['MES'].str.lower().str.strip().map(meses_map)\n",
    "else:\n",
    "    df_balances['MES_NUM'] = df_balances['MES'].apply(lambda x: f'{int(x):02d}' if pd.notna(x) else None)\n",
    "\n",
    "# Crear PERIODO en formato YYYYMM\n",
    "df_balances['PERIODO'] = df_balances['A√ëO'].astype(str) + df_balances['MES_NUM'].astype(str)\n",
    "\n",
    "print(f\"   Ejemplo de periodos creados: {df_balances['PERIODO'].head().tolist()}\")\n",
    "\n",
    "# Seleccionar columnas relevantes\n",
    "df_balances_clean = df_balances[[\n",
    "    'VALVULA', 'PERIODO',\n",
    "    'ENTRADA_VOLUMEN_MEDIDO_MES', 'SALIDA_CONSUMO_FACTURADO_MES',\n",
    "    'DIFERENCIA_PERDIDAS', 'INDICE_PERDIDAS',\n",
    "    'PRESION_PROMEDIO_MES', 'TEMPERATURA_PROMEDIO_MES',\n",
    "    'FACTOR_CORRECCION_PROMEDIO_MES'\n",
    "]].copy()\n",
    "\n",
    "df_balances_clean.rename(columns={\n",
    "    'ENTRADA_VOLUMEN_MEDIDO_MES': 'VOLUMEN_ENTRADA',\n",
    "    'SALIDA_CONSUMO_FACTURADO_MES': 'VOLUMEN_SALIDA',\n",
    "    'DIFERENCIA_PERDIDAS': 'PERDIDAS',\n",
    "    'INDICE_PERDIDAS': 'INDICE_PERDIDAS',\n",
    "    'PRESION_PROMEDIO_MES': 'PRESION_BALANCE',\n",
    "    'TEMPERATURA_PROMEDIO_MES': 'TEMPERATURA_BALANCE',\n",
    "    'FACTOR_CORRECCION_PROMEDIO_MES': 'KPT_BALANCE'\n",
    "}, inplace=True)\n",
    "\n",
    "df_balances_clean['ORIGEN'] = 'BALANCE_HISTORICO'\n",
    "\n",
    "print(f\"   ‚úì Balances hist√≥ricos procesados: {df_balances_clean.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 4: PREPARAR MACROMEDICI√ìN MENSUAL\n",
    "# ============================================================================\n",
    "print(\"\\n4. Preparando macromedici√≥n mensual...\")\n",
    "\n",
    "df_macro.columns = df_macro.columns.str.strip()\n",
    "\n",
    "# Convertir num√©ricas\n",
    "for col in ['PRESION_PROMEDIO', 'TEMPERATURA_PROMEDIO', 'KPT_PROMEDIO', 'VOLUMEN_TOTAL_MES']:\n",
    "    if col in df_macro.columns:\n",
    "        df_macro[col] = df_macro[col].apply(to_numeric)\n",
    "\n",
    "# Normalizar PERIODO\n",
    "df_macro['PERIODO'] = df_macro['PERIODO'].astype(str).str.replace('-', '')\n",
    "\n",
    "df_macro_clean = df_macro[[\n",
    "    'VALVULA', 'PERIODO',\n",
    "    'VOLUMEN_TOTAL_MES', 'PRESION_PROMEDIO',\n",
    "    'TEMPERATURA_PROMEDIO', 'KPT_PROMEDIO', 'NUM_REGISTROS'\n",
    "]].copy()\n",
    "\n",
    "df_macro_clean.rename(columns={\n",
    "    'VOLUMEN_TOTAL_MES': 'VOLUMEN_ENTRADA_MACRO',\n",
    "    'PRESION_PROMEDIO': 'PRESION_MACRO',\n",
    "    'TEMPERATURA_PROMEDIO': 'TEMPERATURA_MACRO',\n",
    "    'KPT_PROMEDIO': 'KPT_MACRO'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"   ‚úì Macromedici√≥n mensual procesada: {df_macro_clean.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 5: PREPARAR USUARIOS\n",
    "# ============================================================================\n",
    "print(\"\\n5. Preparando usuarios por v√°lvula...\")\n",
    "\n",
    "df_usuarios.columns = df_usuarios.columns.str.strip()\n",
    "\n",
    "# Convertir num√©ricas\n",
    "for col in ['CONSUMO_TOTAL_VALVULA', 'PRESION_PROMEDIO', 'KPT_PROMEDIO']:\n",
    "    if col in df_usuarios.columns:\n",
    "        df_usuarios[col] = df_usuarios[col].apply(to_numeric)\n",
    "\n",
    "df_usuarios['PERIODO'] = df_usuarios['PERIODO'].astype(str)\n",
    "\n",
    "df_usuarios_clean = df_usuarios[[\n",
    "    'VALVULA', 'PERIODO',\n",
    "    'CONSUMO_TOTAL_VALVULA', 'NUM_USUARIOS',\n",
    "    'PRESION_PROMEDIO', 'KPT_PROMEDIO'\n",
    "]].copy()\n",
    "\n",
    "df_usuarios_clean.rename(columns={\n",
    "    'CONSUMO_TOTAL_VALVULA': 'VOLUMEN_SALIDA_USUARIOS',\n",
    "    'PRESION_PROMEDIO': 'PRESION_USUARIOS',\n",
    "    'KPT_PROMEDIO': 'KPT_USUARIOS'\n",
    "}, inplace=True)\n",
    "\n",
    "print(f\"   ‚úì Usuarios procesados: {df_usuarios_clean.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 6: UNIR TODOS LOS DATOS\n",
    "# ============================================================================\n",
    "print(\"\\n6. Uniendo todos los datasets...\")\n",
    "\n",
    "# Unir macromedici√≥n con usuarios\n",
    "df_maestro = df_macro_clean.merge(\n",
    "    df_usuarios_clean,\n",
    "    on=['VALVULA', 'PERIODO'],\n",
    "    how='outer'\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Uni√≥n macro + usuarios: {df_maestro.shape}\")\n",
    "\n",
    "# Unir con balances hist√≥ricos\n",
    "df_maestro = df_maestro.merge(\n",
    "    df_balances_clean,\n",
    "    on=['VALVULA', 'PERIODO'],\n",
    "    how='outer',\n",
    "    suffixes=('', '_HIST')\n",
    ")\n",
    "\n",
    "print(f\"   ‚úì Uni√≥n con balances hist√≥ricos: {df_maestro.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 7: CREAR VARIABLES FINALES Y CALCULAR BALANCES\n",
    "# ============================================================================\n",
    "print(\"\\n7. Creando variables finales...\")\n",
    "\n",
    "# Crear variables consolidadas\n",
    "df_maestro['VOLUMEN_ENTRADA_FINAL'] = df_maestro['VOLUMEN_ENTRADA'].fillna(\n",
    "    df_maestro['VOLUMEN_ENTRADA_MACRO']\n",
    ")\n",
    "\n",
    "df_maestro['VOLUMEN_SALIDA_FINAL'] = df_maestro['VOLUMEN_SALIDA'].fillna(\n",
    "    df_maestro['VOLUMEN_SALIDA_USUARIOS']\n",
    ")\n",
    "\n",
    "# Calcular balance\n",
    "df_maestro['PERDIDAS_CALC'] = (df_maestro['VOLUMEN_ENTRADA_FINAL'] -\n",
    "                                df_maestro['VOLUMEN_SALIDA_FINAL'])\n",
    "\n",
    "df_maestro['INDICE_PERDIDAS_CALC'] = np.where(\n",
    "    df_maestro['VOLUMEN_ENTRADA_FINAL'] > 0,\n",
    "    (df_maestro['PERDIDAS_CALC'] / df_maestro['VOLUMEN_ENTRADA_FINAL']) * 100,\n",
    "    np.nan\n",
    ")\n",
    "\n",
    "# Usar balance hist√≥rico si existe, sino el calculado\n",
    "df_maestro['PERDIDAS_FINAL'] = df_maestro['PERDIDAS'].fillna(df_maestro['PERDIDAS_CALC'])\n",
    "df_maestro['INDICE_PERDIDAS_FINAL'] = df_maestro['INDICE_PERDIDAS'].fillna(df_maestro['INDICE_PERDIDAS_CALC'])\n",
    "\n",
    "# Consolidar presi√≥n y temperatura\n",
    "df_maestro['PRESION_FINAL'] = df_maestro['PRESION_BALANCE'].fillna(\n",
    "    df_maestro['PRESION_MACRO']\n",
    ").fillna(df_maestro['PRESION_USUARIOS'])\n",
    "\n",
    "df_maestro['TEMPERATURA_FINAL'] = df_maestro['TEMPERATURA_BALANCE'].fillna(\n",
    "    df_maestro['TEMPERATURA_MACRO']\n",
    ")\n",
    "\n",
    "df_maestro['KPT_FINAL'] = df_maestro['KPT_BALANCE'].fillna(\n",
    "    df_maestro['KPT_MACRO']\n",
    ").fillna(df_maestro['KPT_USUARIOS'])\n",
    "\n",
    "# Filtrar registros sin periodo\n",
    "print(f\"\\n   Registros antes de filtrar: {len(df_maestro)}\")\n",
    "df_maestro = df_maestro[df_maestro['PERIODO'].notna()].copy()\n",
    "df_maestro['PERIODO'] = df_maestro['PERIODO'].astype(str)\n",
    "print(f\"   Registros despu√©s de filtrar NaN: {len(df_maestro)}\")\n",
    "\n",
    "# Verificar y limpiar formatos de PERIODO\n",
    "print(f\"\\n   Muestras de PERIODO: {df_maestro['PERIODO'].unique()[:10]}\")\n",
    "\n",
    "# Normalizar PERIODO: eliminar guiones y espacios\n",
    "df_maestro['PERIODO'] = df_maestro['PERIODO'].str.replace('-', '').str.replace(' ', '').str.strip()\n",
    "\n",
    "# Verificar longitud correcta (debe ser 6 d√≠gitos: YYYYMM)\n",
    "mask_valido = df_maestro['PERIODO'].str.len() == 6\n",
    "print(f\"   Registros con formato v√°lido (6 d√≠gitos): {mask_valido.sum()}\")\n",
    "print(f\"   Registros con formato inv√°lido: {(~mask_valido).sum()}\")\n",
    "\n",
    "if (~mask_valido).sum() > 0:\n",
    "    print(f\"\\n   ‚ö† PERIODOS inv√°lidos encontrados:\")\n",
    "    print(df_maestro[~mask_valido][['VALVULA', 'PERIODO']].head(10))\n",
    "    print(f\"\\n   Eliminando {(~mask_valido).sum()} registros con periodo inv√°lido...\")\n",
    "    df_maestro = df_maestro[mask_valido].copy()\n",
    "\n",
    "# Crear columnas temporales\n",
    "df_maestro['A√ëO'] = df_maestro['PERIODO'].str[:4].astype(int)\n",
    "df_maestro['MES'] = df_maestro['PERIODO'].str[4:6].astype(int)\n",
    "df_maestro['FECHA'] = pd.to_datetime(df_maestro['PERIODO'], format='%Y%m', errors='coerce')\n",
    "\n",
    "# Ordenar\n",
    "df_maestro = df_maestro.sort_values(['VALVULA', 'FECHA']).reset_index(drop=True)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 8: MARCAR PERIODOS CON/SIN MACROMEDIDOR\n",
    "# ============================================================================\n",
    "print(\"\\n8. Identificando periodos con/sin macromedidor...\")\n",
    "\n",
    "# Unir con fechas de retiro\n",
    "df_maestro = df_maestro.merge(\n",
    "    df_datos_entrada[['VALVULA', 'PERIODO_RETIRO', 'CANTIDAD_PERIODOS_PRONOSTICO']],\n",
    "    on='VALVULA',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "# Marcar si hay macromedidor\n",
    "df_maestro['TIENE_MACROMEDIDOR'] = df_maestro['VOLUMEN_ENTRADA_MACRO'].notna()\n",
    "df_maestro['PERIODO_A_PREDECIR'] = (df_maestro['PERIODO'] > df_maestro['PERIODO_RETIRO'])\n",
    "\n",
    "# Calcular meses desde retiro\n",
    "def calcular_meses_retiro(grupo):\n",
    "    retiro_periodo = grupo['PERIODO_RETIRO'].iloc[0]\n",
    "    if pd.notna(retiro_periodo):\n",
    "        retiro_fecha = grupo[grupo['PERIODO'] == retiro_periodo]['FECHA']\n",
    "        if len(retiro_fecha) > 0:\n",
    "            meses = ((grupo['FECHA'] - retiro_fecha.iloc[0]).dt.days / 30).round(0)\n",
    "            return meses\n",
    "    return pd.Series([np.nan] * len(grupo), index=grupo.index)\n",
    "\n",
    "df_maestro['MESES_DESDE_RETIRO'] = df_maestro.groupby('VALVULA', group_keys=False).apply(calcular_meses_retiro).values\n",
    "\n",
    "print(f\"   ‚úì Variables de identificaci√≥n creadas\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 9: SELECCIONAR COLUMNAS FINALES\n",
    "# ============================================================================\n",
    "print(\"\\n9. Seleccionando columnas finales...\")\n",
    "\n",
    "columnas_finales = [\n",
    "    'VALVULA', 'PERIODO', 'A√ëO', 'MES', 'FECHA',\n",
    "    # Variables objetivo\n",
    "    'VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL',\n",
    "    'PERDIDAS_FINAL', 'INDICE_PERDIDAS_FINAL',\n",
    "    # Variables predictoras\n",
    "    'PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL',\n",
    "    'NUM_USUARIOS', 'NUM_REGISTROS',\n",
    "    # Variables de control\n",
    "    'TIENE_MACROMEDIDOR', 'PERIODO_A_PREDECIR', 'MESES_DESDE_RETIRO',\n",
    "    # Variables originales (para an√°lisis)\n",
    "    'VOLUMEN_ENTRADA_MACRO', 'VOLUMEN_SALIDA_USUARIOS',\n",
    "    'PRESION_MACRO', 'TEMPERATURA_MACRO', 'KPT_MACRO'\n",
    "]\n",
    "\n",
    "# Filtrar solo columnas que existen\n",
    "columnas_disponibles = [col for col in columnas_finales if col in df_maestro.columns]\n",
    "df_final = df_maestro[columnas_disponibles].copy()\n",
    "\n",
    "print(f\"   ‚úì Dataset final: {df_final.shape}\")\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 10: RESUMEN Y VALIDACI√ìN\n",
    "# ============================================================================\n",
    "print(\"\\n10. Resumen del dataset maestro:\")\n",
    "\n",
    "print(\"\\n   Registros por v√°lvula:\")\n",
    "print(df_final.groupby('VALVULA').size())\n",
    "\n",
    "print(\"\\n   Periodos con/sin macromedidor:\")\n",
    "resumen = df_final.groupby(['VALVULA', 'TIENE_MACROMEDIDOR']).size().unstack(fill_value=0)\n",
    "resumen.columns = ['Sin_Macro', 'Con_Macro']\n",
    "print(resumen)\n",
    "\n",
    "print(\"\\n   Rango temporal por v√°lvula:\")\n",
    "rango_temp = df_final.groupby('VALVULA')['FECHA'].agg(['min', 'max', 'count'])\n",
    "rango_temp.columns = ['Fecha_Inicio', 'Fecha_Fin', 'Total_Meses']\n",
    "print(rango_temp)\n",
    "\n",
    "print(\"\\n   Periodos a predecir por v√°lvula:\")\n",
    "pred = df_final[df_final['PERIODO_A_PREDECIR'] == True].groupby('VALVULA').size()\n",
    "print(pred)\n",
    "\n",
    "# ============================================================================\n",
    "# PASO 11: GUARDAR RESULTADOS\n",
    "# ============================================================================\n",
    "print(\"\\n11. Guardando resultados...\")\n",
    "\n",
    "# Guardar dataset completo\n",
    "df_final.to_csv('Dataset_Maestro_Balances.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Dataset maestro completo: Dataset_Maestro_Balances.csv\")\n",
    "\n",
    "# Guardar solo periodos con macromedidor (para entrenamiento)\n",
    "df_train = df_final[df_final['TIENE_MACROMEDIDOR'] == True].copy()\n",
    "df_train.to_csv('Dataset_Train.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Dataset entrenamiento: Dataset_Train.csv ({df_train.shape})\")\n",
    "\n",
    "# Guardar solo periodos a predecir\n",
    "df_pred = df_final[df_final['PERIODO_A_PREDECIR'] == True].copy()\n",
    "df_pred.to_csv('Dataset_Prediccion.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Dataset predicci√≥n: Dataset_Prediccion.csv ({df_pred.shape})\")\n",
    "\n",
    "# Guardar resumen por v√°lvula\n",
    "resumen_valvula = df_final.groupby('VALVULA').agg({\n",
    "    'FECHA': ['min', 'max'],\n",
    "    'VOLUMEN_ENTRADA_FINAL': 'sum',\n",
    "    'VOLUMEN_SALIDA_FINAL': 'sum',\n",
    "    'INDICE_PERDIDAS_FINAL': 'mean',\n",
    "    'TIENE_MACROMEDIDOR': 'sum',\n",
    "    'PERIODO_A_PREDECIR': 'sum'\n",
    "}).reset_index()\n",
    "resumen_valvula.columns = ['_'.join(col).strip('_') for col in resumen_valvula.columns.values]\n",
    "resumen_valvula.to_csv('Resumen_Valvulas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"   ‚úì Resumen: Resumen_Valvulas.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"PROCESO COMPLETADO ‚úì\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nüìä Dataset maestro creado con {df_final.shape[0]} registros y {df_final.shape[1]} columnas\")\n",
    "print(f\"\\nüìù Archivos generados:\")\n",
    "print(f\"   ‚Ä¢ Dataset_Maestro_Balances.csv - Dataset completo\")\n",
    "print(f\"   ‚Ä¢ Dataset_Train.csv - Solo per√≠odos con macromedidor (entrenamiento)\")\n",
    "print(f\"   ‚Ä¢ Dataset_Prediccion.csv - Solo per√≠odos a predecir\")\n",
    "print(f\"   ‚Ä¢ Resumen_Valvulas.csv - Resumen por v√°lvula\")\n",
    "print(f\"\\nüéØ Variable objetivo a predecir: VOLUMEN_ENTRADA_FINAL\")\n",
    "print(f\"   (en per√≠odos donde PERIODO_A_PREDECIR = True)\")\n",
    "\n",
    "# Mostrar muestra\n",
    "print(\"\\nüìã Muestra del dataset (√∫ltimos 10 registros):\")\n",
    "print(df_final[['VALVULA', 'PERIODO', 'VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL',\n",
    "                'INDICE_PERDIDAS_FINAL', 'TIENE_MACROMEDIDOR', 'PERIODO_A_PREDECIR']].tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AWkKfsY54Ful",
    "outputId": "abbe1405-8f57-454c-97a0-9b882359ea36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISIS DEL DATASET DE ENTRENAMIENTO\n",
      "================================================================================\n",
      "\n",
      "1. Registros por v√°lvula con macromedidor:\n",
      "VALVULA\n",
      "VALVULA_1    7\n",
      "VALVULA_2    8\n",
      "VALVULA_3    7\n",
      "VALVULA_4    6\n",
      "VALVULA_5    4\n",
      "dtype: int64\n",
      "\n",
      "2. Valores disponibles de VOLUMEN_ENTRADA_FINAL:\n",
      "   Total registros: 32\n",
      "   Con volumen entrada: 32\n",
      "   Sin volumen entrada: 0\n",
      "\n",
      "3. Muestra de datos con volumen:\n",
      "      VALVULA  PERIODO VOLUMEN_ENTRADA_FINAL VOLUMEN_SALIDA_FINAL  \\\n",
      "0   VALVULA_1   202407                  66,5                  NaN   \n",
      "1   VALVULA_1   202408    405,53000000000003                  NaN   \n",
      "2   VALVULA_1   202409                334,21              377,786   \n",
      "3   VALVULA_1   202410                428,15              443,825   \n",
      "4   VALVULA_1   202411                414,74              430,229   \n",
      "5   VALVULA_1   202412                399,51              407,892   \n",
      "6   VALVULA_1   202501                472,57              483,643   \n",
      "7   VALVULA_2   202405    1346,8700000000001                  NaN   \n",
      "8   VALVULA_2   202406               2246,85                  NaN   \n",
      "9   VALVULA_2   202407               2784,44             2542,798   \n",
      "10  VALVULA_2   202408               1837,52             2148,637   \n",
      "11  VALVULA_2   202409               2380,57             2178,348   \n",
      "12  VALVULA_2   202410               2312,88             2230,319   \n",
      "13  VALVULA_2   202411           1924,086667             1714,561   \n",
      "14  VALVULA_2   202412               1731,47             1494,091   \n",
      "\n",
      "   PERDIDAS_FINAL INDICE_PERDIDAS_FINAL  \n",
      "0             NaN                   NaN  \n",
      "1             NaN                   NaN  \n",
      "2         -43,576          -0,130385087  \n",
      "3         -15,675          -0,036611001  \n",
      "4         -15,489          -0,037346289  \n",
      "5          -8,382          -0,020980701  \n",
      "6         -11,073          -0,023431449  \n",
      "7             NaN                   NaN  \n",
      "8             NaN                   NaN  \n",
      "9         241,642            0,08678298  \n",
      "10       -311,117          -0,169313531  \n",
      "11        202,222           0,084946882  \n",
      "12         82,561           0,035696188  \n",
      "13    209,5256667           0,108896169  \n",
      "14        237,379           0,137096802  \n",
      "\n",
      "4. Estad√≠sticas por v√°lvula:\n",
      "          VOLUMEN_ENTRADA_FINAL PERIODO        \n",
      "                       <lambda>     min     max\n",
      "VALVULA                                        \n",
      "VALVULA_1                   7/7  202407  202501\n",
      "VALVULA_2                   8/8  202405  202412\n",
      "VALVULA_3                   7/7  202501  202507\n",
      "VALVULA_4                   6/6  202406  202411\n",
      "VALVULA_5                   4/4  202407  202410\n"
     ]
    }
   ],
   "source": [
    "# Ver qu√© datos tenemos en el dataset de entrenamiento\n",
    "df_train = pd.read_csv('Dataset_Train.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DEL DATASET DE ENTRENAMIENTO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n1. Registros por v√°lvula con macromedidor:\")\n",
    "print(df_train.groupby('VALVULA').size())\n",
    "\n",
    "print(\"\\n2. Valores disponibles de VOLUMEN_ENTRADA_FINAL:\")\n",
    "print(f\"   Total registros: {len(df_train)}\")\n",
    "print(f\"   Con volumen entrada: {df_train['VOLUMEN_ENTRADA_FINAL'].notna().sum()}\")\n",
    "print(f\"   Sin volumen entrada: {df_train['VOLUMEN_ENTRADA_FINAL'].isna().sum()}\")\n",
    "\n",
    "print(\"\\n3. Muestra de datos con volumen:\")\n",
    "print(df_train[df_train['VOLUMEN_ENTRADA_FINAL'].notna()][\n",
    "    ['VALVULA', 'PERIODO', 'VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL',\n",
    "     'PERDIDAS_FINAL', 'INDICE_PERDIDAS_FINAL']\n",
    "].head(15))\n",
    "\n",
    "print(\"\\n4. Estad√≠sticas por v√°lvula:\")\n",
    "stats = df_train.groupby('VALVULA').agg({\n",
    "    'VOLUMEN_ENTRADA_FINAL': lambda x: f\"{x.notna().sum()}/{len(x)}\",\n",
    "    'PERIODO': ['min', 'max']\n",
    "})\n",
    "print(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "EDA: AN√ÅLISIS EXPLORATORIO DE DATOS\n",
      "================================================================================\n",
      "\n",
      "üìä Dataset cargado: 82 registros, 22 columnas\n",
      "\n",
      "1. ESTAD√çSTICAS DESCRIPTIVAS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Resumen estad√≠stico de variables num√©ricas:\n",
      "       VOLUMEN_ENTRADA_FINAL  VOLUMEN_SALIDA_FINAL  PERDIDAS_FINAL  \\\n",
      "count                  36.00                 72.00           26.00   \n",
      "mean                11349.36              12572.75         -649.05   \n",
      "std                 12943.54              14049.49         1470.42   \n",
      "min                    66.50                272.90        -5335.89   \n",
      "25%                  1218.00               1699.95         -412.09   \n",
      "50%                  3559.43               4760.62         -102.32   \n",
      "75%                 27731.20              28893.38           -6.96   \n",
      "max                 35938.86              39198.66          241.64   \n",
      "\n",
      "       INDICE_PERDIDAS_FINAL  PRESION_FINAL  TEMPERATURA_FINAL  KPT_FINAL  \\\n",
      "count                  26.00          80.00              33.00      78.00   \n",
      "mean                   -0.03           1.79              23.32       2.72   \n",
      "std                     0.09           1.97               7.63       1.79   \n",
      "min                    -0.19           0.00               0.00       0.84   \n",
      "25%                    -0.06           0.16              24.00       0.99   \n",
      "50%                    -0.02           0.60              25.89       1.42   \n",
      "75%                    -0.00           3.96              26.48       4.55   \n",
      "max                     0.14           5.21              28.05       5.22   \n",
      "\n",
      "       NUM_USUARIOS  NUM_REGISTROS  \n",
      "count         72.00          32.00  \n",
      "mean          94.00       17671.94  \n",
      "std          178.49       16929.33  \n",
      "min            1.00          15.00  \n",
      "25%            1.00         743.25  \n",
      "50%            8.00       17745.50  \n",
      "75%           12.75       26459.00  \n",
      "max          802.00       44590.00  \n",
      "\n",
      "‚úì Estad√≠sticas guardadas en: eda/Estadisticas_Descriptivas.csv\n",
      "\n",
      "2. AN√ÅLISIS DE VALORES FALTANTES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Variables con valores faltantes:\n",
      "               Variable  Valores_Faltantes  Porcentaje\n",
      "  INDICE_PERDIDAS_FINAL                 56   68.292683\n",
      "         PERDIDAS_FINAL                 56   68.292683\n",
      "      TEMPERATURA_MACRO                 55   67.073171\n",
      "          PRESION_MACRO                 54   65.853659\n",
      "  VOLUMEN_ENTRADA_MACRO                 50   60.975610\n",
      "              KPT_MACRO                 50   60.975610\n",
      "          NUM_REGISTROS                 50   60.975610\n",
      "      TEMPERATURA_FINAL                 49   59.756098\n",
      "  VOLUMEN_ENTRADA_FINAL                 46   56.097561\n",
      "VOLUMEN_SALIDA_USUARIOS                 10   12.195122\n",
      "   VOLUMEN_SALIDA_FINAL                 10   12.195122\n",
      "           NUM_USUARIOS                 10   12.195122\n",
      "              KPT_FINAL                  4    4.878049\n",
      "          PRESION_FINAL                  2    2.439024\n",
      "‚úì Gr√°fico guardado en: eda/Valores_Faltantes.html\n",
      "\n",
      "3. AN√ÅLISIS DE CORRELACIONES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Matriz de correlaci√≥n:\n",
      "                       VOLUMEN_ENTRADA_FINAL  VOLUMEN_SALIDA_FINAL  \\\n",
      "VOLUMEN_ENTRADA_FINAL                  1.000                 0.996   \n",
      "VOLUMEN_SALIDA_FINAL                   0.996                 1.000   \n",
      "PERDIDAS_FINAL                        -0.503                -0.576   \n",
      "INDICE_PERDIDAS_FINAL                 -0.202                -0.255   \n",
      "PRESION_FINAL                          0.114                 0.107   \n",
      "TEMPERATURA_FINAL                      0.165                 0.218   \n",
      "KPT_FINAL                             -0.523                 0.101   \n",
      "NUM_USUARIOS                          -0.201                -0.264   \n",
      "NUM_REGISTROS                         -0.211                -0.340   \n",
      "\n",
      "                       PERDIDAS_FINAL  INDICE_PERDIDAS_FINAL  PRESION_FINAL  \\\n",
      "VOLUMEN_ENTRADA_FINAL          -0.503                 -0.202          0.114   \n",
      "VOLUMEN_SALIDA_FINAL           -0.576                 -0.255          0.107   \n",
      "PERDIDAS_FINAL                  1.000                  0.635         -0.034   \n",
      "INDICE_PERDIDAS_FINAL           0.635                  1.000          0.051   \n",
      "PRESION_FINAL                  -0.034                  0.051          1.000   \n",
      "TEMPERATURA_FINAL              -0.148                  0.010          0.954   \n",
      "KPT_FINAL                       0.553                  0.554          0.920   \n",
      "NUM_USUARIOS                    0.123                  0.002         -0.395   \n",
      "NUM_REGISTROS                   0.197                 -0.134          0.340   \n",
      "\n",
      "                       TEMPERATURA_FINAL  KPT_FINAL  NUM_USUARIOS  \\\n",
      "VOLUMEN_ENTRADA_FINAL              0.165     -0.523        -0.201   \n",
      "VOLUMEN_SALIDA_FINAL               0.218      0.101        -0.264   \n",
      "PERDIDAS_FINAL                    -0.148      0.553         0.123   \n",
      "INDICE_PERDIDAS_FINAL              0.010      0.554         0.002   \n",
      "PRESION_FINAL                      0.954      0.920        -0.395   \n",
      "TEMPERATURA_FINAL                  1.000      0.362        -0.981   \n",
      "KPT_FINAL                          0.362      1.000        -0.286   \n",
      "NUM_USUARIOS                      -0.981     -0.286         1.000   \n",
      "NUM_REGISTROS                      0.253      0.193        -0.333   \n",
      "\n",
      "                       NUM_REGISTROS  \n",
      "VOLUMEN_ENTRADA_FINAL         -0.211  \n",
      "VOLUMEN_SALIDA_FINAL          -0.340  \n",
      "PERDIDAS_FINAL                 0.197  \n",
      "INDICE_PERDIDAS_FINAL         -0.134  \n",
      "PRESION_FINAL                  0.340  \n",
      "TEMPERATURA_FINAL              0.253  \n",
      "KPT_FINAL                      0.193  \n",
      "NUM_USUARIOS                  -0.333  \n",
      "NUM_REGISTROS                  1.000  \n",
      "\n",
      "‚úì Matriz de correlaci√≥n guardada en: eda/Matriz_Correlacion.csv\n",
      "\n",
      "Correlaciones con VOLUMEN_ENTRADA_FINAL (variable objetivo):\n",
      "  VOLUMEN_SALIDA_FINAL: 0.996\n",
      "    ‚úÖ CORRELACI√ìN FUERTE\n",
      "  TEMPERATURA_FINAL: 0.165\n",
      "  PRESION_FINAL: 0.114\n",
      "  NUM_USUARIOS: -0.201\n",
      "  INDICE_PERDIDAS_FINAL: -0.202\n",
      "  NUM_REGISTROS: -0.211\n",
      "  PERDIDAS_FINAL: -0.503\n",
      "    ‚ö† Correlaci√≥n moderada\n",
      "  KPT_FINAL: -0.523\n",
      "    ‚ö† Correlaci√≥n moderada\n",
      "‚úì Gr√°fico de correlaci√≥n guardado en: eda/Matriz_Correlacion_Visual.html\n",
      "\n",
      "4. AN√ÅLISIS DE DISTRIBUCIONES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VOLUMEN_ENTRADA_FINAL:\n",
      "  Media: 11349.36\n",
      "  Mediana: 3559.43\n",
      "  Std: 12943.54\n",
      "  Min: 66.50, Max: 35938.86\n",
      "  Coeficiente de variaci√≥n: 114.05%\n",
      "  ‚ö† Distribuci√≥n moderadamente asim√©trica (skew: 0.72)\n",
      "\n",
      "VOLUMEN_SALIDA_FINAL:\n",
      "  Media: 12572.75\n",
      "  Mediana: 4760.62\n",
      "  Std: 14049.49\n",
      "  Min: 272.90, Max: 39198.66\n",
      "  Coeficiente de variaci√≥n: 111.75%\n",
      "  ‚ö† Distribuci√≥n moderadamente asim√©trica (skew: 0.69)\n",
      "\n",
      "PERDIDAS_FINAL:\n",
      "  Media: -649.05\n",
      "  Mediana: -102.32\n",
      "  Std: 1470.42\n",
      "  Min: -5335.89, Max: 241.64\n",
      "  Coeficiente de variaci√≥n: -226.55%\n",
      "  ‚ö† Distribuci√≥n muy asim√©trica (skew: -2.60)\n",
      "\n",
      "INDICE_PERDIDAS_FINAL:\n",
      "  Media: -0.03\n",
      "  Mediana: -0.02\n",
      "  Std: 0.09\n",
      "  Min: -0.19, Max: 0.14\n",
      "  Coeficiente de variaci√≥n: -260.68%\n",
      "  ‚úì Distribuci√≥n aproximadamente normal (skew: -0.12)\n",
      "\n",
      "PRESION_FINAL:\n",
      "  Media: 1.79\n",
      "  Mediana: 0.60\n",
      "  Std: 1.97\n",
      "  Min: 0.00, Max: 5.21\n",
      "  Coeficiente de variaci√≥n: 110.31%\n",
      "  ‚úì Distribuci√≥n aproximadamente normal (skew: 0.49)\n",
      "\n",
      "TEMPERATURA_FINAL:\n",
      "  Media: 23.32\n",
      "  Mediana: 25.89\n",
      "  Std: 7.63\n",
      "  Min: 0.00, Max: 28.05\n",
      "  Coeficiente de variaci√≥n: 32.72%\n",
      "  ‚ö† Distribuci√≥n muy asim√©trica (skew: -2.79)\n",
      "\n",
      "KPT_FINAL:\n",
      "  Media: 2.72\n",
      "  Mediana: 1.42\n",
      "  Std: 1.79\n",
      "  Min: 0.84, Max: 5.22\n",
      "  Coeficiente de variaci√≥n: 65.80%\n",
      "  ‚úì Distribuci√≥n aproximadamente normal (skew: 0.18)\n",
      "\n",
      "‚úì Gr√°ficos de distribuciones guardados en: eda/Distribuciones_Variables.html\n",
      "\n",
      "5. AN√ÅLISIS DE OUTLIERS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "PERDIDAS_FINAL:\n",
      "  Outliers detectados: 3 (11.5%)\n",
      "  Rango normal: [-1019.77, 600.72]\n",
      "  ‚ö† ALTO porcentaje de outliers\n",
      "\n",
      "INDICE_PERDIDAS_FINAL:\n",
      "  Outliers detectados: 9 (34.6%)\n",
      "  Rango normal: [-0.14, 0.08]\n",
      "  ‚ö† ALTO porcentaje de outliers\n",
      "\n",
      "TEMPERATURA_FINAL:\n",
      "  Outliers detectados: 3 (9.1%)\n",
      "  Rango normal: [20.30, 30.18]\n",
      "\n",
      "‚úì An√°lisis de outliers guardado en: eda/Analisis_Outliers.csv\n",
      "\n",
      "6. AN√ÅLISIS POR V√ÅLVULA\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Estad√≠sticas por v√°lvula:\n",
      "          VOLUMEN_ENTRADA_FINAL                VOLUMEN_SALIDA_FINAL           \\\n",
      "                           mean      std count                 mean      std   \n",
      "VALVULA                                                                        \n",
      "VALVULA_1                348.45   130.08     8               465.19    82.98   \n",
      "VALVULA_2               2021.96   444.45     9              2380.17   692.28   \n",
      "VALVULA_3              25118.24  7832.44     7             30542.14  3396.81   \n",
      "VALVULA_4              27533.24  6911.55     7             31832.26  3883.60   \n",
      "VALVULA_5               3806.24  1671.77     5              4906.78   238.41   \n",
      "\n",
      "                PERDIDAS_FINAL                INDICE_PERDIDAS_FINAL        \\\n",
      "          count           mean      std count                  mean   std   \n",
      "VALVULA                                                                     \n",
      "VALVULA_1    15         -16.78    13.64     6                 -0.05  0.04   \n",
      "VALVULA_2    17          55.82   243.25     7                  0.02  0.13   \n",
      "VALVULA_3     9       -1817.32  2105.99     5                 -0.07  0.08   \n",
      "VALVULA_4    16       -1522.07  2159.70     5                 -0.05  0.08   \n",
      "VALVULA_5    15        -156.15   171.59     3                 -0.03  0.04   \n",
      "\n",
      "                PRESION_FINAL             TEMPERATURA_FINAL              \\\n",
      "          count          mean   std count              mean   std count   \n",
      "VALVULA                                                                   \n",
      "VALVULA_1     6          1.96  1.96    17             24.81  2.09     8   \n",
      "VALVULA_2     7          2.36  2.19    19             26.69  0.77     9   \n",
      "VALVULA_3     5          2.43  1.91    11             25.74  0.46     6   \n",
      "VALVULA_4     5          2.10  1.92    18             25.20  1.57     7   \n",
      "VALVULA_5     3          0.02  0.01    15              0.00  0.00     3   \n",
      "\n",
      "          KPT_FINAL              \n",
      "               mean   std count  \n",
      "VALVULA                          \n",
      "VALVULA_1      2.72  1.90    17  \n",
      "VALVULA_2      3.01  2.03    19  \n",
      "VALVULA_3      4.44  0.19     7  \n",
      "VALVULA_4      2.55  1.48    18  \n",
      "VALVULA_5      1.86  1.62    17  \n",
      "\n",
      "‚úì Estad√≠sticas por v√°lvula guardadas en: eda/Estadisticas_Por_Valvula.csv\n",
      "‚úì Boxplot guardado en: eda/Boxplot_Entrada_Por_Valvula.html\n",
      "\n",
      "7. AN√ÅLISIS TEMPORAL\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Serie temporal guardada en: eda/Serie_Temporal_Entrada.html\n",
      "\n",
      "Tendencias por v√°lvula:\n",
      "  VALVULA_2: Cambio de 286.06 (+21.2%)\n",
      "  VALVULA_4: Cambio de 20699.76 (+164.3%)\n",
      "  VALVULA_1: Cambio de 199.91 (+300.6%)\n",
      "  VALVULA_5: Cambio de 3858.60 (+464.1%)\n",
      "  VALVULA_3: Cambio de 17939.47 (+168.6%)\n",
      "\n",
      "8. AN√ÅLISIS DE RELACIONES ENTRE VARIABLES\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Gr√°fico guardado: eda/Scatter_VOLUMENSALIDAFINAL_vs_VOLUMENENTRADAFINAL.html\n",
      "‚úì Gr√°fico guardado: eda/Scatter_PRESIONFINAL_vs_VOLUMENENTRADAFINAL.html\n",
      "‚úì Gr√°fico guardado: eda/Scatter_NUMUSUARIOS_vs_VOLUMENENTRADAFINAL.html\n",
      "‚úì Gr√°fico guardado: eda/Scatter_TEMPERATURAFINAL_vs_VOLUMENENTRADAFINAL.html\n",
      "\n",
      "9. RESUMEN DE INSIGHTS Y RECOMENDACIONES\n",
      "--------------------------------------------------------------------------------\n",
      "1. ‚úÖ Variables fuertemente correlacionadas con VOLUMEN_ENTRADA_FINAL: VOLUMEN_SALIDA_FINAL, KPT_FINAL, PERDIDAS_FINAL\n",
      "2. ‚ö†Ô∏è Variable con m√°s valores faltantes: INDICE_PERDIDAS_FINAL (68.3%)\n",
      "3. ‚ö†Ô∏è Variable con muchos outliers: INDICE_PERDIDAS_FINAL (34.6%)\n",
      "4. ‚ö†Ô∏è Alta variabilidad en VOLUMEN_ENTRADA_FINAL (CV: 114.0%)\n",
      "\n",
      "‚úì Insights guardados en: eda/Insights_EDA.txt\n",
      "\n",
      "================================================================================\n",
      "EDA COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "üìÅ Archivos generados en carpeta 'eda/':\n",
      "   ‚Ä¢ Estadisticas_Descriptivas.csv\n",
      "   ‚Ä¢ Valores_Faltantes.csv\n",
      "   ‚Ä¢ Matriz_Correlacion.csv\n",
      "   ‚Ä¢ Analisis_Outliers.csv\n",
      "   ‚Ä¢ Estadisticas_Por_Valvula.csv\n",
      "   ‚Ä¢ Insights_EDA.txt\n",
      "   ‚Ä¢ Gr√°ficos HTML interactivos\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# EDA: EXPLORATORY DATA ANALYSIS - AN√ÅLISIS EXPLORATORIO DE DATOS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"EDA: AN√ÅLISIS EXPLORATORIO DE DATOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar dataset maestro\n",
    "if not os.path.exists('Dataset_Maestro_Balances.csv'):\n",
    "    print(\"‚ùå ERROR: Dataset_Maestro_Balances.csv no encontrado\")\n",
    "    print(\"   Ejecuta primero la Celda 12 (Construcci√≥n del Dataset Maestro)\")\n",
    "    raise FileNotFoundError(\"Dataset_Maestro_Balances.csv no encontrado\")\n",
    "\n",
    "df = pd.read_csv('Dataset_Maestro_Balances.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# Asegurar tipos num√©ricos\n",
    "numeric_cols = ['VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL', 'PERDIDAS_FINAL', \n",
    "                'INDICE_PERDIDAS_FINAL', 'PRESION_FINAL', 'TEMPERATURA_FINAL', \n",
    "                'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']\n",
    "for col in numeric_cols:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce')\n",
    "\n",
    "print(f\"\\nüìä Dataset cargado: {df.shape[0]} registros, {df.shape[1]} columnas\")\n",
    "\n",
    "# Crear directorio para gr√°ficos EDA\n",
    "os.makedirs('eda', exist_ok=True)\n",
    "\n",
    "# ===== 1. ESTAD√çSTICAS DESCRIPTIVAS =====\n",
    "print(\"\\n1. ESTAD√çSTICAS DESCRIPTIVAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "print(\"\\nResumen estad√≠stico de variables num√©ricas:\")\n",
    "stats = df[numeric_cols].describe()\n",
    "print(stats.round(2))\n",
    "\n",
    "# Guardar estad√≠sticas\n",
    "stats.to_csv('eda/Estadisticas_Descriptivas.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "print(\"\\n‚úì Estad√≠sticas guardadas en: eda/Estadisticas_Descriptivas.csv\")\n",
    "\n",
    "# ===== 2. AN√ÅLISIS DE VALORES FALTANTES =====\n",
    "print(\"\\n2. AN√ÅLISIS DE VALORES FALTANTES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "missing = df.isnull().sum()\n",
    "missing_pct = (missing / len(df)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Variable': missing.index,\n",
    "    'Valores_Faltantes': missing.values,\n",
    "    'Porcentaje': missing_pct.values\n",
    "}).sort_values('Valores_Faltantes', ascending=False)\n",
    "\n",
    "missing_df = missing_df[missing_df['Valores_Faltantes'] > 0]\n",
    "if len(missing_df) > 0:\n",
    "    print(\"\\nVariables con valores faltantes:\")\n",
    "    print(missing_df.to_string(index=False))\n",
    "    \n",
    "    # Visualizaci√≥n\n",
    "    fig = px.bar(missing_df, x='Variable', y='Porcentaje', \n",
    "                 title='Porcentaje de Valores Faltantes por Variable',\n",
    "                 labels={'Porcentaje': 'Porcentaje (%)'})\n",
    "    fig.write_html('eda/Valores_Faltantes.html')\n",
    "    print(\"‚úì Gr√°fico guardado en: eda/Valores_Faltantes.html\")\n",
    "else:\n",
    "    print(\"‚úì No hay valores faltantes\")\n",
    "\n",
    "missing_df.to_csv('eda/Valores_Faltantes.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# ===== 3. AN√ÅLISIS DE CORRELACIONES =====\n",
    "print(\"\\n3. AN√ÅLISIS DE CORRELACIONES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Seleccionar solo variables num√©ricas para correlaci√≥n\n",
    "corr_cols = [c for c in numeric_cols if c in df.columns]\n",
    "df_corr = df[corr_cols].corr()\n",
    "\n",
    "print(\"\\nMatriz de correlaci√≥n:\")\n",
    "print(df_corr.round(3))\n",
    "\n",
    "# Guardar matriz de correlaci√≥n\n",
    "df_corr.to_csv('eda/Matriz_Correlacion.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "print(\"\\n‚úì Matriz de correlaci√≥n guardada en: eda/Matriz_Correlacion.csv\")\n",
    "\n",
    "# Correlaciones con variable objetivo\n",
    "if 'VOLUMEN_ENTRADA_FINAL' in df_corr.columns:\n",
    "    target_corr = df_corr['VOLUMEN_ENTRADA_FINAL'].sort_values(ascending=False)\n",
    "    print(\"\\nCorrelaciones con VOLUMEN_ENTRADA_FINAL (variable objetivo):\")\n",
    "    for var, corr in target_corr.items():\n",
    "        if var != 'VOLUMEN_ENTRADA_FINAL':\n",
    "            print(f\"  {var}: {corr:.3f}\")\n",
    "            if abs(corr) > 0.7:\n",
    "                print(f\"    ‚úÖ CORRELACI√ìN FUERTE\")\n",
    "            elif abs(corr) > 0.5:\n",
    "                print(f\"    ‚ö† Correlaci√≥n moderada\")\n",
    "            elif abs(corr) > 0.3:\n",
    "                print(f\"    ‚ö† Correlaci√≥n d√©bil\")\n",
    "\n",
    "# Visualizaci√≥n de matriz de correlaci√≥n\n",
    "fig = px.imshow(df_corr, \n",
    "                title='Matriz de Correlaci√≥n entre Variables',\n",
    "                color_continuous_scale='RdBu',\n",
    "                aspect='auto',\n",
    "                labels=dict(color=\"Correlaci√≥n\"))\n",
    "fig.update_layout(height=600, width=800)\n",
    "fig.write_html('eda/Matriz_Correlacion_Visual.html')\n",
    "print(\"‚úì Gr√°fico de correlaci√≥n guardado en: eda/Matriz_Correlacion_Visual.html\")\n",
    "\n",
    "# ===== 4. DISTRIBUCIONES DE VARIABLES =====\n",
    "print(\"\\n4. AN√ÅLISIS DE DISTRIBUCIONES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Distribuciones de variables clave\n",
    "vars_principales = ['VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL', \n",
    "                    'PERDIDAS_FINAL', 'INDICE_PERDIDAS_FINAL',\n",
    "                    'PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL']\n",
    "\n",
    "for var in vars_principales:\n",
    "    if var in df.columns:\n",
    "        valores = df[var].dropna()\n",
    "        if len(valores) > 0:\n",
    "            print(f\"\\n{var}:\")\n",
    "            print(f\"  Media: {valores.mean():.2f}\")\n",
    "            print(f\"  Mediana: {valores.median():.2f}\")\n",
    "            print(f\"  Std: {valores.std():.2f}\")\n",
    "            print(f\"  Min: {valores.min():.2f}, Max: {valores.max():.2f}\")\n",
    "            print(f\"  Coeficiente de variaci√≥n: {(valores.std()/valores.mean()*100):.2f}%\")\n",
    "            \n",
    "            # Skewness\n",
    "            skew = valores.skew()\n",
    "            if abs(skew) > 1:\n",
    "                print(f\"  ‚ö† Distribuci√≥n muy asim√©trica (skew: {skew:.2f})\")\n",
    "            elif abs(skew) > 0.5:\n",
    "                print(f\"  ‚ö† Distribuci√≥n moderadamente asim√©trica (skew: {skew:.2f})\")\n",
    "            else:\n",
    "                print(f\"  ‚úì Distribuci√≥n aproximadamente normal (skew: {skew:.2f})\")\n",
    "\n",
    "# Visualizaci√≥n de distribuciones\n",
    "fig = make_subplots(\n",
    "    rows=3, cols=3,\n",
    "    subplot_titles=vars_principales[:9],\n",
    "    vertical_spacing=0.12\n",
    ")\n",
    "\n",
    "for i, var in enumerate(vars_principales[:9]):\n",
    "    if var in df.columns:\n",
    "        row = (i // 3) + 1\n",
    "        col = (i % 3) + 1\n",
    "        valores = df[var].dropna()\n",
    "        if len(valores) > 0:\n",
    "            fig.add_trace(\n",
    "                go.Histogram(x=valores, name=var, nbinsx=30),\n",
    "                row=row, col=col\n",
    "            )\n",
    "\n",
    "fig.update_layout(height=900, title_text=\"Distribuciones de Variables Principales\", showlegend=False)\n",
    "fig.write_html('eda/Distribuciones_Variables.html')\n",
    "print(\"\\n‚úì Gr√°ficos de distribuciones guardados en: eda/Distribuciones_Variables.html\")\n",
    "\n",
    "# ===== 5. AN√ÅLISIS DE OUTLIERS =====\n",
    "print(\"\\n5. AN√ÅLISIS DE OUTLIERS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "outliers_info = []\n",
    "\n",
    "for var in vars_principales:\n",
    "    if var in df.columns:\n",
    "        valores = df[var].dropna()\n",
    "        if len(valores) > 0:\n",
    "            Q1 = valores.quantile(0.25)\n",
    "            Q3 = valores.quantile(0.75)\n",
    "            IQR = Q3 - Q1\n",
    "            lower_bound = Q1 - 1.5 * IQR\n",
    "            upper_bound = Q3 + 1.5 * IQR\n",
    "            \n",
    "            outliers = valores[(valores < lower_bound) | (valores > upper_bound)]\n",
    "            n_outliers = len(outliers)\n",
    "            pct_outliers = (n_outliers / len(valores)) * 100\n",
    "            \n",
    "            outliers_info.append({\n",
    "                'Variable': var,\n",
    "                'Outliers': n_outliers,\n",
    "                'Porcentaje': pct_outliers,\n",
    "                'Lower_Bound': lower_bound,\n",
    "                'Upper_Bound': upper_bound\n",
    "            })\n",
    "            \n",
    "            if n_outliers > 0:\n",
    "                print(f\"\\n{var}:\")\n",
    "                print(f\"  Outliers detectados: {n_outliers} ({pct_outliers:.1f}%)\")\n",
    "                print(f\"  Rango normal: [{lower_bound:.2f}, {upper_bound:.2f}]\")\n",
    "                if pct_outliers > 10:\n",
    "                    print(f\"  ‚ö† ALTO porcentaje de outliers\")\n",
    "\n",
    "if len(outliers_info) > 0:\n",
    "    df_outliers = pd.DataFrame(outliers_info)\n",
    "    df_outliers.to_csv('eda/Analisis_Outliers.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(\"\\n‚úì An√°lisis de outliers guardado en: eda/Analisis_Outliers.csv\")\n",
    "\n",
    "# ===== 6. AN√ÅLISIS POR V√ÅLVULA =====\n",
    "print(\"\\n6. AN√ÅLISIS POR V√ÅLVULA\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'VALVULA' in df.columns:\n",
    "    print(\"\\nEstad√≠sticas por v√°lvula:\")\n",
    "    stats_valvula = df.groupby('VALVULA')[vars_principales].agg(['mean', 'std', 'count']).round(2)\n",
    "    print(stats_valvula)\n",
    "    \n",
    "    stats_valvula.to_csv('eda/Estadisticas_Por_Valvula.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    print(\"\\n‚úì Estad√≠sticas por v√°lvula guardadas en: eda/Estadisticas_Por_Valvula.csv\")\n",
    "    \n",
    "    # Visualizaci√≥n comparativa\n",
    "    if 'VOLUMEN_ENTRADA_FINAL' in df.columns:\n",
    "        fig = px.box(df, x='VALVULA', y='VOLUMEN_ENTRADA_FINAL',\n",
    "                    title='Distribuci√≥n de Volumen de Entrada por V√°lvula')\n",
    "        fig.write_html('eda/Boxplot_Entrada_Por_Valvula.html')\n",
    "        print(\"‚úì Boxplot guardado en: eda/Boxplot_Entrada_Por_Valvula.html\")\n",
    "\n",
    "# ===== 7. AN√ÅLISIS TEMPORAL =====\n",
    "print(\"\\n7. AN√ÅLISIS TEMPORAL\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if 'FECHA' in df.columns and 'VOLUMEN_ENTRADA_FINAL' in df.columns:\n",
    "    df_temp = df[df['FECHA'].notna()].copy()\n",
    "    if len(df_temp) > 0:\n",
    "        df_temp = df_temp.sort_values('FECHA')\n",
    "        \n",
    "        # Serie temporal de entrada\n",
    "        fig = px.line(df_temp, x='FECHA', y='VOLUMEN_ENTRADA_FINAL', \n",
    "                     color='VALVULA' if 'VALVULA' in df_temp.columns else None,\n",
    "                     title='Evoluci√≥n Temporal del Volumen de Entrada',\n",
    "                     labels={'VOLUMEN_ENTRADA_FINAL': 'Volumen Entrada (m¬≥)', 'FECHA': 'Fecha'})\n",
    "        fig.write_html('eda/Serie_Temporal_Entrada.html')\n",
    "        print(\"‚úì Serie temporal guardada en: eda/Serie_Temporal_Entrada.html\")\n",
    "        \n",
    "        # An√°lisis de tendencias\n",
    "        print(\"\\nTendencias por v√°lvula:\")\n",
    "        for v in df_temp['VALVULA'].unique() if 'VALVULA' in df_temp.columns else [None]:\n",
    "            df_v = df_temp[df_temp['VALVULA'] == v] if v else df_temp\n",
    "            if len(df_v) >= 3:\n",
    "                valores = df_v['VOLUMEN_ENTRADA_FINAL'].dropna()\n",
    "                if len(valores) >= 3:\n",
    "                    # Tendencia simple (√∫ltimo - primero)\n",
    "                    tendencia = valores.iloc[-1] - valores.iloc[0]\n",
    "                    pct_cambio = (tendencia / valores.iloc[0]) * 100 if valores.iloc[0] != 0 else 0\n",
    "                    if v:\n",
    "                        print(f\"  {v}: Cambio de {tendencia:.2f} ({pct_cambio:+.1f}%)\")\n",
    "\n",
    "# ===== 8. RELACIONES ENTRE VARIABLES =====\n",
    "print(\"\\n8. AN√ÅLISIS DE RELACIONES ENTRE VARIABLES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Scatter plots de relaciones importantes\n",
    "if 'VOLUMEN_ENTRADA_FINAL' in df.columns:\n",
    "    relaciones = [\n",
    "        ('VOLUMEN_SALIDA_FINAL', 'VOLUMEN_ENTRADA_FINAL'),\n",
    "        ('PRESION_FINAL', 'VOLUMEN_ENTRADA_FINAL'),\n",
    "        ('NUM_USUARIOS', 'VOLUMEN_ENTRADA_FINAL'),\n",
    "        ('TEMPERATURA_FINAL', 'VOLUMEN_ENTRADA_FINAL')\n",
    "    ]\n",
    "    \n",
    "    for var_x, var_y in relaciones:\n",
    "        if var_x in df.columns and var_y in df.columns:\n",
    "            df_plot = df[[var_x, var_y, 'VALVULA']].dropna() if 'VALVULA' in df.columns else df[[var_x, var_y]].dropna()\n",
    "            if len(df_plot) > 0:\n",
    "                fig = px.scatter(df_plot, x=var_x, y=var_y,\n",
    "                               color='VALVULA' if 'VALVULA' in df_plot.columns else None,\n",
    "                               title=f'Relaci√≥n: {var_x} vs {var_y}',\n",
    "                               trendline='ols' if len(df_plot) > 2 else None)\n",
    "                filename = f\"eda/Scatter_{var_x.replace('_', '')}_vs_{var_y.replace('_', '')}.html\"\n",
    "                fig.write_html(filename)\n",
    "                print(f\"‚úì Gr√°fico guardado: {filename}\")\n",
    "\n",
    "# ===== 9. RESUMEN DE INSIGHTS =====\n",
    "print(\"\\n9. RESUMEN DE INSIGHTS Y RECOMENDACIONES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "insights = []\n",
    "\n",
    "# Insight 1: Correlaciones fuertes\n",
    "if 'VOLUMEN_ENTRADA_FINAL' in df_corr.columns:\n",
    "    strong_corr = df_corr['VOLUMEN_ENTRADA_FINAL'].abs().sort_values(ascending=False)\n",
    "    strong_corr = strong_corr[(strong_corr > 0.5) & (strong_corr < 1.0)]\n",
    "    if len(strong_corr) > 0:\n",
    "        insights.append(f\"‚úÖ Variables fuertemente correlacionadas con VOLUMEN_ENTRADA_FINAL: {', '.join(strong_corr.index[:3].tolist())}\")\n",
    "    else:\n",
    "        insights.append(\"‚ö†Ô∏è No hay variables fuertemente correlacionadas con VOLUMEN_ENTRADA_FINAL\")\n",
    "\n",
    "# Insight 2: Valores faltantes\n",
    "if len(missing_df) > 0:\n",
    "    max_missing = missing_df.iloc[0]\n",
    "    insights.append(f\"‚ö†Ô∏è Variable con m√°s valores faltantes: {max_missing['Variable']} ({max_missing['Porcentaje']:.1f}%)\")\n",
    "\n",
    "# Insight 3: Outliers\n",
    "if len(outliers_info) > 0:\n",
    "    max_outliers = max(outliers_info, key=lambda x: x['Porcentaje'])\n",
    "    if max_outliers['Porcentaje'] > 10:\n",
    "        insights.append(f\"‚ö†Ô∏è Variable con muchos outliers: {max_outliers['Variable']} ({max_outliers['Porcentaje']:.1f}%)\")\n",
    "\n",
    "# Insight 4: Variabilidad\n",
    "if 'VOLUMEN_ENTRADA_FINAL' in df.columns:\n",
    "    cv = (df['VOLUMEN_ENTRADA_FINAL'].std() / df['VOLUMEN_ENTRADA_FINAL'].mean()) * 100\n",
    "    if cv > 50:\n",
    "        insights.append(f\"‚ö†Ô∏è Alta variabilidad en VOLUMEN_ENTRADA_FINAL (CV: {cv:.1f}%)\")\n",
    "    else:\n",
    "        insights.append(f\"‚úÖ Variabilidad moderada en VOLUMEN_ENTRADA_FINAL (CV: {cv:.1f}%)\")\n",
    "\n",
    "for i, insight in enumerate(insights, 1):\n",
    "    print(f\"{i}. {insight}\")\n",
    "\n",
    "# Guardar insights\n",
    "with open('eda/Insights_EDA.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(\"INSIGHTS DEL AN√ÅLISIS EXPLORATORIO DE DATOS\\n\")\n",
    "    f.write(\"=\" * 80 + \"\\n\\n\")\n",
    "    for i, insight in enumerate(insights, 1):\n",
    "        f.write(f\"{i}. {insight}\\n\")\n",
    "\n",
    "print(\"\\n‚úì Insights guardados en: eda/Insights_EDA.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"EDA COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüìÅ Archivos generados en carpeta 'eda/':\")\n",
    "print(\"   ‚Ä¢ Estadisticas_Descriptivas.csv\")\n",
    "print(\"   ‚Ä¢ Valores_Faltantes.csv\")\n",
    "print(\"   ‚Ä¢ Matriz_Correlacion.csv\")\n",
    "print(\"   ‚Ä¢ Analisis_Outliers.csv\")\n",
    "print(\"   ‚Ä¢ Estadisticas_Por_Valvula.csv\")\n",
    "print(\"   ‚Ä¢ Insights_EDA.txt\")\n",
    "print(\"   ‚Ä¢ Gr√°ficos HTML interactivos\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenamiento y Pron√≥stico\n",
    "\n",
    "En esta secci√≥n se entrenan modelos base por v√°lvula y se generan pron√≥sticos de `VOLUMEN_ENTRADA_FINAL` para los periodos con `PERIODO_A_PREDECIR = True` en `Dataset_Prediccion.csv`.\n",
    "\n",
    "- Modelos: Prophet (serie por v√°lvula) y LightGBM (features agregadas).\n",
    "- Salidas: `Pronosticos.csv` y `Predicciones_Con_Balance.csv` con p√©rdidas e √≠ndice recalculados.\n",
    "- M√©tricas: MAE, MAPE, RMSE por v√°lvula en validaci√≥n temporal simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SERIALIZACI√ìN DE MODELOS PARA PRODUCCI√ìN\n",
      "================================================================================\n",
      "\n",
      "Cargando datos...\n",
      "\n",
      "Reentrenando y guardando modelos...\n",
      "\n",
      "Procesando 5 v√°lvulas...\n",
      "\n",
      "Procesando VALVULA_1...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:35 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:29:38 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Prophet entrenado\n",
      "  ‚úì LightGBM entrenado\n",
      "  ‚úì RandomForest entrenado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:40 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì CatBoost entrenado\n",
      "Procesando VALVULA_2...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:45 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Prophet entrenado\n",
      "  ‚úì LightGBM entrenado\n",
      "  ‚úì RandomForest entrenado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:45 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì CatBoost entrenado\n",
      "Procesando VALVULA_3...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:46 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Prophet entrenado\n",
      "  ‚úì LightGBM entrenado\n",
      "  ‚úì RandomForest entrenado\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:46 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì CatBoost entrenado\n",
      "Procesando VALVULA_4...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:48 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ‚úì Prophet entrenado\n",
      "  ‚úì LightGBM entrenado\n",
      "  ‚úì RandomForest entrenado\n",
      "  ‚úì CatBoost entrenado\n",
      "Procesando VALVULA_5...\n",
      "\n",
      "Modelos entrenados para 5 v√°lvulas\n",
      "\n",
      "Procesando VALVULA_1...\n",
      "  ‚úì Prophet guardado: modelos/VALVULA_1_prophet.pkl\n",
      "  ‚úì LightGBM guardado: modelos/VALVULA_1_lightgbm.pkl\n",
      "  ‚úì RandomForest guardado: modelos/VALVULA_1_randomforest.pkl\n",
      "  ‚úì CatBoost guardado: modelos/VALVULA_1_catboost.pkl y .cbm\n",
      "Procesando VALVULA_2...\n",
      "  ‚úì Prophet guardado: modelos/VALVULA_2_prophet.pkl\n",
      "  ‚úì LightGBM guardado: modelos/VALVULA_2_lightgbm.pkl\n",
      "  ‚úì RandomForest guardado: modelos/VALVULA_2_randomforest.pkl\n",
      "  ‚úì CatBoost guardado: modelos/VALVULA_2_catboost.pkl y .cbm\n",
      "Procesando VALVULA_3...\n",
      "  ‚úì Prophet guardado: modelos/VALVULA_3_prophet.pkl\n",
      "  ‚úì LightGBM guardado: modelos/VALVULA_3_lightgbm.pkl\n",
      "  ‚úì RandomForest guardado: modelos/VALVULA_3_randomforest.pkl\n",
      "  ‚úì CatBoost guardado: modelos/VALVULA_3_catboost.pkl y .cbm\n",
      "Procesando VALVULA_4...\n",
      "  ‚úì Prophet guardado: modelos/VALVULA_4_prophet.pkl\n",
      "  ‚úì LightGBM guardado: modelos/VALVULA_4_lightgbm.pkl\n",
      "  ‚úì RandomForest guardado: modelos/VALVULA_4_randomforest.pkl\n",
      "  ‚úì CatBoost guardado: modelos/VALVULA_4_catboost.pkl y .cbm\n",
      "Procesando VALVULA_5...\n",
      "\n",
      "‚úì Metadata guardada en JSON: modelos/metadata_modelos.json\n",
      "\n",
      "‚úì Metadata guardada en: modelos/metadata_modelos.pkl\n",
      "‚úì Script de carga creado: modelos/cargar_modelos.py\n",
      "\n",
      "================================================================================\n",
      "RESUMEN DE SERIALIZACI√ìN\n",
      "================================================================================\n",
      "\n",
      "Modelos serializados para 5 v√°lvulas:\n",
      "\n",
      "  VALVULA_1:\n",
      "    Modelos: prophet, lightgbm, randomforest, catboost\n",
      "    Archivos generados:\n",
      "      - modelos/VALVULA_1_prophet.pkl\n",
      "      - modelos/VALVULA_1_lightgbm.pkl\n",
      "      - modelos/VALVULA_1_randomforest.pkl\n",
      "      - modelos/VALVULA_1_catboost.pkl\n",
      "      - modelos/VALVULA_1_catboost.cbm\n",
      "\n",
      "  VALVULA_2:\n",
      "    Modelos: prophet, lightgbm, randomforest, catboost\n",
      "    Archivos generados:\n",
      "      - modelos/VALVULA_2_prophet.pkl\n",
      "      - modelos/VALVULA_2_lightgbm.pkl\n",
      "      - modelos/VALVULA_2_randomforest.pkl\n",
      "      - modelos/VALVULA_2_catboost.pkl\n",
      "      - modelos/VALVULA_2_catboost.cbm\n",
      "\n",
      "  VALVULA_3:\n",
      "    Modelos: prophet, lightgbm, randomforest, catboost\n",
      "    Archivos generados:\n",
      "      - modelos/VALVULA_3_prophet.pkl\n",
      "      - modelos/VALVULA_3_lightgbm.pkl\n",
      "      - modelos/VALVULA_3_randomforest.pkl\n",
      "      - modelos/VALVULA_3_catboost.pkl\n",
      "      - modelos/VALVULA_3_catboost.cbm\n",
      "\n",
      "  VALVULA_4:\n",
      "    Modelos: prophet, lightgbm, randomforest, catboost\n",
      "    Archivos generados:\n",
      "      - modelos/VALVULA_4_prophet.pkl\n",
      "      - modelos/VALVULA_4_lightgbm.pkl\n",
      "      - modelos/VALVULA_4_randomforest.pkl\n",
      "      - modelos/VALVULA_4_catboost.pkl\n",
      "      - modelos/VALVULA_4_catboost.cbm\n",
      "\n",
      "  VALVULA_5:\n",
      "    Modelos: \n",
      "    Archivos generados:\n",
      "\n",
      "‚úì Archivos generados:\n",
      "   ‚Ä¢ modelos/metadata_modelos.pkl - Metadata de modelos\n",
      "   ‚Ä¢ modelos/metadata_modelos.json - Metadata en JSON\n",
      "   ‚Ä¢ modelos/cargar_modelos.py - Script para cargar modelos\n",
      "   ‚Ä¢ modelos/{VALVULA}_{MODELO}.pkl - Modelos serializados\n",
      "\n",
      "================================================================================\n",
      "SERIALIZACI√ìN COMPLETADA\n",
      "================================================================================\n",
      "\n",
      "üí° Para usar en producci√≥n:\n",
      "   1. Copiar carpeta 'modelos/' al servidor/frontend\n",
      "   2. Instalar dependencias: pandas, numpy, prophet, lightgbm, scikit-learn, catboost\n",
      "   3. Usar script: from modelos.cargar_modelos import cargar_modelos, predecir_entrada\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# SERIALIZACI√ìN DE MODELOS PARA PRODUCCI√ìN (PKL/JOBLIB)\n",
    "# ============================================================================\n",
    "import pickle\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SERIALIZACI√ìN DE MODELOS PARA PRODUCCI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar datos necesarios\n",
    "print(\"\\nCargando datos...\")\n",
    "df_train = pd.read_csv('Dataset_Train.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df_pred = pd.read_csv('Dataset_Prediccion.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','PRESION_FINAL','TEMPERATURA_FINAL','KPT_FINAL','NUM_USUARIOS','NUM_REGISTROS']:\n",
    "    if col in df_train.columns:\n",
    "        df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "df_train['FECHA'] = pd.to_datetime(df_train['FECHA'], errors='coerce')\n",
    "\n",
    "# Funci√≥n para crear features (misma que en entrenamiento)\n",
    "def crear_features_mejoradas(df, hist_v=None):\n",
    "    df = df.copy()\n",
    "    feat_cols = []\n",
    "    for c in ['PRESION_FINAL','TEMPERATURA_FINAL','KPT_FINAL','NUM_USUARIOS','NUM_REGISTROS','VOLUMEN_SALIDA_FINAL']:\n",
    "        if c in df.columns:\n",
    "            feat_cols.append(c)\n",
    "    if 'FECHA' in df.columns:\n",
    "        df['MES'] = df['FECHA'].dt.month\n",
    "        df['A√ëO'] = df['FECHA'].dt.year\n",
    "        df['DIA_A√ëO'] = df['FECHA'].dt.dayofyear\n",
    "        feat_cols.extend(['MES', 'A√ëO', 'DIA_A√ëO'])\n",
    "    if hist_v is not None and len(hist_v) > 0:\n",
    "        hist_v = hist_v.sort_values('FECHA')\n",
    "        if 'VOLUMEN_ENTRADA_FINAL' in hist_v.columns:\n",
    "            valores = hist_v['VOLUMEN_ENTRADA_FINAL'].dropna().values\n",
    "            if len(valores) > 0:\n",
    "                df['LAG_1'] = valores[-1] if len(valores) >= 1 else np.nan\n",
    "                df['MA_3'] = np.mean(valores[-3:]) if len(valores) >= 3 else np.mean(valores) if len(valores) > 0 else np.nan\n",
    "                df['MA_6'] = np.mean(valores[-6:]) if len(valores) >= 6 else np.mean(valores) if len(valores) > 0 else np.nan\n",
    "                feat_cols.extend(['LAG_1', 'MA_3', 'MA_6'])\n",
    "    if 'PRESION_FINAL' in df.columns and 'TEMPERATURA_FINAL' in df.columns:\n",
    "        df['PRESION_TEMP'] = df['PRESION_FINAL'] * df['TEMPERATURA_FINAL']\n",
    "        feat_cols.append('PRESION_TEMP')\n",
    "    if 'VOLUMEN_SALIDA_FINAL' in df.columns and 'NUM_USUARIOS' in df.columns:\n",
    "        df['CONSUMO_POR_USUARIO'] = df['VOLUMEN_SALIDA_FINAL'] / (df['NUM_USUARIOS'] + 1)\n",
    "        feat_cols.append('CONSUMO_POR_USUARIO')\n",
    "    return df, feat_cols\n",
    "\n",
    "# Reentrenar y guardar modelos\n",
    "print(\"\\nReentrenando y guardando modelos...\")\n",
    "valvulas = sorted(df_train['VALVULA'].dropna().unique())\n",
    "modelos_entrenados = {}\n",
    "metadata_modelos = {}\n",
    "\n",
    "# Crear directorio para modelos\n",
    "os.makedirs('modelos', exist_ok=True)\n",
    "\n",
    "print(f\"\\nProcesando {len(valvulas)} v√°lvulas...\\n\")\n",
    "\n",
    "for v in valvulas:\n",
    "    print(f\"Procesando {v}...\")\n",
    "    hist_v = df_train[(df_train['VALVULA']==v) & (df_train['VOLUMEN_ENTRADA_FINAL'].notna())].copy()\n",
    "    if hist_v.empty:\n",
    "        continue\n",
    "    \n",
    "    hist_v = hist_v.sort_values('FECHA')\n",
    "    n_hist = len(hist_v)\n",
    "    modelos_v = {}\n",
    "    metadata_v = {\n",
    "        'valvula': v,\n",
    "        'modelos_disponibles': [],\n",
    "        'features_por_modelo': {},\n",
    "        'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Entrenar y guardar Prophet\n",
    "    if n_hist >= 6:\n",
    "        try:\n",
    "            dfp = hist_v[['FECHA','VOLUMEN_ENTRADA_FINAL']].rename(columns={'FECHA':'ds','VOLUMEN_ENTRADA_FINAL':'y'})\n",
    "            m_prophet = Prophet(seasonality_mode='multiplicative', yearly_seasonality=True, \n",
    "                              weekly_seasonality=False, daily_seasonality=False)\n",
    "            m_prophet.fit(dfp)\n",
    "            modelos_v['prophet'] = m_prophet\n",
    "            metadata_v['modelos_disponibles'].append('prophet')\n",
    "            print(f\"  ‚úì Prophet entrenado\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† Prophet error: {str(e)[:50]}\")\n",
    "    \n",
    "    # Preparar features\n",
    "    hist_v_feat, feat_cols = crear_features_mejoradas(hist_v)\n",
    "    feat_cols = [c for c in feat_cols if c in hist_v_feat.columns]\n",
    "    feat_cols = [c for c in feat_cols if hist_v_feat[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "    \n",
    "    if len(feat_cols) > 0 and n_hist >= 6:\n",
    "        X = hist_v_feat[feat_cols].fillna(method='ffill').fillna(0)\n",
    "        y = hist_v['VOLUMEN_ENTRADA_FINAL'].values\n",
    "        \n",
    "        # LightGBM\n",
    "        try:\n",
    "            model_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.05, \n",
    "                                       subsample=0.9, colsample_bytree=0.8, \n",
    "                                       random_state=42, verbose=-1)\n",
    "            model_lgbm.fit(X, y)\n",
    "            modelos_v['lightgbm'] = model_lgbm\n",
    "            modelos_v['lightgbm_features'] = feat_cols.copy()\n",
    "            metadata_v['modelos_disponibles'].append('lightgbm')\n",
    "            metadata_v['features_por_modelo']['lightgbm'] = feat_cols.copy()\n",
    "            print(f\"  ‚úì LightGBM entrenado\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† LightGBM error: {str(e)[:50]}\")\n",
    "        \n",
    "        # Random Forest\n",
    "        try:\n",
    "            model_rf = RandomForestRegressor(n_estimators=100, max_depth=10, \n",
    "                                            min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "            model_rf.fit(X, y)\n",
    "            modelos_v['randomforest'] = model_rf\n",
    "            modelos_v['randomforest_features'] = feat_cols.copy()\n",
    "            metadata_v['modelos_disponibles'].append('randomforest')\n",
    "            metadata_v['features_por_modelo']['randomforest'] = feat_cols.copy()\n",
    "            print(f\"  ‚úì RandomForest entrenado\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† RandomForest error: {str(e)[:50]}\")\n",
    "        \n",
    "        # CatBoost\n",
    "        try:\n",
    "            model_cat = CatBoostRegressor(iterations=100, learning_rate=0.05, \n",
    "                                         depth=6, random_state=42, verbose=False)\n",
    "            model_cat.fit(X, y)\n",
    "            modelos_v['catboost'] = model_cat\n",
    "            modelos_v['catboost_features'] = feat_cols.copy()\n",
    "            metadata_v['modelos_disponibles'].append('catboost')\n",
    "            metadata_v['features_por_modelo']['catboost'] = feat_cols.copy()\n",
    "            print(f\"  ‚úì CatBoost entrenado\")\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† CatBoost error: {str(e)[:50]}\")\n",
    "    \n",
    "    modelos_entrenados[v] = modelos_v\n",
    "    metadata_modelos[v] = metadata_v\n",
    "\n",
    "print(f\"\\nModelos entrenados para {len(modelos_entrenados)} v√°lvulas\\n\")\n",
    "\n",
    "for valvula, modelos_v in modelos_entrenados.items():\n",
    "    print(f\"Procesando {valvula}...\")\n",
    "    metadata_v = {\n",
    "        'valvula': valvula,\n",
    "        'modelos_disponibles': [],\n",
    "        'features_por_modelo': {},\n",
    "        'fecha_entrenamiento': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    }\n",
    "    \n",
    "    # Serializar cada modelo\n",
    "    for modelo_nombre, modelo_obj in modelos_v.items():\n",
    "        if modelo_nombre.endswith('_features') or modelo_nombre.endswith('_seq_length'):\n",
    "            continue  # Saltar metadata, se guarda aparte\n",
    "            \n",
    "        try:\n",
    "            # Determinar nombre del archivo\n",
    "            if modelo_nombre == 'prophet':\n",
    "                filename = f'modelos/{valvula}_prophet.pkl'\n",
    "                # Prophet se guarda mejor con pickle\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(modelo_obj, f)\n",
    "                metadata_v['modelos_disponibles'].append('prophet')\n",
    "                if f'{valvula}_prophet_features' in modelos_v:\n",
    "                    metadata_v['features_por_modelo']['prophet'] = modelos_v[f'{valvula}_prophet_features']\n",
    "                print(f\"  ‚úì Prophet guardado: {filename}\")\n",
    "                \n",
    "            elif modelo_nombre == 'lightgbm':\n",
    "                filename = f'modelos/{valvula}_lightgbm.pkl'\n",
    "                # LightGBM puede usar joblib o pickle\n",
    "                joblib.dump(modelo_obj, filename)\n",
    "                metadata_v['modelos_disponibles'].append('lightgbm')\n",
    "                if f'{valvula}_lightgbm_features' in modelos_v:\n",
    "                    metadata_v['features_por_modelo']['lightgbm'] = modelos_v[f'{valvula}_lightgbm_features']\n",
    "                print(f\"  ‚úì LightGBM guardado: {filename}\")\n",
    "                \n",
    "            elif modelo_nombre == 'randomforest':\n",
    "                filename = f'modelos/{valvula}_randomforest.pkl'\n",
    "                joblib.dump(modelo_obj, filename)\n",
    "                metadata_v['modelos_disponibles'].append('randomforest')\n",
    "                if f'{valvula}_randomforest_features' in modelos_v:\n",
    "                    metadata_v['features_por_modelo']['randomforest'] = modelos_v[f'{valvula}_randomforest_features']\n",
    "                print(f\"  ‚úì RandomForest guardado: {filename}\")\n",
    "                \n",
    "            elif modelo_nombre == 'catboost':\n",
    "                filename = f'modelos/{valvula}_catboost.pkl'\n",
    "                # CatBoost tiene su propio m√©todo de guardado\n",
    "                modelo_obj.save_model(f'modelos/{valvula}_catboost.cbm')\n",
    "                # Tambi√©n guardar con joblib para compatibilidad\n",
    "                joblib.dump(modelo_obj, filename)\n",
    "                metadata_v['modelos_disponibles'].append('catboost')\n",
    "                if f'{valvula}_catboost_features' in modelos_v:\n",
    "                    metadata_v['features_por_modelo']['catboost'] = modelos_v[f'{valvula}_catboost_features']\n",
    "                print(f\"  ‚úì CatBoost guardado: {filename} y .cbm\")\n",
    "                \n",
    "            elif modelo_nombre == 'hybrid_prophet':\n",
    "                filename = f'modelos/{valvula}_hybrid_prophet.pkl'\n",
    "                with open(filename, 'wb') as f:\n",
    "                    pickle.dump(modelo_obj, f)\n",
    "                metadata_v['modelos_disponibles'].append('hybrid_prophet')\n",
    "                print(f\"  ‚úì Hybrid Prophet guardado: {filename}\")\n",
    "                \n",
    "            elif modelo_nombre == 'hybrid_lstm':\n",
    "                filename = f'modelos/{valvula}_hybrid_lstm.h5'\n",
    "                # Guardar modelo Keras/TensorFlow\n",
    "                modelo_obj.save(filename)\n",
    "                metadata_v['modelos_disponibles'].append('hybrid_lstm')\n",
    "                if f'{valvula}_hybrid_seq_length' in modelos_v:\n",
    "                    metadata_v['hybrid_seq_length'] = modelos_v[f'{valvula}_hybrid_seq_length']\n",
    "                print(f\"  ‚úì Hybrid LSTM guardado: {filename}\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ö† Error guardando {modelo_nombre}: {str(e)[:50]}\")\n",
    "    \n",
    "    metadata_modelos[valvula] = metadata_v\n",
    "\n",
    "# Guardar metadata de modelos\n",
    "with open('modelos/metadata_modelos.pkl', 'wb') as f:\n",
    "    pickle.dump(metadata_modelos, f)\n",
    "\n",
    "# Tambi√©n guardar metadata en JSON legible (si es posible)\n",
    "try:\n",
    "    import json\n",
    "    metadata_json = {}\n",
    "    for v, meta in metadata_modelos.items():\n",
    "        metadata_json[v] = {\n",
    "            'valvula': meta['valvula'],\n",
    "            'modelos_disponibles': meta['modelos_disponibles'],\n",
    "            'features_por_modelo': {k: list(v) if isinstance(v, list) else v \n",
    "                                   for k, v in meta['features_por_modelo'].items()},\n",
    "            'fecha_entrenamiento': meta['fecha_entrenamiento']\n",
    "        }\n",
    "    with open('modelos/metadata_modelos.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(metadata_json, f, indent=2, ensure_ascii=False)\n",
    "    print(\"\\n‚úì Metadata guardada en JSON: modelos/metadata_modelos.json\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö† No se pudo guardar metadata en JSON: {e}\")\n",
    "\n",
    "print(f\"\\n‚úì Metadata guardada en: modelos/metadata_modelos.pkl\")\n",
    "\n",
    "# Crear script de carga para uso en producci√≥n\n",
    "script_carga = '''\"\"\"\n",
    "Script para cargar y usar modelos en producci√≥n\n",
    "\"\"\"\n",
    "import pickle\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from catboost import CatBoostRegressor\n",
    "\n",
    "def cargar_modelos(valvula):\n",
    "    \"\"\"\n",
    "    Carga todos los modelos entrenados para una v√°lvula\n",
    "    \n",
    "    Args:\n",
    "        valvula: Nombre de la v√°lvula (ej: 'VALVULA_1')\n",
    "    \n",
    "    Returns:\n",
    "        dict: Diccionario con modelos y metadata\n",
    "    \"\"\"\n",
    "    # Cargar metadata\n",
    "    with open('modelos/metadata_modelos.pkl', 'rb') as f:\n",
    "        metadata = pickle.load(f)\n",
    "    \n",
    "    if valvula not in metadata:\n",
    "        raise ValueError(f\"V√°lvula {valvula} no encontrada en modelos\")\n",
    "    \n",
    "    modelos = {}\n",
    "    meta_v = metadata[valvula]\n",
    "    \n",
    "    # Cargar cada modelo disponible\n",
    "    for modelo_nombre in meta_v['modelos_disponibles']:\n",
    "        try:\n",
    "            if modelo_nombre == 'prophet':\n",
    "                with open(f'modelos/{valvula}_prophet.pkl', 'rb') as f:\n",
    "                    modelos['prophet'] = pickle.load(f)\n",
    "            elif modelo_nombre == 'lightgbm':\n",
    "                modelos['lightgbm'] = joblib.load(f'modelos/{valvula}_lightgbm.pkl')\n",
    "            elif modelo_nombre == 'randomforest':\n",
    "                modelos['randomforest'] = joblib.load(f'modelos/{valvula}_randomforest.pkl')\n",
    "            elif modelo_nombre == 'catboost':\n",
    "                # Intentar cargar .cbm primero (m√°s eficiente)\n",
    "                try:\n",
    "                    modelos['catboost'] = CatBoostRegressor()\n",
    "                    modelos['catboost'].load_model(f'modelos/{valvula}_catboost.cbm')\n",
    "                except:\n",
    "                    modelos['catboost'] = joblib.load(f'modelos/{valvula}_catboost.pkl')\n",
    "            elif modelo_nombre == 'hybrid_prophet':\n",
    "                with open(f'modelos/{valvula}_hybrid_prophet.pkl', 'rb') as f:\n",
    "                    modelos['hybrid_prophet'] = pickle.load(f)\n",
    "            elif modelo_nombre == 'hybrid_lstm':\n",
    "                from tensorflow.keras.models import load_model\n",
    "                modelos['hybrid_lstm'] = load_model(f'modelos/{valvula}_hybrid_lstm.h5')\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö† Error cargando {modelo_nombre}: {e}\")\n",
    "    \n",
    "    return {\n",
    "        'modelos': modelos,\n",
    "        'metadata': meta_v\n",
    "    }\n",
    "\n",
    "def predecir_entrada(valvula, features_dict, fecha=None):\n",
    "    \"\"\"\n",
    "    Hace predicci√≥n usando el ensemble de modelos\n",
    "    \n",
    "    Args:\n",
    "        valvula: Nombre de la v√°lvula\n",
    "        features_dict: Diccionario con features necesarias\n",
    "        fecha: Fecha para predicci√≥n (requerida para Prophet)\n",
    "    \n",
    "    Returns:\n",
    "        float: Predicci√≥n de volumen de entrada\n",
    "    \"\"\"\n",
    "    modelos_data = cargar_modelos(valvula)\n",
    "    modelos = modelos_data['modelos']\n",
    "    metadata = modelos_data['metadata']\n",
    "    \n",
    "    predicciones = []\n",
    "    pesos = []\n",
    "    \n",
    "    # Prophet\n",
    "    if 'prophet' in modelos and fecha is not None:\n",
    "        try:\n",
    "            future = pd.DataFrame({'ds': [pd.to_datetime(fecha)]})\n",
    "            pred = modelos['prophet'].predict(future)['yhat'].values[0]\n",
    "            predicciones.append(pred)\n",
    "            pesos.append(0.2)  # Peso por defecto\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    # Modelos basados en features\n",
    "    for modelo_nombre in ['lightgbm', 'randomforest', 'catboost']:\n",
    "        if modelo_nombre in modelos:\n",
    "            try:\n",
    "                feat_cols = metadata['features_por_modelo'].get(modelo_nombre, [])\n",
    "                if feat_cols:\n",
    "                    X = pd.DataFrame([features_dict])[feat_cols].fillna(0)\n",
    "                    pred = modelos[modelo_nombre].predict(X)[0]\n",
    "                    predicciones.append(pred)\n",
    "                    # Peso basado en modelo (ajustar seg√∫n m√©tricas)\n",
    "                    pesos_default = {'lightgbm': 0.25, 'randomforest': 0.25, 'catboost': 0.3}\n",
    "                    pesos.append(pesos_default.get(modelo_nombre, 0.2))\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Error en predicci√≥n {modelo_nombre}: {e}\")\n",
    "    \n",
    "    # Ensemble\n",
    "    if len(predicciones) > 0:\n",
    "        pesos = np.array(pesos) / np.sum(pesos)\n",
    "        return np.average(predicciones, weights=pesos)\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "# Ejemplo de uso:\n",
    "# modelos_data = cargar_modelos('VALVULA_1')\n",
    "# pred = predecir_entrada('VALVULA_1', {'PRESION_FINAL': 10.5, 'TEMPERATURA_FINAL': 25.0, ...}, fecha='2025-08-01')\n",
    "'''\n",
    "\n",
    "with open('modelos/cargar_modelos.py', 'w', encoding='utf-8') as f:\n",
    "    f.write(script_carga)\n",
    "\n",
    "print(\"‚úì Script de carga creado: modelos/cargar_modelos.py\")\n",
    "\n",
    "# Resumen\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"RESUMEN DE SERIALIZACI√ìN\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nModelos serializados para {len(metadata_modelos)} v√°lvulas:\")\n",
    "for v, meta in metadata_modelos.items():\n",
    "    print(f\"\\n  {v}:\")\n",
    "    print(f\"    Modelos: {', '.join(meta['modelos_disponibles'])}\")\n",
    "    print(f\"    Archivos generados:\")\n",
    "    for modelo in meta['modelos_disponibles']:\n",
    "        if modelo == 'catboost':\n",
    "            print(f\"      - modelos/{v}_catboost.pkl\")\n",
    "            print(f\"      - modelos/{v}_catboost.cbm\")\n",
    "        elif modelo == 'hybrid_lstm':\n",
    "            print(f\"      - modelos/{v}_hybrid_lstm.h5\")\n",
    "        else:\n",
    "            print(f\"      - modelos/{v}_{modelo}.pkl\")\n",
    "\n",
    "print(\"\\n‚úì Archivos generados:\")\n",
    "print(\"   ‚Ä¢ modelos/metadata_modelos.pkl - Metadata de modelos\")\n",
    "print(\"   ‚Ä¢ modelos/metadata_modelos.json - Metadata en JSON\")\n",
    "print(\"   ‚Ä¢ modelos/cargar_modelos.py - Script para cargar modelos\")\n",
    "print(\"   ‚Ä¢ modelos/{VALVULA}_{MODELO}.pkl - Modelos serializados\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SERIALIZACI√ìN COMPLETADA\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nüí° Para usar en producci√≥n:\")\n",
    "print(\"   1. Copiar carpeta 'modelos/' al servidor/frontend\")\n",
    "print(\"   2. Instalar dependencias: pandas, numpy, prophet, lightgbm, scikit-learn, catboost\")\n",
    "print(\"   3. Usar script: from modelos.cargar_modelos import cargar_modelos, predecir_entrada\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:49 - cmdstanpy - INFO - Chain [1] start processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ö† TensorFlow no disponible, LSTM deshabilitado\n",
      "================================================================================\n",
      "ENTRENAMIENTO MEJORADO: M√öLTIPLES MODELOS POR V√ÅLVULA\n",
      "================================================================================\n",
      "Modelos: Prophet, LightGBM, Random Forest, CatBoost, Prophet+LSTM (h√≠brido)\n",
      "\n",
      "V√°lvulas para procesar: 5 -> ['VALVULA_1', 'VALVULA_2', 'VALVULA_3', 'VALVULA_4', 'VALVULA_5']\n",
      "\n",
      "================================================================================\n",
      "Procesando VALVULA_1: hist=7, pred=4\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:52 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prophet OK\n",
      "‚úì Features disponibles: 11 -> ['PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']...\n",
      "  LightGBM test -> MAE: 106.21, RMSE: 112.32, MAPE: 23.82%\n",
      "‚úì LightGBM OK\n",
      "  RandomForest test -> MAE: 122.28, RMSE: 153.28, MAPE: 26.45%\n",
      "‚úì Random Forest OK\n",
      "  CatBoost test -> MAE: 71.41, RMSE: 94.80, MAPE: 15.29%\n",
      "‚úì CatBoost OK\n",
      "‚úì Ensemble: 3 modelos (pesos: CATBOOST: 44.32%, RF: 25.88%, LGBM: 29.80%)\n",
      "‚úì Pron√≥sticos agregados: 4 filas\n",
      "\n",
      "================================================================================\n",
      "Procesando VALVULA_2: hist=8, pred=11\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:53 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:29:57 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prophet OK\n",
      "‚úì Features disponibles: 11 -> ['PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']...\n",
      "  LightGBM test -> MAE: 323.74, RMSE: 337.76, MAPE: 18.04%\n",
      "‚úì LightGBM OK\n",
      "  RandomForest test -> MAE: 438.66, RMSE: 463.96, MAPE: 24.50%\n",
      "‚úì Random Forest OK\n",
      "  CatBoost test -> MAE: 401.64, RMSE: 417.07, MAPE: 22.36%\n",
      "‚úì CatBoost OK\n",
      "‚úì Ensemble: 3 modelos (pesos: CATBOOST: 31.68%, RF: 29.01%, LGBM: 39.31%)\n",
      "‚úì Pron√≥sticos agregados: 11 filas\n",
      "\n",
      "================================================================================\n",
      "Procesando VALVULA_3: hist=7, pred=5\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:57 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:29:58 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prophet OK\n",
      "‚úì Features disponibles: 11 -> ['PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']...\n",
      "  LightGBM test -> MAE: 4448.63, RMSE: 4457.67, MAPE: 15.71%\n",
      "‚úì LightGBM OK\n",
      "  RandomForest test -> MAE: 1090.91, RMSE: 1125.07, MAPE: 3.87%\n",
      "‚úì Random Forest OK\n",
      "  CatBoost test -> MAE: 2192.96, RMSE: 2258.65, MAPE: 7.73%\n",
      "‚úì CatBoost OK\n",
      "‚úì Ensemble: 3 modelos (pesos: CATBOOST: 28.55%, RF: 57.38%, LGBM: 14.07%)\n",
      "‚úì Pron√≥sticos agregados: 5 filas\n",
      "\n",
      "================================================================================\n",
      "Procesando VALVULA_4: hist=6, pred=12\n",
      "================================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:29:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "23:30:01 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Prophet OK\n",
      "‚úì Features disponibles: 11 -> ['PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']...\n",
      "  LightGBM test -> MAE: 5758.28, RMSE: 6160.97, MAPE: 18.51%\n",
      "‚úì LightGBM OK\n",
      "  RandomForest test -> MAE: 4739.57, RMSE: 5555.82, MAPE: 14.98%\n",
      "‚úì Random Forest OK\n",
      "  CatBoost test -> MAE: 3602.33, RMSE: 4335.42, MAPE: 11.33%\n",
      "‚úì CatBoost OK\n",
      "‚úì Ensemble: 3 modelos (pesos: CATBOOST: 41.92%, RF: 31.86%, LGBM: 26.22%)\n",
      "‚úì Pron√≥sticos agregados: 12 filas\n",
      "\n",
      "================================================================================\n",
      "Procesando VALVULA_5: hist=4, pred=13\n",
      "================================================================================\n",
      "‚ö† Prophet: pocos datos, usando fallback\n",
      "‚úì Features disponibles: 11 -> ['PRESION_FINAL', 'TEMPERATURA_FINAL', 'KPT_FINAL', 'NUM_USUARIOS', 'NUM_REGISTROS']...\n",
      "‚úì Ensemble: 1 modelos (pesos: PROPHET: 100.00%)\n",
      "‚úì Pron√≥sticos agregados: 13 filas\n",
      "\n",
      "\n",
      "================================================================================\n",
      "RESUMEN FINAL\n",
      "================================================================================\n",
      "Total bloques de pron√≥sticos: 5\n",
      "‚úì Pron√≥sticos guardados: Pronosticos.csv ((45, 13))\n",
      "\n",
      "Predicciones disponibles por modelo:\n",
      "  PRED_ENTRADA_PROPHET: 45/45 (100.0%)\n",
      "  PRED_ENTRADA_LGBM: 32/45 (71.1%)\n",
      "  PRED_ENTRADA_RF: 32/45 (71.1%)\n",
      "  PRED_ENTRADA_CATBOOST: 32/45 (71.1%)\n",
      "  PRED_ENTRADA_HYBRID: 0/45 (0.0%)\n",
      "\n",
      "‚úì M√©tricas guardadas: Metrics.csv ((12, 7))\n",
      "\n",
      "Resumen de m√©tricas por modelo:\n",
      "                  MAE     RMSE   MAPE\n",
      "MODELO                               \n",
      "CatBoost      1567.08  1776.49  14.18\n",
      "LightGBM      2659.22  2767.18  19.02\n",
      "RandomForest  1597.86  1824.53  17.45\n",
      "\n",
      "Mejores modelos por v√°lvula:\n",
      "  VALVULA_1: CatBoost (MAE: 71.41)\n",
      "  VALVULA_2: LightGBM (MAE: 323.74)\n",
      "  VALVULA_3: RandomForest (MAE: 1090.91)\n",
      "  VALVULA_4: CatBoost (MAE: 3602.33)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from prophet import Prophet\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Intentar importar TensorFlow/Keras para LSTM (opcional)\n",
    "try:\n",
    "    from tensorflow.keras.models import Sequential\n",
    "    from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    HAS_LSTM = True\n",
    "except:\n",
    "    HAS_LSTM = False\n",
    "    print(\"‚ö† TensorFlow no disponible, LSTM deshabilitado\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENTRENAMIENTO MEJORADO: M√öLTIPLES MODELOS POR V√ÅLVULA\")\n",
    "print(\"=\" * 80)\n",
    "print(\"Modelos: Prophet, LightGBM, Random Forest, CatBoost, Prophet+LSTM (h√≠brido)\")\n",
    "\n",
    "# Cargar datasets generados (parsing con decimal=',')\n",
    "df_train = pd.read_csv('Dataset_Train.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df_pred = pd.read_csv('Dataset_Prediccion.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PRESION_FINAL','TEMPERATURA_FINAL','KPT_FINAL','NUM_USUARIOS','NUM_REGISTROS']:\n",
    "    if col in df_train.columns:\n",
    "        df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "    if col in df_pred.columns:\n",
    "        df_pred[col] = pd.to_numeric(df_pred[col], errors='coerce')\n",
    "df_train['FECHA'] = pd.to_datetime(df_train['FECHA'], errors='coerce')\n",
    "df_pred['FECHA'] = pd.to_datetime(df_pred['FECHA'], errors='coerce')\n",
    "\n",
    "# Funciones auxiliares\n",
    "def mase(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true)\n",
    "    y_pred = np.asarray(y_pred)\n",
    "    if len(y_true) < 2:\n",
    "        return np.nan\n",
    "    denom = np.mean(np.abs(np.diff(y_true)))\n",
    "    return np.mean(np.abs(y_true - y_pred)) / denom if denom > 0 else np.nan\n",
    "\n",
    "def evaluar(y_true, y_pred):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "    mape = np.mean(np.abs((y_true - y_pred) / np.where(y_true==0, np.nan, y_true))) * 100\n",
    "    return mae, rmse, mape, mase(y_true, y_pred)\n",
    "\n",
    "# Fallback ingenuo\n",
    "def naive_forecast(hist_series, pred_index):\n",
    "    hist_series = pd.Series(hist_series).dropna()\n",
    "    if hist_series.empty:\n",
    "        return pd.Series([np.nan] * len(pred_index), index=pred_index)\n",
    "    if len(hist_series) >= 3:\n",
    "        base = hist_series.tail(3).mean()\n",
    "    else:\n",
    "        base = hist_series.mean()\n",
    "    return pd.Series([base] * len(pred_index), index=pred_index)\n",
    "\n",
    "# Funci√≥n para crear features mejoradas\n",
    "def crear_features_mejoradas(df, hist_v=None):\n",
    "    \"\"\"Crea features adicionales incluyendo lags y estad√≠sticas\"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Features b√°sicas\n",
    "    feat_cols = []\n",
    "    for c in ['PRESION_FINAL','TEMPERATURA_FINAL','KPT_FINAL','NUM_USUARIOS','NUM_REGISTROS','VOLUMEN_SALIDA_FINAL']:\n",
    "        if c in df.columns:\n",
    "            feat_cols.append(c)\n",
    "    \n",
    "    # Features temporales\n",
    "    if 'FECHA' in df.columns:\n",
    "        df['MES'] = df['FECHA'].dt.month\n",
    "        df['A√ëO'] = df['FECHA'].dt.year\n",
    "        df['DIA_A√ëO'] = df['FECHA'].dt.dayofyear\n",
    "        feat_cols.extend(['MES', 'A√ëO', 'DIA_A√ëO'])\n",
    "    \n",
    "    # Lags y medias m√≥viles (si hay hist√≥rico)\n",
    "    if hist_v is not None and len(hist_v) > 0:\n",
    "        hist_v = hist_v.sort_values('FECHA')\n",
    "        if 'VOLUMEN_ENTRADA_FINAL' in hist_v.columns:\n",
    "            valores = hist_v['VOLUMEN_ENTRADA_FINAL'].dropna().values\n",
    "            if len(valores) > 0:\n",
    "                # √öltimo valor\n",
    "                df['LAG_1'] = valores[-1] if len(valores) >= 1 else np.nan\n",
    "                # Media de √∫ltimos 3\n",
    "                df['MA_3'] = np.mean(valores[-3:]) if len(valores) >= 3 else np.mean(valores) if len(valores) > 0 else np.nan\n",
    "                # Media de √∫ltimos 6\n",
    "                df['MA_6'] = np.mean(valores[-6:]) if len(valores) >= 6 else np.mean(valores) if len(valores) > 0 else np.nan\n",
    "                feat_cols.extend(['LAG_1', 'MA_3', 'MA_6'])\n",
    "    \n",
    "    # Features de interacci√≥n\n",
    "    if 'PRESION_FINAL' in df.columns and 'TEMPERATURA_FINAL' in df.columns:\n",
    "        df['PRESION_TEMP'] = df['PRESION_FINAL'] * df['TEMPERATURA_FINAL']\n",
    "        feat_cols.append('PRESION_TEMP')\n",
    "    \n",
    "    if 'VOLUMEN_SALIDA_FINAL' in df.columns and 'NUM_USUARIOS' in df.columns:\n",
    "        df['CONSUMO_POR_USUARIO'] = df['VOLUMEN_SALIDA_FINAL'] / (df['NUM_USUARIOS'] + 1)\n",
    "        feat_cols.append('CONSUMO_POR_USUARIO')\n",
    "    \n",
    "    return df, feat_cols\n",
    "\n",
    "# Funci√≥n para LSTM simple\n",
    "def entrenar_lstm_simple(X_seq, y_seq, n_features, epochs=50, verbose=0):\n",
    "    \"\"\"Entrena un LSTM simple para series temporales\"\"\"\n",
    "    if not HAS_LSTM or len(X_seq) < 3:\n",
    "        return None\n",
    "    \n",
    "    try:\n",
    "        model = Sequential([\n",
    "            LSTM(50, activation='relu', input_shape=(1, n_features), return_sequences=True),\n",
    "            Dropout(0.2),\n",
    "            LSTM(50, activation='relu'),\n",
    "            Dropout(0.2),\n",
    "            Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')\n",
    "        model.fit(X_seq, y_seq, epochs=epochs, verbose=verbose, batch_size=1)\n",
    "        return model\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "# Entrenamiento de m√∫ltiples modelos por v√°lvula\n",
    "valvulas = sorted(df_train['VALVULA'].dropna().unique())\n",
    "print(f\"\\nV√°lvulas para procesar: {len(valvulas)} -> {valvulas}\\n\")\n",
    "resultados = []\n",
    "pronosticos = []\n",
    "\n",
    "for v in valvulas:\n",
    "    hist_v = df_train[(df_train['VALVULA']==v) & (df_train['VOLUMEN_ENTRADA_FINAL'].notna())].copy()\n",
    "    pred_v = df_pred[df_pred['VALVULA']==v].copy()\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Procesando {v}: hist={len(hist_v)}, pred={len(pred_v)}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    if hist_v.empty or pred_v.empty:\n",
    "        print(\"‚ö† Saltando por falta de datos\")\n",
    "        continue\n",
    "    \n",
    "    hist_v = hist_v.sort_values('FECHA')\n",
    "    n_hist = len(hist_v)\n",
    "    \n",
    "    # Inicializar predicciones\n",
    "    pred_v['PRED_ENTRADA_PROPHET'] = np.nan\n",
    "    pred_v['PRED_ENTRADA_LGBM'] = np.nan\n",
    "    pred_v['PRED_ENTRADA_RF'] = np.nan\n",
    "    pred_v['PRED_ENTRADA_CATBOOST'] = np.nan\n",
    "    pred_v['PRED_ENTRADA_LSTM'] = np.nan\n",
    "    pred_v['PRED_ENTRADA_HYBRID'] = np.nan\n",
    "    \n",
    "    # ===== MODELO 1: PROPHET =====\n",
    "    dfp = hist_v[['FECHA','VOLUMEN_ENTRADA_FINAL']].rename(columns={'FECHA':'ds','VOLUMEN_ENTRADA_FINAL':'y'})\n",
    "    if n_hist >= 6:\n",
    "        try:\n",
    "            m = Prophet(seasonality_mode='multiplicative', yearly_seasonality=True, \n",
    "                       weekly_seasonality=False, daily_seasonality=False)\n",
    "            m.fit(dfp)\n",
    "            future = pd.DataFrame({'ds': pred_v['FECHA']})\n",
    "            fc_prophet = m.predict(future)\n",
    "            pred_v['PRED_ENTRADA_PROPHET'] = fc_prophet['yhat'].values\n",
    "            print(\"‚úì Prophet OK\")\n",
    "        except Exception as e:\n",
    "            pred_v['PRED_ENTRADA_PROPHET'] = naive_forecast(hist_v['VOLUMEN_ENTRADA_FINAL'], pred_v.index).values\n",
    "            print(f\"‚ö† Prophet fallback: {str(e)[:50]}\")\n",
    "    else:\n",
    "        pred_v['PRED_ENTRADA_PROPHET'] = naive_forecast(hist_v['VOLUMEN_ENTRADA_FINAL'], pred_v.index).values\n",
    "        print(\"‚ö† Prophet: pocos datos, usando fallback\")\n",
    "    \n",
    "    # ===== PREPARAR FEATURES MEJORADAS =====\n",
    "    hist_v_feat, feat_cols = crear_features_mejoradas(hist_v)\n",
    "    pred_v_feat, _ = crear_features_mejoradas(pred_v, hist_v)\n",
    "    \n",
    "    # Filtrar solo features num√©ricas disponibles\n",
    "    feat_cols = [c for c in feat_cols if c in hist_v_feat.columns and c in pred_v_feat.columns]\n",
    "    feat_cols = [c for c in feat_cols if hist_v_feat[c].dtype in [np.float64, np.int64, np.float32, np.int32]]\n",
    "    \n",
    "    if len(feat_cols) == 0:\n",
    "        print(\"‚ö† No hay features disponibles para modelos basados en features\")\n",
    "    else:\n",
    "        print(f\"‚úì Features disponibles: {len(feat_cols)} -> {feat_cols[:5]}...\")\n",
    "        \n",
    "        # Preparar datos\n",
    "        X = hist_v_feat[feat_cols].fillna(method='ffill').fillna(0)\n",
    "        y = hist_v['VOLUMEN_ENTRADA_FINAL'].values\n",
    "        \n",
    "        # Validaci√≥n temporal\n",
    "        if n_hist >= 6:\n",
    "            split_idx = max(1, int(len(X)*0.8))\n",
    "            split_idx = min(split_idx, len(X)-2)\n",
    "            X_tr, X_te = X.iloc[:split_idx], X.iloc[split_idx:]\n",
    "            y_tr, y_te = y[:split_idx], y[split_idx:]\n",
    "            \n",
    "            # ===== MODELO 2: LIGHTGBM =====\n",
    "            if n_hist >= 6:\n",
    "                try:\n",
    "                    model_lgbm = LGBMRegressor(n_estimators=200, learning_rate=0.05, \n",
    "                                               subsample=0.9, colsample_bytree=0.8, \n",
    "                                               random_state=42, verbose=-1)\n",
    "                    model_lgbm.fit(X_tr, y_tr)\n",
    "                    if len(y_te) >= 2:\n",
    "                        y_hat = model_lgbm.predict(X_te)\n",
    "                        mae, rmse, mape, mase_v = evaluar(y_te, y_hat)\n",
    "                        resultados.append({'VALVULA': v, 'MODELO':'LightGBM', 'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'MASE': mase_v, 'N_TEST': len(y_te)})\n",
    "                        print(f\"  LightGBM test -> MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "                    model_lgbm.fit(X, y)\n",
    "                    X_pred = pred_v_feat[feat_cols].fillna(method='ffill').fillna(0)\n",
    "                    pred_v['PRED_ENTRADA_LGBM'] = model_lgbm.predict(X_pred)\n",
    "                    print(\"‚úì LightGBM OK\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† LightGBM error: {str(e)[:50]}\")\n",
    "            \n",
    "            # ===== MODELO 3: RANDOM FOREST =====\n",
    "            try:\n",
    "                model_rf = RandomForestRegressor(n_estimators=100, max_depth=10, \n",
    "                                                min_samples_split=2, random_state=42, n_jobs=-1)\n",
    "                model_rf.fit(X_tr, y_tr)\n",
    "                if len(y_te) >= 2:\n",
    "                    y_hat = model_rf.predict(X_te)\n",
    "                    mae, rmse, mape, mase_v = evaluar(y_te, y_hat)\n",
    "                    resultados.append({'VALVULA': v, 'MODELO':'RandomForest', 'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'MASE': mase_v, 'N_TEST': len(y_te)})\n",
    "                    print(f\"  RandomForest test -> MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "                model_rf.fit(X, y)\n",
    "                X_pred = pred_v_feat[feat_cols].fillna(method='ffill').fillna(0)\n",
    "                pred_v['PRED_ENTRADA_RF'] = model_rf.predict(X_pred)\n",
    "                print(\"‚úì Random Forest OK\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† Random Forest error: {str(e)[:50]}\")\n",
    "            \n",
    "            # ===== MODELO 4: CATBOOST =====\n",
    "            try:\n",
    "                model_cat = CatBoostRegressor(iterations=100, learning_rate=0.05, \n",
    "                                             depth=6, random_state=42, verbose=False)\n",
    "                model_cat.fit(X_tr, y_tr)\n",
    "                if len(y_te) >= 2:\n",
    "                    y_hat = model_cat.predict(X_te)\n",
    "                    mae, rmse, mape, mase_v = evaluar(y_te, y_hat)\n",
    "                    resultados.append({'VALVULA': v, 'MODELO':'CatBoost', 'MAE': mae, 'RMSE': rmse, 'MAPE': mape, 'MASE': mase_v, 'N_TEST': len(y_te)})\n",
    "                    print(f\"  CatBoost test -> MAE: {mae:.2f}, RMSE: {rmse:.2f}, MAPE: {mape:.2f}%\")\n",
    "                model_cat.fit(X, y)\n",
    "                X_pred = pred_v_feat[feat_cols].fillna(method='ffill').fillna(0)\n",
    "                pred_v['PRED_ENTRADA_CATBOOST'] = model_cat.predict(X_pred)\n",
    "                print(\"‚úì CatBoost OK\")\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö† CatBoost error: {str(e)[:50]}\")\n",
    "            \n",
    "            # ===== MODELO 5: H√çBRIDO PROPHET + LSTM =====\n",
    "            if HAS_LSTM and n_hist >= 8:\n",
    "                try:\n",
    "                    # Usar residuos de Prophet para entrenar LSTM\n",
    "                    prophet_train = m.predict(dfp[['ds']])\n",
    "                    residuos = dfp['y'].values - prophet_train['yhat'].values\n",
    "                    \n",
    "                    # Crear secuencias para LSTM\n",
    "                    seq_length = min(3, len(residuos)-1)\n",
    "                    if seq_length >= 2:\n",
    "                        X_seq = []\n",
    "                        y_seq = []\n",
    "                        for i in range(len(residuos) - seq_length):\n",
    "                            X_seq.append(residuos[i:i+seq_length].reshape(1, seq_length))\n",
    "                            y_seq.append(residuos[i+seq_length])\n",
    "                        \n",
    "                        if len(X_seq) > 0:\n",
    "                            X_seq = np.array(X_seq)\n",
    "                            y_seq = np.array(y_seq)\n",
    "                            \n",
    "                            # Entrenar LSTM en residuos\n",
    "                            lstm_model = entrenar_lstm_simple(X_seq, y_seq, seq_length, epochs=30, verbose=0)\n",
    "                            \n",
    "                            if lstm_model is not None:\n",
    "                                # Predecir residuos futuros\n",
    "                                last_seq = residuos[-seq_length:].reshape(1, 1, seq_length)\n",
    "                                residuos_pred = []\n",
    "                                for _ in range(len(pred_v)):\n",
    "                                    pred_res = lstm_model.predict(last_seq, verbose=0)[0, 0]\n",
    "                                    residuos_pred.append(pred_res)\n",
    "                                    # Actualizar secuencia\n",
    "                                    last_seq = np.append(last_seq[0, 0, 1:], pred_res).reshape(1, 1, seq_length)\n",
    "                                \n",
    "                                # Combinar Prophet + residuos LSTM\n",
    "                                pred_v['PRED_ENTRADA_HYBRID'] = pred_v['PRED_ENTRADA_PROPHET'].values + np.array(residuos_pred)\n",
    "                                print(\"‚úì Prophet+LSTM H√≠brido OK\")\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö† H√≠brido Prophet+LSTM error: {str(e)[:50]}\")\n",
    "    \n",
    "    # ===== ENSEMBLE FINAL: Pesos basados en m√©tricas reales (CORREGIDO) =====\n",
    "    preds_disponibles = []\n",
    "    pesos = []\n",
    "    metricas_por_modelo = {}  # Guardar m√©tricas para usar en pesos\n",
    "    \n",
    "    # Obtener m√©tricas de esta v√°lvula de los resultados\n",
    "    metricas_v = [r for r in resultados if r['VALVULA'] == v]\n",
    "    for m in metricas_v:\n",
    "        metricas_por_modelo[m['MODELO']] = m\n",
    "    \n",
    "    # Mapeo de modelos a columnas\n",
    "    modelo_col_map = {\n",
    "        'CatBoost': 'PRED_ENTRADA_CATBOOST',\n",
    "        'RandomForest': 'PRED_ENTRADA_RF',\n",
    "        'LightGBM': 'PRED_ENTRADA_LGBM',\n",
    "        'Prophet': 'PRED_ENTRADA_PROPHET'\n",
    "    }\n",
    "    \n",
    "    # ESTRATEGIA MEJORADA: Priorizar modelos con m√©tricas, Prophet solo como respaldo\n",
    "    modelos_con_metricas = []\n",
    "    modelos_sin_metricas = []\n",
    "    \n",
    "    # Separar modelos con y sin m√©tricas\n",
    "    for modelo, col in modelo_col_map.items():\n",
    "        if pred_v[col].notna().any():\n",
    "            if modelo in metricas_por_modelo:\n",
    "                modelos_con_metricas.append((modelo, col))\n",
    "            else:\n",
    "                modelos_sin_metricas.append((modelo, col))\n",
    "    \n",
    "    # Si hay modelos con m√©tricas, usar solo esos (con pesos basados en MAE inverso)\n",
    "    if len(modelos_con_metricas) > 0:\n",
    "        # Calcular pesos basados en MAE inverso\n",
    "        pesos_metricas = []\n",
    "        for modelo, col in modelos_con_metricas:\n",
    "            mae = metricas_por_modelo[modelo]['MAE']\n",
    "            # Peso = 1/MAE (normalizado despu√©s)\n",
    "            peso = 1.0 / (mae + 1e-6)\n",
    "            preds_disponibles.append(col)\n",
    "            pesos_metricas.append(peso)\n",
    "        \n",
    "        # Normalizar pesos de modelos con m√©tricas\n",
    "        pesos_metricas = np.array(pesos_metricas)\n",
    "        pesos_metricas = pesos_metricas / np.sum(pesos_metricas)\n",
    "        pesos = pesos_metricas.tolist()\n",
    "        \n",
    "        # Solo agregar Prophet si no hay suficientes modelos con m√©tricas (m√°ximo 1 modelo sin m√©tricas)\n",
    "        if len(modelos_con_metricas) < 2 and len(modelos_sin_metricas) > 0:\n",
    "            # Agregar Prophet con peso bajo (10% del total)\n",
    "            prophet_col = None\n",
    "            for modelo, col in modelos_sin_metricas:\n",
    "                if modelo == 'Prophet':\n",
    "                    prophet_col = col\n",
    "                    break\n",
    "            \n",
    "            if prophet_col is not None:\n",
    "                # Reducir pesos existentes y agregar Prophet\n",
    "                factor_reduccion = 0.9\n",
    "                pesos = [p * factor_reduccion for p in pesos]\n",
    "                preds_disponibles.append(prophet_col)\n",
    "                pesos.append(0.1)  # 10% para Prophet\n",
    "                # Renormalizar\n",
    "                pesos = np.array(pesos)\n",
    "                pesos = pesos / np.sum(pesos)\n",
    "                pesos = pesos.tolist()\n",
    "    else:\n",
    "        # Si no hay m√©tricas, usar todos los modelos disponibles con pesos por defecto\n",
    "        pesos_default = {'CatBoost': 0.35, 'RandomForest': 0.25, 'LightGBM': 0.25, 'Prophet': 0.15}\n",
    "        for modelo, col in modelos_sin_metricas:\n",
    "            preds_disponibles.append(col)\n",
    "            pesos.append(pesos_default.get(modelo, 0.2))\n",
    "        # Normalizar\n",
    "        if len(pesos) > 0:\n",
    "            pesos = np.array(pesos)\n",
    "            pesos = pesos / np.sum(pesos)\n",
    "            pesos = pesos.tolist()\n",
    "    \n",
    "    # Agregar h√≠brido si est√° disponible (solo si hay otros modelos)\n",
    "    if pred_v['PRED_ENTRADA_HYBRID'].notna().any() and len(preds_disponibles) > 0:\n",
    "        # Reducir pesos existentes y agregar h√≠brido con 10%\n",
    "        factor_reduccion = 0.9\n",
    "        pesos = [p * factor_reduccion for p in pesos]\n",
    "        preds_disponibles.append('PRED_ENTRADA_HYBRID')\n",
    "        pesos.append(0.1)\n",
    "        # Renormalizar\n",
    "        pesos = np.array(pesos)\n",
    "        pesos = pesos / np.sum(pesos)\n",
    "        pesos = pesos.tolist()\n",
    "    \n",
    "    if len(preds_disponibles) > 0:\n",
    "        # Normalizar pesos finales\n",
    "        pesos = np.array(pesos)\n",
    "        pesos = pesos / np.sum(pesos)\n",
    "        # Promedio ponderado\n",
    "        pred_v['PRED_ENTRADA'] = sum(pred_v[col].values * peso for col, peso in zip(preds_disponibles, pesos))\n",
    "        \n",
    "        # Mostrar pesos usados\n",
    "        pesos_str = \", \".join([f\"{col.split('_')[-1]}: {p:.2%}\" for col, p in zip(preds_disponibles, pesos)])\n",
    "        print(f\"‚úì Ensemble: {len(preds_disponibles)} modelos (pesos: {pesos_str})\")\n",
    "    else:\n",
    "        pred_v['PRED_ENTRADA'] = naive_forecast(hist_v['VOLUMEN_ENTRADA_FINAL'], pred_v.index).values\n",
    "        print(\"‚ö† Ensemble: usando fallback ingenuo\")\n",
    "    \n",
    "    # Recalcular p√©rdidas e √≠ndice\n",
    "    pred_v['PRED_SALIDA'] = pred_v.get('VOLUMEN_SALIDA_FINAL', np.nan)\n",
    "    pred_v['PRED_PERDIDAS'] = pred_v['PRED_ENTRADA'] - pred_v['PRED_SALIDA']\n",
    "    pred_v['PRED_INDICE_PERDIDAS'] = np.where(pred_v['PRED_ENTRADA']>0, (pred_v['PRED_PERDIDAS']/pred_v['PRED_ENTRADA'])*100, np.nan)\n",
    "    \n",
    "    # Guardar todas las predicciones\n",
    "    cols_guardar = ['VALVULA','PERIODO','FECHA','PRED_ENTRADA_PROPHET','PRED_ENTRADA_LGBM',\n",
    "                   'PRED_ENTRADA_RF','PRED_ENTRADA_CATBOOST','PRED_ENTRADA_LSTM',\n",
    "                   'PRED_ENTRADA_HYBRID','PRED_ENTRADA','PRED_SALIDA','PRED_PERDIDAS','PRED_INDICE_PERDIDAS']\n",
    "    cols_guardar = [c for c in cols_guardar if c in pred_v.columns]\n",
    "    pronosticos.append(pred_v[cols_guardar])\n",
    "    print(f\"‚úì Pron√≥sticos agregados: {len(pred_v)} filas\\n\")\n",
    "\n",
    "# Concatenar y guardar\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(f\"RESUMEN FINAL\")\n",
    "print(f\"{'='*80}\")\n",
    "print(f\"Total bloques de pron√≥sticos: {len(pronosticos)}\")\n",
    "\n",
    "if len(pronosticos)>0:\n",
    "    df_fc = pd.concat(pronosticos, ignore_index=True)\n",
    "    df_fc.to_csv('Pronosticos.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"‚úì Pron√≥sticos guardados: Pronosticos.csv ({df_fc.shape})\")\n",
    "    \n",
    "    # Mostrar resumen de predicciones por modelo\n",
    "    print(\"\\nPredicciones disponibles por modelo:\")\n",
    "    for col in ['PRED_ENTRADA_PROPHET','PRED_ENTRADA_LGBM','PRED_ENTRADA_RF',\n",
    "               'PRED_ENTRADA_CATBOOST','PRED_ENTRADA_HYBRID']:\n",
    "        if col in df_fc.columns:\n",
    "            n_valid = df_fc[col].notna().sum()\n",
    "            print(f\"  {col}: {n_valid}/{len(df_fc)} ({100*n_valid/len(df_fc):.1f}%)\")\n",
    "else:\n",
    "    print(\"‚ö† No se generaron pron√≥sticos (verificar datos)\")\n",
    "\n",
    "# Guardar m√©tricas\n",
    "if len(resultados)>0:\n",
    "    df_metrics = pd.DataFrame(resultados)\n",
    "    df_metrics.to_csv('Metrics.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"\\n‚úì M√©tricas guardadas: Metrics.csv ({df_metrics.shape})\")\n",
    "    print(\"\\nResumen de m√©tricas por modelo:\")\n",
    "    print(df_metrics.groupby('MODELO')[['MAE','RMSE','MAPE']].mean().round(2))\n",
    "    print(\"\\nMejores modelos por v√°lvula:\")\n",
    "    for v in df_metrics['VALVULA'].unique():\n",
    "        df_v = df_metrics[df_metrics['VALVULA']==v]\n",
    "        mejor = df_v.loc[df_v['MAE'].idxmin()]\n",
    "        print(f\"  {v}: {mejor['MODELO']} (MAE: {mejor['MAE']:.2f})\")\n",
    "else:\n",
    "    print(\"‚ö† No se calcularon m√©tricas (datos insuficientes)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISIS DETALLADO DE RESULTADOS\n",
      "================================================================================\n",
      "\n",
      "1. RESUMEN DE M√âTRICAS POR MODELO (PROMEDIO)\n",
      "--------------------------------------------------------------------------------\n",
      "                  MAE                               RMSE            MAPE  \\\n",
      "                 mean      std     min      max     mean      std   mean   \n",
      "MODELO                                                                     \n",
      "CatBoost      1567.08  1646.13   71.41  3602.33  1776.49  1954.20  14.18   \n",
      "LightGBM      2659.22  2873.93  106.21  5758.28  2767.18  3018.05  19.02   \n",
      "RandomForest  1597.86  2132.95  122.28  4739.57  1824.53  2520.32  17.45   \n",
      "\n",
      "                     MASE        \n",
      "                std  mean   std  \n",
      "MODELO                           \n",
      "CatBoost       6.27  1.94  1.40  \n",
      "LightGBM       3.43  3.07  3.18  \n",
      "RandomForest  10.35  1.74  0.50  \n",
      "\n",
      "2. RANKING DE MODELOS POR M√âTRICA\n",
      "--------------------------------------------------------------------------------\n",
      "Por MAE (menor es mejor):\n",
      "  1. CatBoost: MAE promedio = 1567.08\n",
      "  2. RandomForest: MAE promedio = 1597.86\n",
      "  3. LightGBM: MAE promedio = 2659.22\n",
      "\n",
      "Por MAPE (menor es mejor):\n",
      "  1. CatBoost: MAPE promedio = 14.18%\n",
      "  2. RandomForest: MAPE promedio = 17.45%\n",
      "  3. LightGBM: MAPE promedio = 19.02%\n",
      "\n",
      "3. MEJOR MODELO POR V√ÅLVULA\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "VALVULA_1:\n",
      "  Mejor MAE: CatBoost (MAE: 71.41, MAPE: 15.29%)\n",
      "\n",
      "VALVULA_2:\n",
      "  Mejor MAE: LightGBM (MAE: 323.74, MAPE: 18.04%)\n",
      "\n",
      "VALVULA_3:\n",
      "  Mejor MAE: RandomForest (MAE: 1090.91, MAPE: 3.87%)\n",
      "\n",
      "VALVULA_4:\n",
      "  Mejor MAE: CatBoost (MAE: 3602.33, MAPE: 11.33%)\n",
      "\n",
      "4. AN√ÅLISIS DE VARIABILIDAD\n",
      "--------------------------------------------------------------------------------\n",
      "Desviaci√≥n est√°ndar de MAE por modelo (menor = m√°s consistente):\n",
      "  CatBoost: œÉ = 1646.13\n",
      "  RandomForest: œÉ = 2132.95\n",
      "  LightGBM: œÉ = 2873.93\n",
      "\n",
      "5. COMPARACI√ìN DE PREDICCIONES\n",
      "--------------------------------------------------------------------------------\n",
      "Modelos con predicciones: 6\n",
      "\n",
      "Estad√≠sticas de predicciones por modelo:\n",
      "\n",
      "  PROPHET:\n",
      "    Predicciones v√°lidas: 45/45 (100.0%)\n",
      "    Media: 13272.12\n",
      "    Mediana: 4503.27\n",
      "    Std: 413750.76\n",
      "    Min: -2008084.16, Max: 1770074.72\n",
      "\n",
      "  LGBM:\n",
      "    Predicciones v√°lidas: 32/45 (71.1%)\n",
      "    Media: 14646.14\n",
      "    Mediana: 25118.24\n",
      "    Std: 12457.77\n",
      "    Min: 360.17, Max: 26572.34\n",
      "\n",
      "  RF:\n",
      "    Predicciones v√°lidas: 32/45 (71.1%)\n",
      "    Media: 14031.77\n",
      "    Mediana: 21075.14\n",
      "    Std: 12046.19\n",
      "    Min: 331.37, Max: 28540.39\n",
      "\n",
      "  CATBOOST:\n",
      "    Predicciones v√°lidas: 32/45 (71.1%)\n",
      "    Media: 14778.89\n",
      "    Mediana: 23583.48\n",
      "    Std: 12608.25\n",
      "    Min: 384.57, Max: 28594.72\n",
      "\n",
      "  Ensemble Final:\n",
      "    Predicciones v√°lidas: 45/45 (100.0%)\n",
      "    Media: 11659.05\n",
      "    Mediana: 4503.27\n",
      "    Std: 11397.52\n",
      "\n",
      "6. RECOMENDACIONES\n",
      "--------------------------------------------------------------------------------\n",
      "Modelo recomendado (mejor MAE promedio): CatBoost\n",
      "Modelos m√°s consistentes (baja variabilidad): CatBoost\n",
      "\n",
      "V√°lvula con mejor rendimiento: VALVULA_4 (MAE promedio: 4700.06)\n",
      "V√°lvula con peor rendimiento: VALVULA_1 (MAE promedio: 99.97)\n",
      "Ratio: 0.02x\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "‚úì Resumen guardado en: Resumen_Analisis_Modelos.csv\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISIS DETALLADO DE RESULTADOS Y COMPARACI√ìN DE MODELOS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DETALLADO DE RESULTADOS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar resultados\n",
    "try:\n",
    "    df_metrics = pd.read_csv('Metrics.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    df_fc = pd.read_csv('Pronosticos.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    df_train = pd.read_csv('Dataset_Train.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando archivos: {e}\")\n",
    "    raise\n",
    "\n",
    "# Asegurar tipos num√©ricos\n",
    "for col in df_metrics.select_dtypes(include=['object']).columns:\n",
    "    if col not in ['VALVULA', 'MODELO']:\n",
    "        df_metrics[col] = pd.to_numeric(df_metrics[col], errors='coerce')\n",
    "\n",
    "print(\"\\n1. RESUMEN DE M√âTRICAS POR MODELO (PROMEDIO)\")\n",
    "print(\"-\" * 80)\n",
    "if len(df_metrics) > 0:\n",
    "    resumen = df_metrics.groupby('MODELO').agg({\n",
    "        'MAE': ['mean', 'std', 'min', 'max'],\n",
    "        'RMSE': ['mean', 'std'],\n",
    "        'MAPE': ['mean', 'std'],\n",
    "        'MASE': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    print(resumen)\n",
    "    \n",
    "    print(\"\\n2. RANKING DE MODELOS POR M√âTRICA\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Por MAE (menor es mejor):\")\n",
    "    ranking_mae = df_metrics.groupby('MODELO')['MAE'].mean().sort_values()\n",
    "    for i, (modelo, mae) in enumerate(ranking_mae.items(), 1):\n",
    "        print(f\"  {i}. {modelo}: MAE promedio = {mae:.2f}\")\n",
    "    \n",
    "    print(\"\\nPor MAPE (menor es mejor):\")\n",
    "    ranking_mape = df_metrics.groupby('MODELO')['MAPE'].mean().sort_values()\n",
    "    for i, (modelo, mape) in enumerate(ranking_mape.items(), 1):\n",
    "        print(f\"  {i}. {modelo}: MAPE promedio = {mape:.2f}%\")\n",
    "    \n",
    "    print(\"\\n3. MEJOR MODELO POR V√ÅLVULA\")\n",
    "    print(\"-\" * 80)\n",
    "    for v in sorted(df_metrics['VALVULA'].unique()):\n",
    "        df_v = df_metrics[df_metrics['VALVULA'] == v]\n",
    "        mejor_mae = df_v.loc[df_v['MAE'].idxmin()]\n",
    "        mejor_mape = df_v.loc[df_v['MAPE'].idxmin()]\n",
    "        print(f\"\\n{v}:\")\n",
    "        print(f\"  Mejor MAE: {mejor_mae['MODELO']} (MAE: {mejor_mae['MAE']:.2f}, MAPE: {mejor_mae['MAPE']:.2f}%)\")\n",
    "        if mejor_mae['MODELO'] != mejor_mape['MODELO']:\n",
    "            print(f\"  Mejor MAPE: {mejor_mape['MODELO']} (MAE: {mejor_mape['MAE']:.2f}, MAPE: {mejor_mape['MAPE']:.2f}%)\")\n",
    "    \n",
    "    print(\"\\n4. AN√ÅLISIS DE VARIABILIDAD\")\n",
    "    print(\"-\" * 80)\n",
    "    print(\"Desviaci√≥n est√°ndar de MAE por modelo (menor = m√°s consistente):\")\n",
    "    std_mae = df_metrics.groupby('MODELO')['MAE'].std().sort_values()\n",
    "    for modelo, std in std_mae.items():\n",
    "        print(f\"  {modelo}: œÉ = {std:.2f}\")\n",
    "    \n",
    "    print(\"\\n5. COMPARACI√ìN DE PREDICCIONES\")\n",
    "    print(\"-\" * 80)\n",
    "    # Comparar predicciones de diferentes modelos\n",
    "    pred_cols = [c for c in df_fc.columns if c.startswith('PRED_ENTRADA') and c != 'PRED_ENTRADA']\n",
    "    \n",
    "    if len(pred_cols) > 0:\n",
    "        print(f\"Modelos con predicciones: {len(pred_cols)}\")\n",
    "        print(\"\\nEstad√≠sticas de predicciones por modelo:\")\n",
    "        for col in pred_cols:\n",
    "            valores = df_fc[col].dropna()\n",
    "            if len(valores) > 0:\n",
    "                modelo_nombre = col.replace('PRED_ENTRADA_', '')\n",
    "                print(f\"\\n  {modelo_nombre}:\")\n",
    "                print(f\"    Predicciones v√°lidas: {len(valores)}/{len(df_fc)} ({100*len(valores)/len(df_fc):.1f}%)\")\n",
    "                print(f\"    Media: {valores.mean():.2f}\")\n",
    "                print(f\"    Mediana: {valores.median():.2f}\")\n",
    "                print(f\"    Std: {valores.std():.2f}\")\n",
    "                print(f\"    Min: {valores.min():.2f}, Max: {valores.max():.2f}\")\n",
    "        \n",
    "        # Comparar con ensemble final\n",
    "        if 'PRED_ENTRADA' in df_fc.columns:\n",
    "            ensemble = df_fc['PRED_ENTRADA'].dropna()\n",
    "            print(f\"\\n  Ensemble Final:\")\n",
    "            print(f\"    Predicciones v√°lidas: {len(ensemble)}/{len(df_fc)} ({100*len(ensemble)/len(df_fc):.1f}%)\")\n",
    "            print(f\"    Media: {ensemble.mean():.2f}\")\n",
    "            print(f\"    Mediana: {ensemble.median():.2f}\")\n",
    "            print(f\"    Std: {ensemble.std():.2f}\")\n",
    "    \n",
    "    print(\"\\n6. RECOMENDACIONES\")\n",
    "    print(\"-\" * 80)\n",
    "    # Analizar qu√© modelo funciona mejor en general\n",
    "    mejor_modelo_global = ranking_mae.index[0]\n",
    "    print(f\"Modelo recomendado (mejor MAE promedio): {mejor_modelo_global}\")\n",
    "    \n",
    "    # Verificar consistencia\n",
    "    modelos_consistentes = std_mae[std_mae < std_mae.median()].index.tolist()\n",
    "    if modelos_consistentes:\n",
    "        print(f\"Modelos m√°s consistentes (baja variabilidad): {', '.join(modelos_consistentes)}\")\n",
    "    \n",
    "    # Verificar si hay v√°lvulas problem√°ticas\n",
    "    mae_por_valvula = df_metrics.groupby('VALVULA')['MAE'].mean().sort_values(ascending=False)\n",
    "    if len(mae_por_valvula) > 0:\n",
    "        peor_valvula = mae_por_valvula.index[-1]\n",
    "        mejor_valvula = mae_por_valvula.index[0]\n",
    "        print(f\"\\nV√°lvula con mejor rendimiento: {mejor_valvula} (MAE promedio: {mae_por_valvula[mejor_valvula]:.2f})\")\n",
    "        print(f\"V√°lvula con peor rendimiento: {peor_valvula} (MAE promedio: {mae_por_valvula[peor_valvula]:.2f})\")\n",
    "        print(f\"Ratio: {mae_por_valvula[peor_valvula] / mae_por_valvula[mejor_valvula]:.2f}x\")\n",
    "    \n",
    "else:\n",
    "    print(\"‚ö† No hay m√©tricas disponibles para an√°lisis\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AN√ÅLISIS COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Guardar resumen de an√°lisis\n",
    "if len(df_metrics) > 0:\n",
    "    resumen_completo = df_metrics.groupby('MODELO').agg({\n",
    "        'MAE': ['count', 'mean', 'std', 'min', 'max'],\n",
    "        'RMSE': ['mean', 'std'],\n",
    "        'MAPE': ['mean', 'std'],\n",
    "        'MASE': ['mean']\n",
    "    }).round(2)\n",
    "    resumen_completo.to_csv('Resumen_Analisis_Modelos.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    print(\"\\n‚úì Resumen guardado en: Resumen_Analisis_Modelos.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTREGABLE 1: TABLA DE BALANCES VIRTUALES\n",
      "================================================================================\n",
      "‚ö† Predicciones_Con_Balance.csv no encontrado. Gener√°ndolo...\n",
      "‚úì Predicciones_Con_Balance.csv generado exitosamente\n",
      "‚úì Tabla de balances virtuales guardada: Tabla_Balances_Virtuales.csv ((82, 10))\n",
      "\n",
      "Resumen por punto:\n",
      "          ENTRADA_m3                  SALIDA_m3           PERDIDAS_m3  \\\n",
      "                 sum      mean count        sum      mean         sum   \n",
      "PUNTO                                                                   \n",
      "VALVULA_1    4253.62    354.47    12    6977.91    465.19     -805.32   \n",
      "VALVULA_2   39538.67   2080.98    19   40462.89   2380.17    -4517.94   \n",
      "VALVULA_3  284403.94  25854.90    11  274879.28  30542.14   -24356.64   \n",
      "VALVULA_4  463953.10  25775.17    18  509316.16  31832.26   -87051.04   \n",
      "VALVULA_5   72883.73   4287.28    17   73601.67   4906.78    -5883.70   \n",
      "\n",
      "                   INDICE_PERDIDAS_% ES_PRONOSTICO  \n",
      "              mean              mean           sum  \n",
      "PUNTO                                               \n",
      "VALVULA_1   -80.53            -19.24             4  \n",
      "VALVULA_2  -265.76            -13.89            11  \n",
      "VALVULA_3 -2706.29             -8.19             5  \n",
      "VALVULA_4 -5440.69            -19.69            12  \n",
      "VALVULA_5  -392.25             -8.43            13  \n",
      "\n",
      "Muestra de la tabla (primeros 10 registros):\n",
      "       PUNTO  PERIODO   A√ëO  MES      FECHA  ENTRADA_m3  SALIDA_m3  PERDIDAS_m3  INDICE_PERDIDAS_%  ES_PRONOSTICO\n",
      "0  VALVULA_1   202407  2024    7 2024-07-01       66.50        NaN          NaN                NaN          False\n",
      "1  VALVULA_1   202408  2024    8 2024-08-01      405.53        NaN          NaN                NaN          False\n",
      "2  VALVULA_1   202409  2024    9 2024-09-01      334.21     377.79       -43.58              -0.13          False\n",
      "3  VALVULA_1   202410  2024   10 2024-10-01      428.15     443.82       -15.68              -0.04          False\n",
      "4  VALVULA_1   202411  2024   11 2024-11-01      414.74     430.23       -15.49              -0.04          False\n",
      "5  VALVULA_1   202412  2024   12 2024-12-01      399.51     407.89        -8.38              -0.02          False\n",
      "6  VALVULA_1   202501  2025    1 2025-01-01      472.57     483.64       -11.07              -0.02          False\n",
      "7  VALVULA_1   202502  2025    2 2025-02-01      266.41     272.90        -6.49              -0.02          False\n",
      "8  VALVULA_1   202503  2025    3 2025-03-01         NaN     457.42          NaN                NaN          False\n",
      "9  VALVULA_1   202504  2025    4 2025-04-01         NaN     486.56          NaN                NaN          False\n",
      "\n",
      "================================================================================\n",
      "ENTREGABLE 1 COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENTREGABLE 1: TABLA DE BALANCES VIRTUALES POR PUNTO Y MES (m¬≥) + √çNDICE DE P√âRDIDAS\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENTREGABLE 1: TABLA DE BALANCES VIRTUALES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verificar si existe Predicciones_Con_Balance.csv, si no, generarlo\n",
    "if not os.path.exists('Predicciones_Con_Balance.csv'):\n",
    "    print(\"‚ö† Predicciones_Con_Balance.csv no encontrado. Gener√°ndolo...\")\n",
    "    \n",
    "    # Verificar archivos necesarios\n",
    "    archivos_necesarios = ['Dataset_Maestro_Balances.csv', 'Pronosticos.csv']\n",
    "    faltantes = [f for f in archivos_necesarios if not os.path.exists(f)]\n",
    "    \n",
    "    if faltantes:\n",
    "        print(f\"‚ùå ERROR: Faltan archivos necesarios: {', '.join(faltantes)}\")\n",
    "        print(\"   Por favor, ejecuta primero:\")\n",
    "        print(\"   1. Celdas de preparaci√≥n de datos (hasta Dataset_Maestro_Balances.csv)\")\n",
    "        print(\"   2. Celda 15 (Entrenamiento y Pron√≥stico)\")\n",
    "        raise FileNotFoundError(f\"Archivos faltantes: {', '.join(faltantes)}\")\n",
    "    \n",
    "    # Generar Predicciones_Con_Balance.csv\n",
    "    try:\n",
    "        df_maestro = pd.read_csv('Dataset_Maestro_Balances.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "        df_fc = pd.read_csv('Pronosticos.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "        \n",
    "        # Normalizar tipos\n",
    "        for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL','PRED_ENTRADA','PRED_SALIDA','PRED_PERDIDAS','PRED_INDICE_PERDIDAS']:\n",
    "            if col in df_maestro.columns:\n",
    "                df_maestro[col] = pd.to_numeric(df_maestro[col], errors='coerce')\n",
    "            if col in df_fc.columns:\n",
    "                df_fc[col] = pd.to_numeric(df_fc[col], errors='coerce')\n",
    "        \n",
    "        df_maestro['FECHA'] = pd.to_datetime(df_maestro['FECHA'], errors='coerce')\n",
    "        df_fc['FECHA'] = pd.to_datetime(df_fc['FECHA'], errors='coerce')\n",
    "        \n",
    "        # Unir por VALVULA + PERIODO\n",
    "        df_out = df_maestro.merge(df_fc[['VALVULA','PERIODO','PRED_ENTRADA','PRED_SALIDA','PRED_PERDIDAS','PRED_INDICE_PERDIDAS']], \n",
    "                                 on=['VALVULA','PERIODO'], how='left')\n",
    "        \n",
    "        # Reemplazar entrada/salida en periodos a predecir\n",
    "        mask_pred = df_out['PERIODO_A_PREDECIR'] == True\n",
    "        df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'] = df_out.loc[mask_pred, 'PRED_ENTRADA']\n",
    "        df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL'] = df_out.loc[mask_pred, 'PRED_SALIDA'].fillna(df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL'])\n",
    "        \n",
    "        # Recalcular p√©rdidas e √≠ndice para periodos a predecir\n",
    "        df_out.loc[mask_pred, 'PERDIDAS_FINAL'] = df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'] - df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL']\n",
    "        df_out.loc[mask_pred, 'INDICE_PERDIDAS_FINAL'] = np.where(df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL']>0, \n",
    "                                                                  (df_out.loc[mask_pred, 'PERDIDAS_FINAL']/df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'])*100, np.nan)\n",
    "        \n",
    "        # Guardar resultado\n",
    "        df_out.to_csv('Predicciones_Con_Balance.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "        print(\"‚úì Predicciones_Con_Balance.csv generado exitosamente\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERROR al generar Predicciones_Con_Balance.csv: {e}\")\n",
    "        raise\n",
    "\n",
    "# Cargar datos\n",
    "df_balance = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "    if col in df_balance.columns:\n",
    "        df_balance[col] = pd.to_numeric(df_balance[col], errors='coerce')\n",
    "\n",
    "df_balance['FECHA'] = pd.to_datetime(df_balance['FECHA'], errors='coerce')\n",
    "df_balance['A√ëO'] = df_balance['FECHA'].dt.year\n",
    "df_balance['MES'] = df_balance['FECHA'].dt.month\n",
    "\n",
    "# Crear tabla de balances virtuales (formato entregable)\n",
    "tabla_balances = df_balance[[\n",
    "    'VALVULA', 'PERIODO', 'A√ëO', 'MES', 'FECHA',\n",
    "    'VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL', \n",
    "    'PERDIDAS_FINAL', 'INDICE_PERDIDAS_FINAL',\n",
    "    'PERIODO_A_PREDECIR'\n",
    "]].copy()\n",
    "\n",
    "# Renombrar columnas para el entregable\n",
    "tabla_balances.rename(columns={\n",
    "    'VALVULA': 'PUNTO',\n",
    "    'VOLUMEN_ENTRADA_FINAL': 'ENTRADA_m3',\n",
    "    'VOLUMEN_SALIDA_FINAL': 'SALIDA_m3',\n",
    "    'PERDIDAS_FINAL': 'PERDIDAS_m3',\n",
    "    'INDICE_PERDIDAS_FINAL': 'INDICE_PERDIDAS_%',\n",
    "    'PERIODO_A_PREDECIR': 'ES_PRONOSTICO'\n",
    "}, inplace=True)\n",
    "\n",
    "# Ordenar por punto y fecha\n",
    "tabla_balances = tabla_balances.sort_values(['PUNTO', 'FECHA']).reset_index(drop=True)\n",
    "\n",
    "# Formatear valores\n",
    "tabla_balances['ENTRADA_m3'] = tabla_balances['ENTRADA_m3'].round(2)\n",
    "tabla_balances['SALIDA_m3'] = tabla_balances['SALIDA_m3'].round(2)\n",
    "tabla_balances['PERDIDAS_m3'] = tabla_balances['PERDIDAS_m3'].round(2)\n",
    "tabla_balances['INDICE_PERDIDAS_%'] = tabla_balances['INDICE_PERDIDAS_%'].round(2)\n",
    "\n",
    "# Guardar tabla de balances virtuales\n",
    "tabla_balances.to_csv('Tabla_Balances_Virtuales.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"‚úì Tabla de balances virtuales guardada: Tabla_Balances_Virtuales.csv ({tabla_balances.shape})\")\n",
    "\n",
    "# Mostrar resumen\n",
    "print(\"\\nResumen por punto:\")\n",
    "resumen_puntos = tabla_balances.groupby('PUNTO').agg({\n",
    "    'ENTRADA_m3': ['sum', 'mean', 'count'],\n",
    "    'SALIDA_m3': ['sum', 'mean'],\n",
    "    'PERDIDAS_m3': ['sum', 'mean'],\n",
    "    'INDICE_PERDIDAS_%': 'mean',\n",
    "    'ES_PRONOSTICO': 'sum'\n",
    "}).round(2)\n",
    "print(resumen_puntos)\n",
    "\n",
    "# Mostrar muestra\n",
    "print(\"\\nMuestra de la tabla (primeros 10 registros):\")\n",
    "print(tabla_balances.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENTREGABLE 1 COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTREGABLE 2: M√âTRICAS DE PERFORMANCE Y BENCHMARK\n",
      "================================================================================\n",
      "\n",
      "1. M√âTRICAS DEL MODELO (VALIDACI√ìN TEMPORAL)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "M√©tricas por modelo:\n",
      "                  MAE                               RMSE            MAPE  \\\n",
      "                 mean      std     min      max     mean      std   mean   \n",
      "MODELO                                                                     \n",
      "CatBoost      1567.08  1646.13   71.41  3602.33  1776.49  1954.20  14.18   \n",
      "LightGBM      2659.22  2873.93  106.21  5758.28  2767.18  3018.05  19.02   \n",
      "RandomForest  1597.86  2132.95  122.28  4739.57  1824.53  2520.32  17.45   \n",
      "\n",
      "                     MASE        \n",
      "                std  mean   std  \n",
      "MODELO                           \n",
      "CatBoost       6.27  1.94  1.40  \n",
      "LightGBM       3.43  3.07  3.18  \n",
      "RandomForest  10.35  1.74  0.50  \n",
      "\n",
      "M√©tricas por v√°lvula:\n",
      "               MAE              RMSE   MAPE  MASE\n",
      "              mean      min     mean   mean  mean\n",
      "VALVULA                                          \n",
      "VALVULA_1    99.97    71.41   120.13  21.85  1.37\n",
      "VALVULA_2   388.01   323.74   406.26  21.63  2.01\n",
      "VALVULA_3  2577.50  1090.91  2613.80   9.10  4.54\n",
      "VALVULA_4  4700.06  3602.33  5350.74  14.94  1.07\n",
      "\n",
      "Mejor modelo por v√°lvula:\n",
      "  VALVULA_1: CatBoost - MAE: 71.41, MAPE: 15.29%\n",
      "  VALVULA_2: LightGBM - MAE: 323.74, MAPE: 18.04%\n",
      "  VALVULA_3: RandomForest - MAE: 1090.91, MAPE: 3.87%\n",
      "  VALVULA_4: CatBoost - MAE: 3602.33, MAPE: 11.33%\n",
      "\n",
      "2. BENCHMARK: HIST√ìRICO vs PRON√ìSTICO\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Estad√≠sticas hist√≥ricas (con macromedidor):\n",
      "          VOLUMEN_ENTRADA_FINAL                               \\\n",
      "                           mean      std       min       max   \n",
      "VALVULA                                                        \n",
      "VALVULA_1                348.45   130.08     66.50    472.57   \n",
      "VALVULA_2               2070.59   448.81   1346.87   2784.44   \n",
      "VALVULA_3              24541.36  8415.53  10640.10  35938.86   \n",
      "VALVULA_4              26572.34  7040.41  12598.91  32602.03   \n",
      "VALVULA_5               3585.30  1844.18    831.40   4743.00   \n",
      "\n",
      "          VOLUMEN_SALIDA_FINAL          PERDIDAS_FINAL           \\\n",
      "                          mean      std           mean      std   \n",
      "VALVULA                                                           \n",
      "VALVULA_1               437.03    75.90         -16.78    13.64   \n",
      "VALVULA_2              2051.46   380.29         110.37   214.50   \n",
      "VALVULA_3             29373.20  4919.59       -1031.49  1340.44   \n",
      "VALVULA_4             31119.43  2790.64       -1682.92  2458.98   \n",
      "VALVULA_5              4684.56    25.21         -96.86   194.41   \n",
      "\n",
      "          INDICE_PERDIDAS_FINAL        \n",
      "                           mean   std  \n",
      "VALVULA                                \n",
      "VALVULA_1                 -0.05  0.04  \n",
      "VALVULA_2                  0.05  0.11  \n",
      "VALVULA_3                 -0.04  0.06  \n",
      "VALVULA_4                 -0.06  0.09  \n",
      "VALVULA_5                 -0.02  0.04  \n",
      "\n",
      "Estad√≠sticas de pron√≥stico:\n",
      "          VOLUMEN_ENTRADA_FINAL                               \\\n",
      "                           mean      std       min       max   \n",
      "VALVULA                                                        \n",
      "VALVULA_1                366.50     2.05    363.53    368.03   \n",
      "VALVULA_2               2088.54    89.80   1959.76   2187.16   \n",
      "VALVULA_3              27431.16   381.70  27077.81  27833.36   \n",
      "VALVULA_4              25376.59  1650.06  23549.88  27523.61   \n",
      "VALVULA_5               4503.27     0.00   4503.27   4503.27   \n",
      "\n",
      "          VOLUMEN_SALIDA_FINAL          PERDIDAS_FINAL           \\\n",
      "                          mean      std           mean      std   \n",
      "VALVULA                                                           \n",
      "VALVULA_1               542.66    44.94        -176.15    43.44   \n",
      "VALVULA_2              2559.47   770.91        -470.92   694.87   \n",
      "VALVULA_3             31477.30  1570.14       -4046.14  1205.58   \n",
      "VALVULA_4             32069.87  4265.75       -6693.28  3483.15   \n",
      "VALVULA_5              4940.96   238.25        -437.69   238.25   \n",
      "\n",
      "          INDICE_PERDIDAS_FINAL         \n",
      "                           mean    std  \n",
      "VALVULA                                 \n",
      "VALVULA_1                -48.03  11.65  \n",
      "VALVULA_2                -21.49  32.65  \n",
      "VALVULA_3                -14.71   4.19  \n",
      "VALVULA_4                -26.23  13.77  \n",
      "VALVULA_5                 -9.72   5.29  \n",
      "\n",
      "Comparaci√≥n de promedios (Pron√≥stico vs Hist√≥rico):\n",
      "           ENTRADA_HIST  ENTRADA_PRED  SALIDA_HIST  SALIDA_PRED  \\\n",
      "VALVULA                                                           \n",
      "VALVULA_1        348.45        366.50       437.03       542.66   \n",
      "VALVULA_2       2070.59       2088.54      2051.46      2559.47   \n",
      "VALVULA_3      24541.36      27431.16     29373.20     31477.30   \n",
      "VALVULA_4      26572.34      25376.59     31119.43     32069.87   \n",
      "VALVULA_5       3585.30       4503.27      4684.56      4940.96   \n",
      "\n",
      "           PERDIDAS_HIST  PERDIDAS_PRED  INDICE_HIST  INDICE_PRED  \\\n",
      "VALVULA                                                             \n",
      "VALVULA_1         -16.78        -176.15        -0.05       -48.03   \n",
      "VALVULA_2         110.37        -470.92         0.05       -21.49   \n",
      "VALVULA_3       -1031.49       -4046.14        -0.04       -14.71   \n",
      "VALVULA_4       -1682.92       -6693.28        -0.06       -26.23   \n",
      "VALVULA_5         -96.86        -437.69        -0.02        -9.72   \n",
      "\n",
      "           DIF_ENTRADA_%  DIF_SALIDA_%  DIF_INDICE_%  \n",
      "VALVULA                                               \n",
      "VALVULA_1           5.18         24.17        -47.98  \n",
      "VALVULA_2           0.87         24.76        -21.54  \n",
      "VALVULA_3          11.78          7.16        -14.67  \n",
      "VALVULA_4          -4.50          3.05        -26.17  \n",
      "VALVULA_5          25.60          5.47         -9.70  \n",
      "\n",
      "An√°lisis de consistencia:\n",
      "\n",
      "VALVULA_1:\n",
      "  Entrada: +5.18% vs hist√≥rico\n",
      "  √çndice p√©rdidas: -47.98 pp vs hist√≥rico\n",
      "  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\n",
      "\n",
      "VALVULA_2:\n",
      "  Entrada: +0.87% vs hist√≥rico\n",
      "  √çndice p√©rdidas: -21.54 pp vs hist√≥rico\n",
      "  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\n",
      "\n",
      "VALVULA_3:\n",
      "  Entrada: +11.78% vs hist√≥rico\n",
      "  √çndice p√©rdidas: -14.67 pp vs hist√≥rico\n",
      "  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\n",
      "\n",
      "VALVULA_4:\n",
      "  Entrada: -4.50% vs hist√≥rico\n",
      "  √çndice p√©rdidas: -26.17 pp vs hist√≥rico\n",
      "  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\n",
      "\n",
      "VALVULA_5:\n",
      "  Entrada: +25.60% vs hist√≥rico\n",
      "  √çndice p√©rdidas: -9.70 pp vs hist√≥rico\n",
      "  ‚ö† Variaci√≥n significativa en entrada (>20%)\n",
      "  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\n",
      "\n",
      "3. M√âTRICAS DE CALIDAD DEL PRON√ìSTICO\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Comparaci√≥n con tendencia hist√≥rica:\n",
      "     VALVULA  ENTRADA_PRED  ENTRADA_HIST  Z_SCORE  DENTRO_RANGO_2SIGMA\n",
      "0  VALVULA_1        366.50        428.94    -0.50                 True\n",
      "1  VALVULA_2       2088.54       1989.48     0.24                 True\n",
      "2  VALVULA_3      27431.16      30843.51    -0.47                 True\n",
      "3  VALVULA_4      25376.59      29718.62    -0.68                 True\n",
      "4  VALVULA_5       4503.27       4503.27    -0.00                 True\n",
      "\n",
      "Pron√≥sticos dentro de rango hist√≥rico (¬±2œÉ): 5/5 (100.0%)\n",
      "\n",
      "4. GUARDANDO REPORTE DE M√âTRICAS\n",
      "--------------------------------------------------------------------------------\n",
      "‚úì Reporte de m√©tricas guardado: Reporte_Metricas_Performance.csv ((63, 4))\n",
      "‚úì Benchmark hist√≥rico guardado: Benchmark_Historico_vs_Pronostico.csv\n",
      "\n",
      "================================================================================\n",
      "ENTREGABLE 2 COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENTREGABLE 2: M√âTRICAS DE PERFORMANCE DEL MODELO Y BENCHMARK FRENTE A HIST√ìRICO\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENTREGABLE 2: M√âTRICAS DE PERFORMANCE Y BENCHMARK\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verificar y cargar archivos (con manejo de errores)\n",
    "if not os.path.exists('Predicciones_Con_Balance.csv'):\n",
    "    print(\"‚ö† Predicciones_Con_Balance.csv no encontrado. Ejecuta primero la celda 17 o la celda que combina predicciones.\")\n",
    "    raise FileNotFoundError(\"Predicciones_Con_Balance.csv no encontrado\")\n",
    "\n",
    "df_balance = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "if not os.path.exists('Dataset_Train.csv'):\n",
    "    print(\"‚ö† Dataset_Train.csv no encontrado. Algunas comparaciones no estar√°n disponibles.\")\n",
    "    df_train = pd.DataFrame()\n",
    "else:\n",
    "    df_train = pd.read_csv('Dataset_Train.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "if not os.path.exists('Metrics.csv'):\n",
    "    print(\"‚ö† Metrics.csv no encontrado. Las m√©tricas de validaci√≥n no estar√°n disponibles.\")\n",
    "    df_metrics = pd.DataFrame()\n",
    "else:\n",
    "    df_metrics = pd.read_csv('Metrics.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "    if col in df_balance.columns:\n",
    "        df_balance[col] = pd.to_numeric(df_balance[col], errors='coerce')\n",
    "    if col in df_train.columns:\n",
    "        df_train[col] = pd.to_numeric(df_train[col], errors='coerce')\n",
    "\n",
    "# Separar hist√≥rico y pron√≥stico\n",
    "df_historico = df_balance[df_balance['PERIODO_A_PREDECIR'] == False].copy()\n",
    "df_pronostico = df_balance[df_balance['PERIODO_A_PREDECIR'] == True].copy()\n",
    "\n",
    "# ===== 1. M√âTRICAS DEL MODELO (VALIDACI√ìN) =====\n",
    "print(\"\\n1. M√âTRICAS DEL MODELO (VALIDACI√ìN TEMPORAL)\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(df_metrics) > 0:\n",
    "    # M√©tricas por modelo\n",
    "    metricas_modelo = df_metrics.groupby('MODELO').agg({\n",
    "        'MAE': ['mean', 'std', 'min', 'max'],\n",
    "        'RMSE': ['mean', 'std'],\n",
    "        'MAPE': ['mean', 'std'],\n",
    "        'MASE': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    print(\"\\nM√©tricas por modelo:\")\n",
    "    print(metricas_modelo)\n",
    "    \n",
    "    # M√©tricas por v√°lvula\n",
    "    print(\"\\nM√©tricas por v√°lvula:\")\n",
    "    metricas_valvula = df_metrics.groupby('VALVULA').agg({\n",
    "        'MAE': ['mean', 'min'],\n",
    "        'RMSE': 'mean',\n",
    "        'MAPE': 'mean',\n",
    "        'MASE': 'mean'\n",
    "    }).round(2)\n",
    "    print(metricas_valvula)\n",
    "    \n",
    "    # Mejor modelo por v√°lvula\n",
    "    print(\"\\nMejor modelo por v√°lvula:\")\n",
    "    for v in sorted(df_metrics['VALVULA'].unique()):\n",
    "        df_v = df_metrics[df_metrics['VALVULA'] == v]\n",
    "        mejor = df_v.loc[df_v['MAE'].idxmin()]\n",
    "        print(f\"  {v}: {mejor['MODELO']} - MAE: {mejor['MAE']:.2f}, MAPE: {mejor['MAPE']:.2f}%\")\n",
    "else:\n",
    "    print(\"‚ö† No hay m√©tricas de validaci√≥n disponibles\")\n",
    "\n",
    "# ===== 2. BENCHMARK: COMPARACI√ìN HIST√ìRICO vs PRON√ìSTICO =====\n",
    "print(\"\\n2. BENCHMARK: HIST√ìRICO vs PRON√ìSTICO\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(df_historico) > 0 and len(df_pronostico) > 0:\n",
    "    # Estad√≠sticas hist√≥ricas\n",
    "    stats_historico = df_historico.groupby('VALVULA').agg({\n",
    "        'VOLUMEN_ENTRADA_FINAL': ['mean', 'std', 'min', 'max'],\n",
    "        'VOLUMEN_SALIDA_FINAL': ['mean', 'std'],\n",
    "        'PERDIDAS_FINAL': ['mean', 'std'],\n",
    "        'INDICE_PERDIDAS_FINAL': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    # Estad√≠sticas de pron√≥stico\n",
    "    stats_pronostico = df_pronostico.groupby('VALVULA').agg({\n",
    "        'VOLUMEN_ENTRADA_FINAL': ['mean', 'std', 'min', 'max'],\n",
    "        'VOLUMEN_SALIDA_FINAL': ['mean', 'std'],\n",
    "        'PERDIDAS_FINAL': ['mean', 'std'],\n",
    "        'INDICE_PERDIDAS_FINAL': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    \n",
    "    print(\"\\nEstad√≠sticas hist√≥ricas (con macromedidor):\")\n",
    "    print(stats_historico)\n",
    "    \n",
    "    print(\"\\nEstad√≠sticas de pron√≥stico:\")\n",
    "    print(stats_pronostico)\n",
    "    \n",
    "    # Comparaci√≥n de promedios\n",
    "    print(\"\\nComparaci√≥n de promedios (Pron√≥stico vs Hist√≥rico):\")\n",
    "    comparacion = pd.DataFrame({\n",
    "        'ENTRADA_HIST': stats_historico[('VOLUMEN_ENTRADA_FINAL', 'mean')],\n",
    "        'ENTRADA_PRED': stats_pronostico[('VOLUMEN_ENTRADA_FINAL', 'mean')],\n",
    "        'SALIDA_HIST': stats_historico[('VOLUMEN_SALIDA_FINAL', 'mean')],\n",
    "        'SALIDA_PRED': stats_pronostico[('VOLUMEN_SALIDA_FINAL', 'mean')],\n",
    "        'PERDIDAS_HIST': stats_historico[('PERDIDAS_FINAL', 'mean')],\n",
    "        'PERDIDAS_PRED': stats_pronostico[('PERDIDAS_FINAL', 'mean')],\n",
    "        'INDICE_HIST': stats_historico[('INDICE_PERDIDAS_FINAL', 'mean')],\n",
    "        'INDICE_PRED': stats_pronostico[('INDICE_PERDIDAS_FINAL', 'mean')]\n",
    "    })\n",
    "    \n",
    "    # Calcular diferencias y ratios\n",
    "    comparacion['DIF_ENTRADA_%'] = ((comparacion['ENTRADA_PRED'] - comparacion['ENTRADA_HIST']) / comparacion['ENTRADA_HIST'] * 100).round(2)\n",
    "    comparacion['DIF_SALIDA_%'] = ((comparacion['SALIDA_PRED'] - comparacion['SALIDA_HIST']) / comparacion['SALIDA_HIST'] * 100).round(2)\n",
    "    comparacion['DIF_INDICE_%'] = (comparacion['INDICE_PRED'] - comparacion['INDICE_HIST']).round(2)\n",
    "    \n",
    "    print(comparacion)\n",
    "    \n",
    "    # An√°lisis de consistencia\n",
    "    print(\"\\nAn√°lisis de consistencia:\")\n",
    "    for v in comparacion.index:\n",
    "        dif_entrada = comparacion.loc[v, 'DIF_ENTRADA_%']\n",
    "        dif_indice = comparacion.loc[v, 'DIF_INDICE_%']\n",
    "        print(f\"\\n{v}:\")\n",
    "        print(f\"  Entrada: {dif_entrada:+.2f}% vs hist√≥rico\")\n",
    "        print(f\"  √çndice p√©rdidas: {dif_indice:+.2f} pp vs hist√≥rico\")\n",
    "        if abs(dif_entrada) > 20:\n",
    "            print(f\"  ‚ö† Variaci√≥n significativa en entrada (>20%)\")\n",
    "        if abs(dif_indice) > 5:\n",
    "            print(f\"  ‚ö† Variaci√≥n significativa en √≠ndice (>5pp)\")\n",
    "\n",
    "# ===== 3. M√âTRICAS DE CALIDAD DEL PRON√ìSTICO =====\n",
    "print(\"\\n3. M√âTRICAS DE CALIDAD DEL PRON√ìSTICO\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Si tenemos datos hist√≥ricos, podemos evaluar la calidad del pron√≥stico\n",
    "# comparando con tendencias hist√≥ricas\n",
    "if len(df_train) > 0:\n",
    "    # Calcular tendencia hist√≥rica por v√°lvula\n",
    "    tendencias = {}\n",
    "    for v in df_train['VALVULA'].unique():\n",
    "        df_v = df_train[df_train['VALVULA'] == v].sort_values('FECHA')\n",
    "        if len(df_v) >= 3:\n",
    "            # Tendencia lineal simple\n",
    "            valores = df_v['VOLUMEN_ENTRADA_FINAL'].dropna().values\n",
    "            if len(valores) >= 3:\n",
    "                # Media m√≥vil de √∫ltimos 3\n",
    "                tendencia = np.mean(valores[-3:])\n",
    "                # Desviaci√≥n est√°ndar\n",
    "                std = np.std(valores)\n",
    "                tendencias[v] = {'media': tendencia, 'std': std}\n",
    "    \n",
    "    # Comparar pron√≥sticos con tendencias\n",
    "    if len(tendencias) > 0:\n",
    "        print(\"\\nComparaci√≥n con tendencia hist√≥rica:\")\n",
    "        calidad_pronostico = []\n",
    "        for v in df_pronostico['VALVULA'].unique():\n",
    "            if v in tendencias:\n",
    "                pred_v = df_pronostico[df_pronostico['VALVULA'] == v]\n",
    "                entrada_pred = pred_v['VOLUMEN_ENTRADA_FINAL'].mean()\n",
    "                entrada_hist = tendencias[v]['media']\n",
    "                std_hist = tendencias[v]['std']\n",
    "                \n",
    "                # Z-score (cu√°ntas desviaciones est√°ndar est√° del hist√≥rico)\n",
    "                z_score = (entrada_pred - entrada_hist) / (std_hist + 1e-6)\n",
    "                \n",
    "                calidad_pronostico.append({\n",
    "                    'VALVULA': v,\n",
    "                    'ENTRADA_PRED': entrada_pred,\n",
    "                    'ENTRADA_HIST': entrada_hist,\n",
    "                    'Z_SCORE': z_score,\n",
    "                    'DENTRO_RANGO_2SIGMA': abs(z_score) <= 2\n",
    "                })\n",
    "        \n",
    "        if len(calidad_pronostico) > 0:\n",
    "            df_calidad = pd.DataFrame(calidad_pronostico)\n",
    "            print(df_calidad.round(2))\n",
    "            \n",
    "            # Resumen\n",
    "            dentro_rango = df_calidad['DENTRO_RANGO_2SIGMA'].sum()\n",
    "            print(f\"\\nPron√≥sticos dentro de rango hist√≥rico (¬±2œÉ): {dentro_rango}/{len(df_calidad)} ({100*dentro_rango/len(df_calidad):.1f}%)\")\n",
    "\n",
    "# ===== 4. GUARDAR REPORTE DE M√âTRICAS =====\n",
    "print(\"\\n4. GUARDANDO REPORTE DE M√âTRICAS\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "# Crear reporte consolidado\n",
    "reporte_metricas = {\n",
    "    'TIPO': [],\n",
    "    'VALVULA': [],\n",
    "    'METRICA': [],\n",
    "    'VALOR': []\n",
    "}\n",
    "\n",
    "# Agregar m√©tricas del modelo\n",
    "if len(df_metrics) > 0:\n",
    "    for _, row in df_metrics.iterrows():\n",
    "        for metrica in ['MAE', 'RMSE', 'MAPE', 'MASE']:\n",
    "            reporte_metricas['TIPO'].append('VALIDACION_MODELO')\n",
    "            reporte_metricas['VALVULA'].append(row['VALVULA'])\n",
    "            reporte_metricas['METRICA'].append(metrica)\n",
    "            reporte_metricas['VALOR'].append(row[metrica])\n",
    "\n",
    "# Agregar comparaciones hist√≥rico vs pron√≥stico\n",
    "if len(comparacion) > 0:\n",
    "    for v in comparacion.index:\n",
    "        for metrica in ['DIF_ENTRADA_%', 'DIF_SALIDA_%', 'DIF_INDICE_%']:\n",
    "            reporte_metricas['TIPO'].append('BENCHMARK_HISTORICO')\n",
    "            reporte_metricas['VALVULA'].append(v)\n",
    "            reporte_metricas['METRICA'].append(metrica)\n",
    "            reporte_metricas['VALOR'].append(comparacion.loc[v, metrica])\n",
    "\n",
    "df_reporte = pd.DataFrame(reporte_metricas)\n",
    "if len(df_reporte) > 0:\n",
    "    df_reporte.to_csv('Reporte_Metricas_Performance.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"‚úì Reporte de m√©tricas guardado: Reporte_Metricas_Performance.csv ({df_reporte.shape})\")\n",
    "\n",
    "# Guardar comparaci√≥n detallada\n",
    "if len(comparacion) > 0:\n",
    "    comparacion.to_csv('Benchmark_Historico_vs_Pronostico.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"‚úì Benchmark hist√≥rico guardado: Benchmark_Historico_vs_Pronostico.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENTREGABLE 2 COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENTREGABLE 4: DASHBOARD Y REPORTE\n",
      "================================================================================\n",
      "\n",
      "1. Generando gr√°ficos de series temporales...\n",
      "  ‚úì VALVULA_1\n",
      "  ‚úì VALVULA_2\n",
      "  ‚úì VALVULA_3\n",
      "  ‚úì VALVULA_4\n",
      "  ‚úì VALVULA_5\n",
      "\n",
      "2. Generando alertas por punto...\n",
      "  ‚úì 5 alertas generadas\n",
      "\n",
      "  Resumen de alertas:\n",
      "    CR√çTICAS: 0\n",
      "    ALTAS: 5\n",
      "    OK: 0\n",
      "\n",
      "3. Generando top desbalances...\n",
      "  ‚úì Top desbalances generado\n",
      "\n",
      "  Top 5 por p√©rdidas absolutas:\n",
      "    1. VALVULA_4: -6693.28 m¬≥ (-26.23%)\n",
      "    2. VALVULA_3: -4046.14 m¬≥ (-14.71%)\n",
      "    3. VALVULA_2: -470.92 m¬≥ (-21.49%)\n",
      "    4. VALVULA_5: -437.69 m¬≥ (-9.72%)\n",
      "    5. VALVULA_1: -176.15 m¬≥ (-48.03%)\n",
      "\n",
      "4. Generando dashboard HTML consolidado...\n",
      "  ‚úì Dashboard guardado: dashboard/Dashboard_Balances_Virtuales.html\n",
      "\n",
      "================================================================================\n",
      "ENTREGABLE 4 COMPLETADO\n",
      "================================================================================\n",
      "\n",
      "Archivos generados:\n",
      "  ‚Ä¢ dashboard/Dashboard_Balances_Virtuales.html - Dashboard principal\n",
      "  ‚Ä¢ dashboard/grafica_*.html - Gr√°ficos por v√°lvula\n",
      "  ‚Ä¢ dashboard/Alertas_Puntos.csv - Alertas generadas\n",
      "  ‚Ä¢ dashboard/Top_Desbalances.csv - An√°lisis de desbalances\n",
      "  ‚Ä¢ dashboard/Top10_Perdidas_Absolutas.csv - Top 10 p√©rdidas\n",
      "  ‚Ä¢ dashboard/Top10_Indice_Perdidas.csv - Top 10 √≠ndice\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# ENTREGABLE 4: DASHBOARD/REPORTE (GR√ÅFICOS, ALERTAS, TOP DESBALANCES)\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENTREGABLE 4: DASHBOARD Y REPORTE\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Verificar y cargar datos\n",
    "if not os.path.exists('Predicciones_Con_Balance.csv'):\n",
    "    print(\"‚ùå ERROR: Predicciones_Con_Balance.csv no encontrado.\")\n",
    "    print(\"   Por favor, ejecuta primero:\")\n",
    "    print(\"   1. Celda 15 (Entrenamiento y Pron√≥stico)\")\n",
    "    print(\"   2. Celda que combina predicciones con dataset maestro\")\n",
    "    print(\"   O ejecuta la Celda 17 que lo genera autom√°ticamente\")\n",
    "    raise FileNotFoundError(\"Predicciones_Con_Balance.csv no encontrado\")\n",
    "\n",
    "df_balance = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df_metrics = pd.read_csv('Metrics.csv', sep=';', decimal=',', encoding='latin-1') if os.path.exists('Metrics.csv') else pd.DataFrame()\n",
    "\n",
    "# Asegurar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "    if col in df_balance.columns:\n",
    "        df_balance[col] = pd.to_numeric(df_balance[col], errors='coerce')\n",
    "\n",
    "df_balance['FECHA'] = pd.to_datetime(df_balance['FECHA'], errors='coerce')\n",
    "\n",
    "# Crear directorio para gr√°ficos\n",
    "os.makedirs('dashboard', exist_ok=True)\n",
    "\n",
    "# ===== 1. GR√ÅFICOS DE SERIES TEMPORALES POR V√ÅLVULA =====\n",
    "print(\"\\n1. Generando gr√°ficos de series temporales...\")\n",
    "\n",
    "valvulas = sorted(df_balance['VALVULA'].dropna().unique())\n",
    "graficas_html = []\n",
    "\n",
    "for v in valvulas:\n",
    "    df_v = df_balance[df_balance['VALVULA'] == v].sort_values('FECHA')\n",
    "    \n",
    "    # Crear figura con subplots\n",
    "    fig = make_subplots(\n",
    "        rows=3, cols=1,\n",
    "        subplot_titles=(\n",
    "            f'{v} - Entrada vs Salida (m¬≥)',\n",
    "            f'{v} - P√©rdidas (m¬≥)',\n",
    "            f'{v} - √çndice de P√©rdidas (%)'\n",
    "        ),\n",
    "        vertical_spacing=0.1,\n",
    "        row_heights=[0.4, 0.3, 0.3]\n",
    "    )\n",
    "    \n",
    "    # Separar hist√≥rico y pron√≥stico\n",
    "    df_hist = df_v[df_v['PERIODO_A_PREDECIR'] == False]\n",
    "    df_pred = df_v[df_v['PERIODO_A_PREDECIR'] == True]\n",
    "    \n",
    "    # Gr√°fico 1: Entrada vs Salida\n",
    "    if len(df_hist) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_hist['FECHA'], y=df_hist['VOLUMEN_ENTRADA_FINAL'],\n",
    "            mode='lines+markers', name='Entrada (Hist√≥rico)',\n",
    "            line=dict(color='blue', width=2), marker=dict(size=6)\n",
    "        ), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_hist['FECHA'], y=df_hist['VOLUMEN_SALIDA_FINAL'],\n",
    "            mode='lines+markers', name='Salida (Hist√≥rico)',\n",
    "            line=dict(color='green', width=2), marker=dict(size=6)\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    if len(df_pred) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pred['FECHA'], y=df_pred['VOLUMEN_ENTRADA_FINAL'],\n",
    "            mode='lines+markers', name='Entrada (Pron√≥stico)',\n",
    "            line=dict(color='blue', width=2, dash='dash'), marker=dict(size=6)\n",
    "        ), row=1, col=1)\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pred['FECHA'], y=df_pred['VOLUMEN_SALIDA_FINAL'],\n",
    "            mode='lines+markers', name='Salida (Pron√≥stico)',\n",
    "            line=dict(color='green', width=2, dash='dash'), marker=dict(size=6)\n",
    "        ), row=1, col=1)\n",
    "    \n",
    "    # Gr√°fico 2: P√©rdidas\n",
    "    if len(df_hist) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_hist['FECHA'], y=df_hist['PERDIDAS_FINAL'],\n",
    "            mode='lines+markers', name='P√©rdidas (Hist√≥rico)',\n",
    "            line=dict(color='orange', width=2), marker=dict(size=6),\n",
    "            showlegend=False\n",
    "        ), row=2, col=1)\n",
    "    \n",
    "    if len(df_pred) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pred['FECHA'], y=df_pred['PERDIDAS_FINAL'],\n",
    "            mode='lines+markers', name='P√©rdidas (Pron√≥stico)',\n",
    "            line=dict(color='orange', width=2, dash='dash'), marker=dict(size=6),\n",
    "            showlegend=False\n",
    "        ), row=2, col=1)\n",
    "    \n",
    "    # L√≠nea de referencia en cero\n",
    "    fig.add_hline(y=0, line_dash=\"dot\", line_color=\"gray\", row=2, col=1)\n",
    "    \n",
    "    # Gr√°fico 3: √çndice de p√©rdidas\n",
    "    if len(df_hist) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_hist['FECHA'], y=df_hist['INDICE_PERDIDAS_FINAL'],\n",
    "            mode='lines+markers', name='√çndice (Hist√≥rico)',\n",
    "            line=dict(color='red', width=2), marker=dict(size=6),\n",
    "            showlegend=False\n",
    "        ), row=3, col=1)\n",
    "    \n",
    "    if len(df_pred) > 0:\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df_pred['FECHA'], y=df_pred['INDICE_PERDIDAS_FINAL'],\n",
    "            mode='lines+markers', name='√çndice (Pron√≥stico)',\n",
    "            line=dict(color='red', width=2, dash='dash'), marker=dict(size=6),\n",
    "            showlegend=False\n",
    "        ), row=3, col=1)\n",
    "    \n",
    "    # Actualizar ejes\n",
    "    fig.update_xaxes(title_text=\"Fecha\", row=3, col=1)\n",
    "    fig.update_yaxes(title_text=\"Volumen (m¬≥)\", row=1, col=1)\n",
    "    fig.update_yaxes(title_text=\"P√©rdidas (m¬≥)\", row=2, col=1)\n",
    "    fig.update_yaxes(title_text=\"√çndice (%)\", row=3, col=1)\n",
    "    \n",
    "    # Actualizar layout\n",
    "    fig.update_layout(\n",
    "        height=900,\n",
    "        title_text=f\"An√°lisis Completo - {v}\",\n",
    "        hovermode='x unified'\n",
    "    )\n",
    "    \n",
    "    # Guardar gr√°fico\n",
    "    filename = f\"dashboard/grafica_{v}.html\"\n",
    "    fig.write_html(filename)\n",
    "    graficas_html.append(f\"grafica_{v}.html\")\n",
    "    print(f\"  ‚úì {v}\")\n",
    "\n",
    "# ===== 2. ALERTAS POR PUNTO =====\n",
    "print(\"\\n2. Generando alertas por punto...\")\n",
    "\n",
    "alertas = []\n",
    "\n",
    "# Definir umbrales de alerta\n",
    "UMBRAL_INDICE_PERDIDAS_ALTO = 15  # %\n",
    "UMBRAL_INDICE_PERDIDAS_CRITICO = 25  # %\n",
    "UMBRAL_VARIACION_ENTRADA = 30  # %\n",
    "UMBRAL_PREDICCION_NEGATIVA = True\n",
    "\n",
    "for v in valvulas:\n",
    "    df_v = df_balance[df_balance['VALVULA'] == v].sort_values('FECHA')\n",
    "    df_pred = df_v[df_v['PERIODO_A_PREDECIR'] == True]\n",
    "    df_hist = df_v[df_v['PERIODO_A_PREDECIR'] == False]\n",
    "    \n",
    "    if len(df_pred) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Calcular promedios\n",
    "    indice_pred = df_pred['INDICE_PERDIDAS_FINAL'].mean()\n",
    "    entrada_pred = df_pred['VOLUMEN_ENTRADA_FINAL'].mean()\n",
    "    entrada_hist = df_hist['VOLUMEN_ENTRADA_FINAL'].mean() if len(df_hist) > 0 else None\n",
    "    \n",
    "    # Alertas\n",
    "    nivel_alerta = 'OK'\n",
    "    mensajes = []\n",
    "    \n",
    "    # Alerta 1: √çndice de p√©rdidas alto\n",
    "    if pd.notna(indice_pred):\n",
    "        if indice_pred >= UMBRAL_INDICE_PERDIDAS_CRITICO:\n",
    "            nivel_alerta = 'CRITICO'\n",
    "            mensajes.append(f\"√çndice de p√©rdidas cr√≠tico: {indice_pred:.2f}%\")\n",
    "        elif indice_pred >= UMBRAL_INDICE_PERDIDAS_ALTO:\n",
    "            nivel_alerta = 'ALTO' if nivel_alerta == 'OK' else nivel_alerta\n",
    "            mensajes.append(f\"√çndice de p√©rdidas alto: {indice_pred:.2f}%\")\n",
    "    \n",
    "    # Alerta 2: Variaci√≥n significativa en entrada\n",
    "    if entrada_hist is not None and pd.notna(entrada_pred) and pd.notna(entrada_hist):\n",
    "        variacion = abs((entrada_pred - entrada_hist) / entrada_hist * 100)\n",
    "        if variacion >= UMBRAL_VARIACION_ENTRADA:\n",
    "            nivel_alerta = 'ALTO' if nivel_alerta == 'OK' else nivel_alerta\n",
    "            mensajes.append(f\"Variaci√≥n significativa en entrada: {variacion:.1f}%\")\n",
    "    \n",
    "    # Alerta 3: P√©rdidas negativas (ganancias)\n",
    "    perdidas_negativas = (df_pred['PERDIDAS_FINAL'] < 0).sum()\n",
    "    if perdidas_negativas > 0:\n",
    "        nivel_alerta = 'ALTO' if nivel_alerta == 'OK' else nivel_alerta\n",
    "        mensajes.append(f\"P√©rdidas negativas en {perdidas_negativas} periodo(s)\")\n",
    "    \n",
    "    # Alerta 4: Valores faltantes\n",
    "    valores_faltantes = df_pred[['VOLUMEN_ENTRADA_FINAL', 'VOLUMEN_SALIDA_FINAL']].isna().sum().sum()\n",
    "    if valores_faltantes > 0:\n",
    "        nivel_alerta = 'ALTO' if nivel_alerta == 'OK' else nivel_alerta\n",
    "        mensajes.append(f\"Valores faltantes: {valores_faltantes}\")\n",
    "    \n",
    "    if nivel_alerta != 'OK' or len(mensajes) > 0:\n",
    "        alertas.append({\n",
    "            'VALVULA': v,\n",
    "            'NIVEL': nivel_alerta,\n",
    "            'MENSAJES': ' | '.join(mensajes) if mensajes else 'Sin alertas',\n",
    "            'INDICE_PERDIDAS_%': indice_pred,\n",
    "            'ENTRADA_PROMEDIO': entrada_pred\n",
    "        })\n",
    "\n",
    "df_alertas = pd.DataFrame(alertas)\n",
    "if len(df_alertas) > 0:\n",
    "    df_alertas.to_csv('dashboard/Alertas_Puntos.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"  ‚úì {len(df_alertas)} alertas generadas\")\n",
    "    \n",
    "    # Resumen de alertas\n",
    "    print(\"\\n  Resumen de alertas:\")\n",
    "    print(f\"    CR√çTICAS: {len(df_alertas[df_alertas['NIVEL'] == 'CRITICO'])}\")\n",
    "    print(f\"    ALTAS: {len(df_alertas[df_alertas['NIVEL'] == 'ALTO'])}\")\n",
    "    print(f\"    OK: {len(df_alertas[df_alertas['NIVEL'] == 'OK'])}\")\n",
    "else:\n",
    "    print(\"  ‚úì Sin alertas\")\n",
    "\n",
    "# ===== 3. TOP DESBALANCES =====\n",
    "print(\"\\n3. Generando top desbalances...\")\n",
    "\n",
    "# Calcular desbalances por v√°lvula (promedio del per√≠odo de pron√≥stico)\n",
    "desbalances = []\n",
    "for v in valvulas:\n",
    "    df_v = df_balance[df_balance['VALVULA'] == v]\n",
    "    df_pred = df_v[df_v['PERIODO_A_PREDECIR'] == True]\n",
    "    \n",
    "    if len(df_pred) > 0:\n",
    "        desbalances.append({\n",
    "            'VALVULA': v,\n",
    "            'PERDIDAS_PROMEDIO_m3': df_pred['PERDIDAS_FINAL'].mean(),\n",
    "            'INDICE_PERDIDAS_%': df_pred['INDICE_PERDIDAS_FINAL'].mean(),\n",
    "            'ENTRADA_PROMEDIO_m3': df_pred['VOLUMEN_ENTRADA_FINAL'].mean(),\n",
    "            'SALIDA_PROMEDIO_m3': df_pred['VOLUMEN_SALIDA_FINAL'].mean(),\n",
    "            'NUM_PERIODOS': len(df_pred)\n",
    "        })\n",
    "\n",
    "df_desbalances = pd.DataFrame(desbalances)\n",
    "if len(df_desbalances) > 0:\n",
    "    # Top por p√©rdidas absolutas\n",
    "    df_desbalances['PERDIDAS_ABS'] = df_desbalances['PERDIDAS_PROMEDIO_m3'].abs()\n",
    "    top_perdidas = df_desbalances.nlargest(10, 'PERDIDAS_ABS')\n",
    "    \n",
    "    # Top por √≠ndice de p√©rdidas\n",
    "    top_indice = df_desbalances.nlargest(10, 'INDICE_PERDIDAS_%')\n",
    "    \n",
    "    # Guardar\n",
    "    df_desbalances.to_csv('dashboard/Top_Desbalances.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    top_perdidas.to_csv('dashboard/Top10_Perdidas_Absolutas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    top_indice.to_csv('dashboard/Top10_Indice_Perdidas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    \n",
    "    print(f\"  ‚úì Top desbalances generado\")\n",
    "    print(\"\\n  Top 5 por p√©rdidas absolutas:\")\n",
    "    for i, (_, row) in enumerate(top_perdidas.head(5).iterrows(), 1):\n",
    "        print(f\"    {i}. {row['VALVULA']}: {row['PERDIDAS_PROMEDIO_m3']:.2f} m¬≥ ({row['INDICE_PERDIDAS_%']:.2f}%)\")\n",
    "\n",
    "# ===== 4. DASHBOARD HTML CONSOLIDADO =====\n",
    "print(\"\\n4. Generando dashboard HTML consolidado...\")\n",
    "\n",
    "html_content = f\"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html>\n",
    "<head>\n",
    "    <title>Dashboard - Balances Virtuales</title>\n",
    "    <meta charset=\"utf-8\">\n",
    "    <style>\n",
    "        body {{\n",
    "            font-family: Arial, sans-serif;\n",
    "            margin: 20px;\n",
    "            background-color: #f5f5f5;\n",
    "        }}\n",
    "        .header {{\n",
    "            background-color: #2c3e50;\n",
    "            color: white;\n",
    "            padding: 20px;\n",
    "            border-radius: 5px;\n",
    "            margin-bottom: 20px;\n",
    "        }}\n",
    "        .section {{\n",
    "            background-color: white;\n",
    "            padding: 20px;\n",
    "            margin: 20px 0;\n",
    "            border-radius: 5px;\n",
    "            box-shadow: 0 2px 4px rgba(0,0,0,0.1);\n",
    "        }}\n",
    "        .alert {{\n",
    "            padding: 10px;\n",
    "            margin: 10px 0;\n",
    "            border-radius: 5px;\n",
    "        }}\n",
    "        .alert-critico {{\n",
    "            background-color: #ffebee;\n",
    "            border-left: 4px solid #f44336;\n",
    "        }}\n",
    "        .alert-alto {{\n",
    "            background-color: #fff3e0;\n",
    "            border-left: 4px solid #ff9800;\n",
    "        }}\n",
    "        .alert-ok {{\n",
    "            background-color: #e8f5e9;\n",
    "            border-left: 4px solid #4caf50;\n",
    "        }}\n",
    "        table {{\n",
    "            width: 100%;\n",
    "            border-collapse: collapse;\n",
    "            margin: 10px 0;\n",
    "        }}\n",
    "        th, td {{\n",
    "            padding: 10px;\n",
    "            text-align: left;\n",
    "            border-bottom: 1px solid #ddd;\n",
    "        }}\n",
    "        th {{\n",
    "            background-color: #2c3e50;\n",
    "            color: white;\n",
    "        }}\n",
    "        iframe {{\n",
    "            width: 100%;\n",
    "            height: 900px;\n",
    "            border: none;\n",
    "            margin: 20px 0;\n",
    "        }}\n",
    "        .grafica-container {{\n",
    "            margin: 30px 0;\n",
    "        }}\n",
    "    </style>\n",
    "</head>\n",
    "<body>\n",
    "    <div class=\"header\">\n",
    "        <h1>üìä Dashboard - Balances Virtuales</h1>\n",
    "        <p>Generado el: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}</p>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2>üö® Alertas por Punto</h2>\n",
    "\"\"\"\n",
    "\n",
    "# Agregar alertas al HTML\n",
    "if len(df_alertas) > 0:\n",
    "    for _, alerta in df_alertas.iterrows():\n",
    "        nivel_class = alerta['NIVEL'].lower()\n",
    "        html_content += f\"\"\"\n",
    "        <div class=\"alert alert-{nivel_class}\">\n",
    "            <strong>{alerta['VALVULA']}</strong> - {alerta['NIVEL']}<br>\n",
    "            {alerta['MENSAJES']}\n",
    "        </div>\n",
    "        \"\"\"\n",
    "else:\n",
    "    html_content += \"<p>‚úÖ No hay alertas activas</p>\"\n",
    "\n",
    "html_content += \"\"\"\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2>üìà Top 10 Desbalances (P√©rdidas Absolutas)</h2>\n",
    "        <table>\n",
    "            <tr>\n",
    "                <th>V√°lvula</th>\n",
    "                <th>P√©rdidas Promedio (m¬≥)</th>\n",
    "                <th>√çndice de P√©rdidas (%)</th>\n",
    "                <th>Entrada Promedio (m¬≥)</th>\n",
    "                <th>N√∫mero de Per√≠odos</th>\n",
    "            </tr>\n",
    "\"\"\"\n",
    "\n",
    "# Agregar top desbalances\n",
    "if len(df_desbalances) > 0:\n",
    "    for _, row in top_perdidas.head(10).iterrows():\n",
    "        html_content += f\"\"\"\n",
    "            <tr>\n",
    "                <td>{row['VALVULA']}</td>\n",
    "                <td>{row['PERDIDAS_PROMEDIO_m3']:.2f}</td>\n",
    "                <td>{row['INDICE_PERDIDAS_%']:.2f}</td>\n",
    "                <td>{row['ENTRADA_PROMEDIO_m3']:.2f}</td>\n",
    "                <td>{row['NUM_PERIODOS']}</td>\n",
    "            </tr>\n",
    "        \"\"\"\n",
    "\n",
    "html_content += \"\"\"\n",
    "        </table>\n",
    "    </div>\n",
    "    \n",
    "    <div class=\"section\">\n",
    "        <h2>üìä Gr√°ficos de Series Temporales</h2>\n",
    "\"\"\"\n",
    "\n",
    "# Agregar gr√°ficos\n",
    "for grafica in graficas_html:\n",
    "    html_content += f\"\"\"\n",
    "        <div class=\"grafica-container\">\n",
    "            <h3>{grafica.replace('grafica_', '').replace('.html', '')}</h3>\n",
    "            <iframe src=\"{grafica}\"></iframe>\n",
    "        </div>\n",
    "    \"\"\"\n",
    "\n",
    "html_content += \"\"\"\n",
    "    </div>\n",
    "</body>\n",
    "</html>\n",
    "\"\"\"\n",
    "\n",
    "# Guardar dashboard\n",
    "with open('dashboard/Dashboard_Balances_Virtuales.html', 'w', encoding='utf-8') as f:\n",
    "    f.write(html_content)\n",
    "\n",
    "print(f\"  ‚úì Dashboard guardado: dashboard/Dashboard_Balances_Virtuales.html\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENTREGABLE 4 COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nArchivos generados:\")\n",
    "print(\"  ‚Ä¢ dashboard/Dashboard_Balances_Virtuales.html - Dashboard principal\")\n",
    "print(\"  ‚Ä¢ dashboard/grafica_*.html - Gr√°ficos por v√°lvula\")\n",
    "print(\"  ‚Ä¢ dashboard/Alertas_Puntos.csv - Alertas generadas\")\n",
    "print(\"  ‚Ä¢ dashboard/Top_Desbalances.csv - An√°lisis de desbalances\")\n",
    "print(\"  ‚Ä¢ dashboard/Top10_Perdidas_Absolutas.csv - Top 10 p√©rdidas\")\n",
    "print(\"  ‚Ä¢ dashboard/Top10_Indice_Perdidas.csv - Top 10 √≠ndice\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "AN√ÅLISIS DE CONFIABILIDAD DEL MODELO\n",
      "================================================================================\n",
      "\n",
      "1. AN√ÅLISIS DE M√âTRICAS DE VALIDACI√ìN\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "M√©tricas promedio por modelo:\n",
      "                  MAE                             MAPE            RMSE  \\\n",
      "                 mean      std     min      max   mean    std     mean   \n",
      "MODELO                                                                   \n",
      "CatBoost      1567.08  1646.13   71.41  3602.33  14.18   6.27  1776.49   \n",
      "LightGBM      2659.22  2873.93  106.21  5758.28  19.02   3.43  2767.18   \n",
      "RandomForest  1597.86  2132.95  122.28  4739.57  17.45  10.35  1824.53   \n",
      "\n",
      "                       \n",
      "                  std  \n",
      "MODELO                 \n",
      "CatBoost      1954.20  \n",
      "LightGBM      3018.05  \n",
      "RandomForest  2520.32  \n",
      "\n",
      "üìä Evaluaci√≥n de Confiabilidad por M√©trica:\n",
      "\n",
      "  MAE:\n",
      "    Promedio: 1941.39\n",
      "    Desviaci√≥n est√°ndar: 2124.53\n",
      "    Coeficiente de variaci√≥n: 109.43%\n",
      "    ‚ö† ALTA VARIABILIDAD: Los errores var√≠an mucho entre v√°lvulas\n",
      "\n",
      "  MAPE (Error porcentual promedio):\n",
      "    Promedio: 16.88%\n",
      "    Desviaci√≥n est√°ndar: 6.90%\n",
      "    ‚úÖ BUENO: Error < 20%\n",
      "\n",
      "üìã Confiabilidad por V√°lvula:\n",
      "\n",
      "  VALVULA_1:\n",
      "    Mejor modelo: CatBoost (MAE: 71.41, MAPE: 15.29%)\n",
      "    Peor modelo: RandomForest (MAE: 122.28, MAPE: 26.45%)\n",
      "    Ratio mejor/peor: 1.71x\n",
      "    ‚úì Consenso entre modelos\n",
      "    ‚ö† Confiabilidad MEDIA (MAPE 15-25%)\n",
      "\n",
      "  VALVULA_2:\n",
      "    Mejor modelo: LightGBM (MAE: 323.74, MAPE: 18.04%)\n",
      "    Peor modelo: RandomForest (MAE: 438.66, MAPE: 24.50%)\n",
      "    Ratio mejor/peor: 1.35x\n",
      "    ‚úì Consenso entre modelos\n",
      "    ‚ö† Confiabilidad MEDIA (MAPE 15-25%)\n",
      "\n",
      "  VALVULA_3:\n",
      "    Mejor modelo: RandomForest (MAE: 1090.91, MAPE: 3.87%)\n",
      "    Peor modelo: LightGBM (MAE: 4448.63, MAPE: 15.71%)\n",
      "    Ratio mejor/peor: 4.08x\n",
      "    ‚ö† ALTA DISPERSI√ìN: Los modelos difieren mucho\n",
      "    ‚úÖ Confiabilidad ALTA (MAPE < 15%)\n",
      "\n",
      "  VALVULA_4:\n",
      "    Mejor modelo: CatBoost (MAE: 3602.33, MAPE: 11.33%)\n",
      "    Peor modelo: LightGBM (MAE: 5758.28, MAPE: 18.51%)\n",
      "    Ratio mejor/peor: 1.60x\n",
      "    ‚úì Consenso entre modelos\n",
      "    ‚úÖ Confiabilidad ALTA (MAPE < 15%)\n",
      "\n",
      "2. AN√ÅLISIS DE DATOS DE ENTRENAMIENTO\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Puntos hist√≥ricos por v√°lvula:\n",
      "  VALVULA_1: 7 puntos (2024-07-01 a 2025-01-01)\n",
      "    ‚ö† DATOS LIMITADOS: 6-11 puntos (aceptable pero limitado)\n",
      "  VALVULA_2: 8 puntos (2024-05-01 a 2024-12-01)\n",
      "    ‚ö† DATOS LIMITADOS: 6-11 puntos (aceptable pero limitado)\n",
      "  VALVULA_3: 7 puntos (2025-01-01 a 2025-07-01)\n",
      "    ‚ö† DATOS LIMITADOS: 6-11 puntos (aceptable pero limitado)\n",
      "  VALVULA_4: 6 puntos (2024-06-01 a 2024-11-01)\n",
      "    ‚ö† DATOS LIMITADOS: 6-11 puntos (aceptable pero limitado)\n",
      "  VALVULA_5: 4 puntos (2024-07-01 a 2024-10-01)\n",
      "    ‚ö† POCOS DATOS: < 6 puntos (m√≠nimo recomendado)\n",
      "\n",
      "Variabilidad en datos hist√≥ricos:\n",
      "  VALVULA_1: CV = 37.72%\n",
      "    ‚ö† VARIABILIDAD MODERADA\n",
      "  VALVULA_2: CV = 21.68%\n",
      "    ‚úì Variabilidad baja (datos estables)\n",
      "  VALVULA_3: CV = 31.18%\n",
      "    ‚ö† VARIABILIDAD MODERADA\n",
      "  VALVULA_4: CV = 26.50%\n",
      "    ‚úì Variabilidad baja (datos estables)\n",
      "  VALVULA_5: CV = 51.44%\n",
      "    ‚ö† ALTA VARIABILIDAD: Datos muy vol√°tiles\n",
      "\n",
      "3. AN√ÅLISIS DEL ENSEMBLE\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚ö† PROBLEMA DETECTADO: An√°lisis de pesos del ensemble\n",
      "   (Los pesos deber√≠an favorecer al modelo con mejor MAE)\n",
      "\n",
      "  VALVULA_1:\n",
      "    Mejor modelo (menor MAE): CatBoost (MAE: 71.41)\n",
      "\n",
      "  VALVULA_2:\n",
      "    Mejor modelo (menor MAE): LightGBM (MAE: 323.74)\n",
      "\n",
      "  VALVULA_3:\n",
      "    Mejor modelo (menor MAE): RandomForest (MAE: 1090.91)\n",
      "\n",
      "  VALVULA_4:\n",
      "    Mejor modelo (menor MAE): CatBoost (MAE: 3602.33)\n",
      "\n",
      "4. EVALUACI√ìN GENERAL DE CONFIABILIDAD\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "‚úÖ VALVULA_1:\n",
      "   Score de confiabilidad: 80/100 (ALTA)\n",
      "   Mejor modelo: CatBoost (MAE: 71.41, MAPE: 15.29%)\n",
      "\n",
      "‚úÖ VALVULA_2:\n",
      "   Score de confiabilidad: 80/100 (ALTA)\n",
      "   Mejor modelo: LightGBM (MAE: 323.74, MAPE: 18.04%)\n",
      "\n",
      "‚ö†Ô∏è VALVULA_3:\n",
      "   Score de confiabilidad: 70/100 (MEDIA-ALTA)\n",
      "   Mejor modelo: RandomForest (MAE: 1090.91, MAPE: 3.87%)\n",
      "\n",
      "‚úÖ VALVULA_4:\n",
      "   Score de confiabilidad: 90/100 (ALTA)\n",
      "   Mejor modelo: CatBoost (MAE: 3602.33, MAPE: 11.33%)\n",
      "\n",
      "5. RECOMENDACIONES\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "üìä Score promedio de confiabilidad: 80/100\n",
      "   ‚úÖ El modelo es GENERALMENTE CONFIABLE\n",
      "\n",
      "‚úì An√°lisis guardado en: Analisis_Confiabilidad.csv\n",
      "\n",
      "================================================================================\n",
      "AN√ÅLISIS DE CONFIABILIDAD COMPLETADO\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================================\n",
    "# AN√ÅLISIS DE CONFIABILIDAD DEL MODELO\n",
    "# ============================================================================\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE CONFIABILIDAD DEL MODELO\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Cargar m√©tricas y pron√≥sticos\n",
    "if os.path.exists('Metrics.csv'):\n",
    "    df_metrics = pd.read_csv('Metrics.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    for col in df_metrics.select_dtypes(include=['object']).columns:\n",
    "        if col not in ['VALVULA', 'MODELO']:\n",
    "            df_metrics[col] = pd.to_numeric(df_metrics[col], errors='coerce')\n",
    "else:\n",
    "    df_metrics = pd.DataFrame()\n",
    "    print(\"‚ö† Metrics.csv no encontrado\")\n",
    "\n",
    "if os.path.exists('Pronosticos.csv'):\n",
    "    df_pronos = pd.read_csv('Pronosticos.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "else:\n",
    "    df_pronos = pd.DataFrame()\n",
    "    print(\"‚ö† Pronosticos.csv no encontrado\")\n",
    "\n",
    "if os.path.exists('Dataset_Train.csv'):\n",
    "    df_train = pd.read_csv('Dataset_Train.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "else:\n",
    "    df_train = pd.DataFrame()\n",
    "\n",
    "# ===== 1. AN√ÅLISIS DE M√âTRICAS =====\n",
    "print(\"\\n1. AN√ÅLISIS DE M√âTRICAS DE VALIDACI√ìN\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(df_metrics) > 0:\n",
    "    # Resumen por modelo\n",
    "    print(\"\\nM√©tricas promedio por modelo:\")\n",
    "    resumen_modelos = df_metrics.groupby('MODELO').agg({\n",
    "        'MAE': ['mean', 'std', 'min', 'max'],\n",
    "        'MAPE': ['mean', 'std'],\n",
    "        'RMSE': ['mean', 'std']\n",
    "    }).round(2)\n",
    "    print(resumen_modelos)\n",
    "    \n",
    "    # An√°lisis de confiabilidad por m√©trica\n",
    "    print(\"\\nüìä Evaluaci√≥n de Confiabilidad por M√©trica:\")\n",
    "    \n",
    "    # MAE\n",
    "    mae_promedio = df_metrics['MAE'].mean()\n",
    "    mae_std = df_metrics['MAE'].std()\n",
    "    mae_cv = (mae_std / mae_promedio) * 100 if mae_promedio > 0 else np.nan\n",
    "    \n",
    "    print(f\"\\n  MAE:\")\n",
    "    print(f\"    Promedio: {mae_promedio:.2f}\")\n",
    "    print(f\"    Desviaci√≥n est√°ndar: {mae_std:.2f}\")\n",
    "    print(f\"    Coeficiente de variaci√≥n: {mae_cv:.2f}%\")\n",
    "    if mae_cv > 100:\n",
    "        print(f\"    ‚ö† ALTA VARIABILIDAD: Los errores var√≠an mucho entre v√°lvulas\")\n",
    "    elif mae_cv > 50:\n",
    "        print(f\"    ‚ö† VARIABILIDAD MODERADA\")\n",
    "    else:\n",
    "        print(f\"    ‚úì Variabilidad aceptable\")\n",
    "    \n",
    "    # MAPE\n",
    "    mape_promedio = df_metrics['MAPE'].mean()\n",
    "    mape_std = df_metrics['MAPE'].std()\n",
    "    \n",
    "    print(f\"\\n  MAPE (Error porcentual promedio):\")\n",
    "    print(f\"    Promedio: {mape_promedio:.2f}%\")\n",
    "    print(f\"    Desviaci√≥n est√°ndar: {mape_std:.2f}%\")\n",
    "    \n",
    "    # Evaluar MAPE\n",
    "    if mape_promedio < 10:\n",
    "        print(f\"    ‚úÖ EXCELENTE: Error < 10%\")\n",
    "        confiabilidad_mape = \"ALTA\"\n",
    "    elif mape_promedio < 20:\n",
    "        print(f\"    ‚úÖ BUENO: Error < 20%\")\n",
    "        confiabilidad_mape = \"MEDIA-ALTA\"\n",
    "    elif mape_promedio < 30:\n",
    "        print(f\"    ‚ö† ACEPTABLE: Error < 30%\")\n",
    "        confiabilidad_mape = \"MEDIA\"\n",
    "    else:\n",
    "        print(f\"    ‚ö† BAJO: Error > 30%\")\n",
    "        confiabilidad_mape = \"BAJA\"\n",
    "    \n",
    "    # An√°lisis por v√°lvula\n",
    "    print(\"\\nüìã Confiabilidad por V√°lvula:\")\n",
    "    for v in sorted(df_metrics['VALVULA'].unique()):\n",
    "        df_v = df_metrics[df_metrics['VALVULA'] == v]\n",
    "        mejor = df_v.loc[df_v['MAE'].idxmin()]\n",
    "        peor = df_v.loc[df_v['MAE'].idxmax()]\n",
    "        \n",
    "        ratio = peor['MAE'] / mejor['MAE'] if mejor['MAE'] > 0 else np.nan\n",
    "        \n",
    "        print(f\"\\n  {v}:\")\n",
    "        print(f\"    Mejor modelo: {mejor['MODELO']} (MAE: {mejor['MAE']:.2f}, MAPE: {mejor['MAPE']:.2f}%)\")\n",
    "        print(f\"    Peor modelo: {peor['MODELO']} (MAE: {peor['MAE']:.2f}, MAPE: {peor['MAPE']:.2f}%)\")\n",
    "        print(f\"    Ratio mejor/peor: {ratio:.2f}x\")\n",
    "        \n",
    "        if ratio > 3:\n",
    "            print(f\"    ‚ö† ALTA DISPERSI√ìN: Los modelos difieren mucho\")\n",
    "        elif ratio > 2:\n",
    "            print(f\"    ‚ö† DISPERSI√ìN MODERADA\")\n",
    "        else:\n",
    "            print(f\"    ‚úì Consenso entre modelos\")\n",
    "        \n",
    "        # Evaluar MAPE del mejor modelo\n",
    "        if mejor['MAPE'] < 15:\n",
    "            print(f\"    ‚úÖ Confiabilidad ALTA (MAPE < 15%)\")\n",
    "        elif mejor['MAPE'] < 25:\n",
    "            print(f\"    ‚ö† Confiabilidad MEDIA (MAPE 15-25%)\")\n",
    "        else:\n",
    "            print(f\"    ‚ö† Confiabilidad BAJA (MAPE > 25%)\")\n",
    "\n",
    "# ===== 2. AN√ÅLISIS DE DATOS DE ENTRENAMIENTO =====\n",
    "print(\"\\n2. AN√ÅLISIS DE DATOS DE ENTRENAMIENTO\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(df_train) > 0:\n",
    "    datos_por_valvula = df_train.groupby('VALVULA').agg({\n",
    "        'VOLUMEN_ENTRADA_FINAL': 'count',\n",
    "        'FECHA': ['min', 'max']\n",
    "    })\n",
    "    datos_por_valvula.columns = ['NUM_PUNTOS', 'FECHA_MIN', 'FECHA_MAX']\n",
    "    \n",
    "    print(\"\\nPuntos hist√≥ricos por v√°lvula:\")\n",
    "    for v in datos_por_valvula.index:\n",
    "        n_puntos = datos_por_valvula.loc[v, 'NUM_PUNTOS']\n",
    "        fecha_min = datos_por_valvula.loc[v, 'FECHA_MIN']\n",
    "        fecha_max = datos_por_valvula.loc[v, 'FECHA_MAX']\n",
    "        \n",
    "        print(f\"  {v}: {n_puntos} puntos ({fecha_min} a {fecha_max})\")\n",
    "        \n",
    "        if n_puntos < 6:\n",
    "            print(f\"    ‚ö† POCOS DATOS: < 6 puntos (m√≠nimo recomendado)\")\n",
    "        elif n_puntos < 12:\n",
    "            print(f\"    ‚ö† DATOS LIMITADOS: 6-11 puntos (aceptable pero limitado)\")\n",
    "        else:\n",
    "            print(f\"    ‚úÖ DATOS SUFICIENTES: ‚â• 12 puntos\")\n",
    "    \n",
    "    # An√°lisis de variabilidad en datos hist√≥ricos\n",
    "    print(\"\\nVariabilidad en datos hist√≥ricos:\")\n",
    "    for v in df_train['VALVULA'].unique():\n",
    "        df_v = df_train[df_train['VALVULA'] == v].sort_values('FECHA')\n",
    "        valores = df_v['VOLUMEN_ENTRADA_FINAL'].dropna()\n",
    "        \n",
    "        if len(valores) > 1:\n",
    "            cv = (valores.std() / valores.mean()) * 100 if valores.mean() > 0 else np.nan\n",
    "            print(f\"  {v}: CV = {cv:.2f}%\")\n",
    "            \n",
    "            if cv > 50:\n",
    "                print(f\"    ‚ö† ALTA VARIABILIDAD: Datos muy vol√°tiles\")\n",
    "            elif cv > 30:\n",
    "                print(f\"    ‚ö† VARIABILIDAD MODERADA\")\n",
    "            else:\n",
    "                print(f\"    ‚úì Variabilidad baja (datos estables)\")\n",
    "\n",
    "# ===== 3. AN√ÅLISIS DEL ENSEMBLE =====\n",
    "print(\"\\n3. AN√ÅLISIS DEL ENSEMBLE\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(df_pronos) > 0:\n",
    "    # Verificar si hay problemas con los pesos del ensemble\n",
    "    print(\"\\n‚ö† PROBLEMA DETECTADO: An√°lisis de pesos del ensemble\")\n",
    "    print(\"   (Los pesos deber√≠an favorecer al modelo con mejor MAE)\")\n",
    "    \n",
    "    if len(df_metrics) > 0:\n",
    "        for v in sorted(df_metrics['VALVULA'].unique()):\n",
    "            df_v_metrics = df_metrics[df_metrics['VALVULA'] == v]\n",
    "            mejor_modelo = df_v_metrics.loc[df_v_metrics['MAE'].idxmin(), 'MODELO']\n",
    "            mejor_mae = df_v_metrics.loc[df_v_metrics['MAE'].idxmin(), 'MAE']\n",
    "            \n",
    "            print(f\"\\n  {v}:\")\n",
    "            print(f\"    Mejor modelo (menor MAE): {mejor_modelo} (MAE: {mejor_mae:.2f})\")\n",
    "            \n",
    "            # Verificar si Prophet est√° dominando sin ser el mejor\n",
    "            prophet_mae = df_v_metrics[df_v_metrics['MODELO'] == 'Prophet']['MAE'].values\n",
    "            if len(prophet_mae) > 0:\n",
    "                prophet_mae = prophet_mae[0]\n",
    "                if mejor_modelo != 'Prophet' and prophet_mae > mejor_mae * 1.1:\n",
    "                    print(f\"    ‚ö† PROBLEMA: Prophet tiene MAE {prophet_mae:.2f} pero no es el mejor\")\n",
    "                    print(f\"       El ensemble deber√≠a dar m√°s peso a {mejor_modelo}\")\n",
    "\n",
    "# ===== 4. EVALUACI√ìN GENERAL DE CONFIABILIDAD =====\n",
    "print(\"\\n4. EVALUACI√ìN GENERAL DE CONFIABILIDAD\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "confiabilidad_puntos = []\n",
    "\n",
    "if len(df_metrics) > 0:\n",
    "    for v in sorted(df_metrics['VALVULA'].unique()):\n",
    "        df_v = df_metrics[df_metrics['VALVULA'] == v]\n",
    "        mejor = df_v.loc[df_v['MAE'].idxmin()]\n",
    "        \n",
    "        # Calcular score de confiabilidad (0-100)\n",
    "        score = 100\n",
    "        \n",
    "        # Penalizar por MAPE alto\n",
    "        if mejor['MAPE'] > 30:\n",
    "            score -= 30\n",
    "        elif mejor['MAPE'] > 20:\n",
    "            score -= 20\n",
    "        elif mejor['MAPE'] > 15:\n",
    "            score -= 10\n",
    "        \n",
    "        # Penalizar por alta variabilidad entre modelos\n",
    "        ratio = df_v['MAE'].max() / df_v['MAE'].min()\n",
    "        if ratio > 3:\n",
    "            score -= 20\n",
    "        elif ratio > 2:\n",
    "            score -= 10\n",
    "        \n",
    "        # Penalizar por pocos datos\n",
    "        if len(df_train) > 0:\n",
    "            n_puntos = len(df_train[df_train['VALVULA'] == v])\n",
    "            if n_puntos < 6:\n",
    "                score -= 20\n",
    "            elif n_puntos < 12:\n",
    "                score -= 10\n",
    "        \n",
    "        score = max(0, score)\n",
    "        \n",
    "        # Clasificar\n",
    "        if score >= 80:\n",
    "            nivel = \"ALTA\"\n",
    "            emoji = \"‚úÖ\"\n",
    "        elif score >= 60:\n",
    "            nivel = \"MEDIA-ALTA\"\n",
    "            emoji = \"‚ö†Ô∏è\"\n",
    "        elif score >= 40:\n",
    "            nivel = \"MEDIA\"\n",
    "            emoji = \"‚ö†Ô∏è\"\n",
    "        else:\n",
    "            nivel = \"BAJA\"\n",
    "            emoji = \"‚ùå\"\n",
    "        \n",
    "        confiabilidad_puntos.append({\n",
    "            'VALVULA': v,\n",
    "            'SCORE': score,\n",
    "            'NIVEL': nivel,\n",
    "            'MEJOR_MODELO': mejor['MODELO'],\n",
    "            'MAE': mejor['MAE'],\n",
    "            'MAPE': mejor['MAPE']\n",
    "        })\n",
    "        \n",
    "        print(f\"\\n{emoji} {v}:\")\n",
    "        print(f\"   Score de confiabilidad: {score:.0f}/100 ({nivel})\")\n",
    "        print(f\"   Mejor modelo: {mejor['MODELO']} (MAE: {mejor['MAE']:.2f}, MAPE: {mejor['MAPE']:.2f}%)\")\n",
    "\n",
    "# ===== 5. RECOMENDACIONES =====\n",
    "print(\"\\n5. RECOMENDACIONES\")\n",
    "print(\"-\" * 80)\n",
    "\n",
    "if len(confiabilidad_puntos) > 0:\n",
    "    df_conf = pd.DataFrame(confiabilidad_puntos)\n",
    "    \n",
    "    # V√°lvulas con baja confiabilidad\n",
    "    bajas = df_conf[df_conf['SCORE'] < 60]\n",
    "    if len(bajas) > 0:\n",
    "        print(\"\\n‚ö† V√°lvulas con confiabilidad BAJA o MEDIA:\")\n",
    "        for _, row in bajas.iterrows():\n",
    "            print(f\"  ‚Ä¢ {row['VALVULA']}: Score {row['SCORE']:.0f}/100\")\n",
    "            print(f\"    - Revisar calidad de datos hist√≥ricos\")\n",
    "            print(f\"    - Considerar recopilar m√°s datos\")\n",
    "            print(f\"    - Validar manualmente las predicciones\")\n",
    "    \n",
    "    # Promedio general\n",
    "    score_promedio = df_conf['SCORE'].mean()\n",
    "    print(f\"\\nüìä Score promedio de confiabilidad: {score_promedio:.0f}/100\")\n",
    "    \n",
    "    if score_promedio >= 80:\n",
    "        print(\"   ‚úÖ El modelo es GENERALMENTE CONFIABLE\")\n",
    "    elif score_promedio >= 60:\n",
    "        print(\"   ‚ö†Ô∏è El modelo es MODERADAMENTE CONFIABLE\")\n",
    "        print(\"   - Usar con precauci√≥n\")\n",
    "        print(\"   - Validar resultados cr√≠ticos manualmente\")\n",
    "    else:\n",
    "        print(\"   ‚ùå El modelo tiene CONFIABILIDAD BAJA\")\n",
    "        print(\"   - NO RECOMENDADO para uso en producci√≥n sin mejoras\")\n",
    "        print(\"   - Revisar datos y modelo\")\n",
    "\n",
    "# Guardar an√°lisis\n",
    "if len(confiabilidad_puntos) > 0:\n",
    "    df_conf = pd.DataFrame(confiabilidad_puntos)\n",
    "    df_conf.to_csv('Analisis_Confiabilidad.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"\\n‚úì An√°lisis guardado en: Analisis_Confiabilidad.csv\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"AN√ÅLISIS DE CONFIABILIDAD COMPLETADO\")\n",
    "print(\"=\" * 80)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Balance virtual con predicciones: Predicciones_Con_Balance.csv ((82, 26))\n",
      "      VALVULA  PERIODO  VOLUMEN_ENTRADA_FINAL  VOLUMEN_SALIDA_FINAL  \\\n",
      "72  VALVULA_5   202502            4503.273333              4935.425   \n",
      "73  VALVULA_5   202503            4503.273333              4866.239   \n",
      "74  VALVULA_5   202504            4503.273333              4944.441   \n",
      "75  VALVULA_5   202505            4503.273333              4845.262   \n",
      "76  VALVULA_5   202506            4503.273333              5483.756   \n",
      "77  VALVULA_5   202507            4503.273333              4925.483   \n",
      "78  VALVULA_5   202508            4503.273333              5105.857   \n",
      "79  VALVULA_5   202509            4503.273333              4679.096   \n",
      "80  VALVULA_5   202510            4503.273333              4994.496   \n",
      "81  VALVULA_5   202511            4503.273333              5177.004   \n",
      "\n",
      "    PERDIDAS_FINAL  INDICE_PERDIDAS_FINAL  \n",
      "72     -432.151667              -9.596390  \n",
      "73     -362.965667              -8.060041  \n",
      "74     -441.167667              -9.796600  \n",
      "75     -341.988667              -7.594224  \n",
      "76     -980.482667             -21.772666  \n",
      "77     -422.209667              -9.375617  \n",
      "78     -602.583667             -13.381015  \n",
      "79     -175.822667              -3.904330  \n",
      "80     -491.222667             -10.908125  \n",
      "81     -673.730667             -14.960910  \n"
     ]
    }
   ],
   "source": [
    "# Combinar pron√≥sticos con dataset maestro para entregar balance virtual completo\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "try:\n",
    "    df_maestro = pd.read_csv('Dataset_Maestro_Balances.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    df_fc = pd.read_csv('Pronosticos.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "except Exception as e:\n",
    "    print(f\"Error cargando archivos: {e}\")\n",
    "    raise\n",
    "\n",
    "# Normalizar tipos\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL','PRED_ENTRADA','PRED_SALIDA','PRED_PERDIDAS','PRED_INDICE_PERDIDAS']:\n",
    "    if col in df_maestro.columns:\n",
    "        df_maestro[col] = pd.to_numeric(df_maestro[col], errors='coerce')\n",
    "    if col in df_fc.columns:\n",
    "        df_fc[col] = pd.to_numeric(df_fc[col], errors='coerce')\n",
    "\n",
    "df_maestro['FECHA'] = pd.to_datetime(df_maestro['FECHA'], errors='coerce')\n",
    "df_fc['FECHA'] = pd.to_datetime(df_fc['FECHA'], errors='coerce')\n",
    "\n",
    "# Unir por VALVULA + PERIODO\n",
    "df_out = df_maestro.merge(df_fc[['VALVULA','PERIODO','PRED_ENTRADA','PRED_SALIDA','PRED_PERDIDAS','PRED_INDICE_PERDIDAS']], on=['VALVULA','PERIODO'], how='left')\n",
    "\n",
    "# Reemplazar entrada/salida en periodos a predecir\n",
    "mask_pred = df_out['PERIODO_A_PREDECIR'] == True\n",
    "df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'] = df_out.loc[mask_pred, 'PRED_ENTRADA']\n",
    "df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL'] = df_out.loc[mask_pred, 'PRED_SALIDA'].fillna(df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL'])\n",
    "\n",
    "# Recalcular p√©rdidas e √≠ndice para periodos a predecir\n",
    "df_out.loc[mask_pred, 'PERDIDAS_FINAL'] = df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'] - df_out.loc[mask_pred, 'VOLUMEN_SALIDA_FINAL']\n",
    "df_out.loc[mask_pred, 'INDICE_PERDIDAS_FINAL'] = np.where(df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL']>0, (df_out.loc[mask_pred, 'PERDIDAS_FINAL']/df_out.loc[mask_pred, 'VOLUMEN_ENTRADA_FINAL'])*100, np.nan)\n",
    "\n",
    "# Guardar resultado\n",
    "df_out.to_csv('Predicciones_Con_Balance.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"‚úì Balance virtual con predicciones: Predicciones_Con_Balance.csv ({df_out.shape})\")\n",
    "print(df_out[['VALVULA','PERIODO','VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']].tail(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verificaci√≥n de Entrenamiento y Predicci√≥n\n",
    "\n",
    "Validar que existan periodos a predecir (`PERIODO_A_PREDECIR=True`) y suficiente historia por v√°lvula para entrenar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "VERIFICACI√ìN DE DATOS PARA ENTRENAMIENTO Y PRON√ìSTICO\n",
      "================================================================================\n",
      "\n",
      "1) Historia disponible por v√°lvula (con VOLUMEN_ENTRADA_FINAL):\n",
      "VALVULA\n",
      "VALVULA_2    8\n",
      "VALVULA_1    7\n",
      "VALVULA_3    7\n",
      "VALVULA_4    6\n",
      "VALVULA_5    4\n",
      "dtype: int64\n",
      "Total v√°lvulas con historia: 5\n",
      "\n",
      "2) Periodos a predecir por v√°lvula:\n",
      "VALVULA\n",
      "VALVULA_5    13\n",
      "VALVULA_4    12\n",
      "VALVULA_2    11\n",
      "VALVULA_3     5\n",
      "VALVULA_1     4\n",
      "dtype: int64\n",
      "Total v√°lvulas con periodos a predecir: 5\n",
      "\n",
      "3) Validaci√≥n retiro vs √∫ltimo periodo de usuarios (debe ser True para tener predicci√≥n):\n",
      "     VALVULA PERIODO_RETIRO MAX_PERIODO_USUARIOS  TIENE_PRED\n",
      "0  VALVULA_1         202507               202511        True\n",
      "1  VALVULA_2         202412               202511        True\n",
      "2  VALVULA_3         202506               202511        True\n",
      "3  VALVULA_4         202411               202511        True\n",
      "4  VALVULA_5         202410               202511        True\n",
      "V√°lvulas con posible predicci√≥n: 5 / 5\n",
      "\n",
      "4) V√°lvulas SIN periodos a predecir:\n",
      "[]\n",
      "\n",
      "5) V√°lvulas con POCA historia (<6 puntos):\n",
      "['VALVULA_5']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"VERIFICACI√ìN DE DATOS PARA ENTRENAMIENTO Y PRON√ìSTICO\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "df_train = pd.read_csv('Dataset_Train.csv', sep=';', encoding='latin-1')\n",
    "df_pred = pd.read_csv('Dataset_Prediccion.csv', sep=';', encoding='latin-1')\n",
    "df_datos_entrada = pd.read_csv('Datos_Entrada.csv', sep=';', encoding='latin-1')\n",
    "\n",
    "# Conteo de historia por v√°lvula\n",
    "hist_counts = df_train[df_train['VOLUMEN_ENTRADA_FINAL'].notna()].groupby('VALVULA').size().sort_values(ascending=False)\n",
    "print(\"\\n1) Historia disponible por v√°lvula (con VOLUMEN_ENTRADA_FINAL):\")\n",
    "print(hist_counts.head(20))\n",
    "print(f\"Total v√°lvulas con historia: {hist_counts.shape[0]}\")\n",
    "\n",
    "# Periodos a predecir por v√°lvula\n",
    "pred_counts = df_pred.groupby('VALVULA').size().sort_values(ascending=False)\n",
    "print(\"\\n2) Periodos a predecir por v√°lvula:\")\n",
    "print(pred_counts.head(20))\n",
    "print(f\"Total v√°lvulas con periodos a predecir: {pred_counts.shape[0]}\")\n",
    "\n",
    "# Revisar PERIODO_RETIRO vs m√°ximos periodos\n",
    "df_datos_entrada['VALVULA'] = df_datos_entrada['CODIGO VALVULA REFERENCIA']\n",
    "df_datos_entrada['FECHA_RETIRO'] = pd.to_datetime(df_datos_entrada['FECHA RETIRO/TRASLADO'], errors='coerce')\n",
    "df_datos_entrada['PERIODO_RETIRO'] = df_datos_entrada['FECHA_RETIRO'].dt.to_period('M').astype(str).str.replace('-', '')\n",
    "\n",
    "# M√°ximo periodo por v√°lvula en usuarios\n",
    "df_usuarios = pd.read_csv('Usuarios_Por_Valvula_Simple.csv', sep=';', encoding='latin-1')\n",
    "df_usuarios['PERIODO'] = df_usuarios['PERIODO'].astype(str)\n",
    "max_periodos = df_usuarios.groupby('VALVULA')['PERIODO'].max().reset_index().rename(columns={'PERIODO':'MAX_PERIODO_USUARIOS'})\n",
    "\n",
    "check = df_datos_entrada[['VALVULA','PERIODO_RETIRO']].merge(max_periodos, on='VALVULA', how='left')\n",
    "check['TIENE_PRED'] = (check['MAX_PERIODO_USUARIOS'] > check['PERIODO_RETIRO'])\n",
    "print(\"\\n3) Validaci√≥n retiro vs √∫ltimo periodo de usuarios (debe ser True para tener predicci√≥n):\")\n",
    "print(check.head(20))\n",
    "print(f\"V√°lvulas con posible predicci√≥n: {check['TIENE_PRED'].sum()} / {len(check)}\")\n",
    "\n",
    "# Identificar v√°lvulas sin predicci√≥n y con poca historia\n",
    "sin_pred = check[check['TIENE_PRED'] == False]['VALVULA'].tolist()\n",
    "poca_hist = hist_counts[hist_counts < 6].index.tolist()\n",
    "print(\"\\n4) V√°lvulas SIN periodos a predecir:\")\n",
    "print(sin_pred[:20])\n",
    "print(\"\\n5) V√°lvulas con POCA historia (<6 puntos):\")\n",
    "print(poca_hist[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumen por V√°lvula y Gr√°ficas\n",
    "En esta secci√≥n se genera un resumen por v√°lvula del horizonte sin macromedici√≥n y se crean gr√°ficas de `VOLUMEN_ENTRADA_FINAL`, `VOLUMEN_SALIDA_FINAL` y `INDICE_PERDIDAS_FINAL` por periodo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Resumen por v√°lvula guardado: Resumen_Pronostico_Valvulas.csv ((5, 9))\n",
      "     VALVULA  NUM_PERIODOS  VOLUMEN_ENTRADA_FINAL_sum  \\\n",
      "0  VALVULA_1             4                1466.012352   \n",
      "1  VALVULA_2            11               22973.972525   \n",
      "2  VALVULA_3             5              137155.807632   \n",
      "3  VALVULA_4            12              304519.087600   \n",
      "4  VALVULA_5            13               58542.553333   \n",
      "\n",
      "   VOLUMEN_ENTRADA_FINAL_mean  VOLUMEN_SALIDA_FINAL_sum  \\\n",
      "0                  366.503088                 2170.6290   \n",
      "1                 2088.542957                28154.1200   \n",
      "2                27431.161526               157386.4889   \n",
      "3                25376.590633               384838.4250   \n",
      "4                 4503.273333                64232.5380   \n",
      "\n",
      "   VOLUMEN_SALIDA_FINAL_mean  PERDIDAS_FINAL_sum  PERDIDAS_FINAL_mean  \\\n",
      "0                 542.657250         -704.616648          -176.154162   \n",
      "1                2559.465455        -5180.147475          -470.922498   \n",
      "2               31477.297780       -20230.681268         -4046.136254   \n",
      "3               32069.868750       -80319.337400         -6693.278117   \n",
      "4                4940.964462        -5689.984667          -437.691128   \n",
      "\n",
      "   INDICE_PERDIDAS_FINAL_mean  \n",
      "0                  -48.028511  \n",
      "1                  -21.490073  \n",
      "2                  -14.706511  \n",
      "3                  -26.234245  \n",
      "4                   -9.719400  \n"
     ]
    }
   ],
   "source": [
    "# Resumen por v√°lvula del horizonte sin macromedici√≥n\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Cargar balance con predicciones\n",
    "df = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce')\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Filtrar solo periodos a predecir\n",
    "df_pred = df[df['PERIODO_A_PREDECIR'] == True].copy()\n",
    "\n",
    "if df_pred.empty:\n",
    "    print('‚ö† No hay periodos a predecir en Predicciones_Con_Balance.csv')\n",
    "else:\n",
    "    resumen = df_pred.groupby('VALVULA').agg({\n",
    "        'PERIODO': 'count',\n",
    "        'VOLUMEN_ENTRADA_FINAL': ['sum','mean'],\n",
    "        'VOLUMEN_SALIDA_FINAL': ['sum','mean'],\n",
    "        'PERDIDAS_FINAL': ['sum','mean'],\n",
    "        'INDICE_PERDIDAS_FINAL': 'mean'\n",
    "    }).reset_index()\n",
    "    resumen.columns = ['_'.join(col).strip('_') for col in resumen.columns.values]\n",
    "    resumen.rename(columns={'PERIODO_count':'NUM_PERIODOS'}, inplace=True)\n",
    "    resumen.to_csv('Resumen_Pronostico_Valvulas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "    print(f\"‚úì Resumen por v√°lvula guardado: Resumen_Pronostico_Valvulas.csv ({resumen.shape})\")\n",
    "    print(resumen.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando gr√°ficas para 5 v√°lvulas..."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úì Gr√°ficas guardadas en la carpeta graficas_valvulas/\n"
     ]
    }
   ],
   "source": [
    "# Gr√°ficas por v√°lvula del horizonte sin macromedici√≥n\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import os\n",
    "\n",
    "df = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df['FECHA'] = pd.to_datetime(df['FECHA'], errors='coerce')\n",
    "for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "    df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "\n",
    "# Filtrar solo periodos a predecir\n",
    "df_pred = df[df['PERIODO_A_PREDECIR'] == True].copy()\n",
    "if df_pred.empty:\n",
    "    print('‚ö† No hay periodos a predecir en Predicciones_Con_Balance.csv')\n",
    "else:\n",
    "    os.makedirs('graficas_valvulas', exist_ok=True)\n",
    "    valvulas = sorted(df_pred['VALVULA'].dropna().unique())\n",
    "    print(f\"Generando gr√°ficas para {len(valvulas)} v√°lvulas...\")\n",
    "    for v in valvulas:\n",
    "        dv = df_pred[df_pred['VALVULA']==v].sort_values('FECHA')\n",
    "        if dv.empty:\n",
    "            continue\n",
    "        fig1 = px.line(dv, x='FECHA', y=['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL'],\n",
    "                        title=f'Entrada vs Salida - {v}', labels={'value':'Volumen','variable':'Serie'})\n",
    "        fig1.write_html(os.path.join('graficas_valvulas', f'{v}_entrada_salida.html'))\n",
    "        fig1.write_image(os.path.join('graficas_valvulas', f'{v}_entrada_salida.png'))\n",
    "        fig2 = px.line(dv, x='FECHA', y='INDICE_PERDIDAS_FINAL', title=f'√çndice de P√©rdidas (%) - {v}', labels={'INDICE_PERDIDAS_FINAL':'% P√©rdidas'})\n",
    "        fig2.write_html(os.path.join('graficas_valvulas', f'{v}_indice_perdidas.html'))\n",
    "        fig2.write_image(os.path.join('graficas_valvulas', f'{v}_indice_perdidas.png'))\n",
    "    print(\"‚úì Gr√°ficas guardadas en la carpeta graficas_valvulas/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tabla Comparativa por V√°lvula\n",
    "Esta celda genera una tabla comparativa por v√°lvula con KPIs del horizonte sin macromedici√≥n y, si est√°n disponibles, m√©tricas de validaci√≥n de LightGBM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Tabla comparativa guardada: Comparativo_Valvulas.csv ((5, 18))\n",
      "     VALVULA  NUM_PERIODOS    ENTRADA_SUM  ENTRADA_MEAN   SALIDA_SUM  \\\n",
      "0  VALVULA_1             4    1466.012352    366.503088    2170.6290   \n",
      "1  VALVULA_4            12  304519.087600  25376.590633  384838.4250   \n",
      "2  VALVULA_2            11   22973.972525   2088.542957   28154.1200   \n",
      "3  VALVULA_3             5  137155.807632  27431.161526  157386.4889   \n",
      "4  VALVULA_5            13   58542.553333   4503.273333   64232.5380   \n",
      "\n",
      "    SALIDA_MEAN  PERDIDAS_SUM  PERDIDAS_MEAN  INDICE_PERDIDAS_MEAN  \\\n",
      "0    542.657250   -704.616648    -176.154162            -48.028511   \n",
      "1  32069.868750 -80319.337400   -6693.278117            -26.234245   \n",
      "2   2559.465455  -5180.147475    -470.922498            -21.490073   \n",
      "3  31477.297780 -20230.681268   -4046.136254            -14.706511   \n",
      "4   4940.964462  -5689.984667    -437.691128             -9.719400   \n",
      "\n",
      "   PERDIDAS_%_SOBRE_ENTRADA  RELACION_SALIDA_ENTRADA  RANK_PERDIDAS_%  \\\n",
      "0                -48.063486                 1.480635              1.0   \n",
      "1                -26.375797                 1.263758              2.0   \n",
      "2                -22.547896                 1.225479              3.0   \n",
      "3                -14.750146                 1.147501              4.0   \n",
      "4                 -9.719400                 1.097194              5.0   \n",
      "\n",
      "   RANK_INDICE_PERDIDAS_MEAN          MAE         RMSE       MAPE      MASE  \\\n",
      "0                        1.0   106.214005   112.320327  23.824132  1.453791   \n",
      "1                        2.0  5758.279953  6160.970777  18.511831  1.314173   \n",
      "2                        3.0   323.743334   337.764772  18.040121  1.680765   \n",
      "3                        4.0  4448.629141  4457.668312  15.713376  7.839408   \n",
      "4                        5.0          NaN          NaN        NaN       NaN   \n",
      "\n",
      "   N_TEST  \n",
      "0     2.0  \n",
      "1     2.0  \n",
      "2     2.0  \n",
      "3     2.0  \n",
      "4     NaN  \n"
     ]
    }
   ],
   "source": [
    "# Generar tabla comparativa por v√°lvula\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Si no existe Resumen_Pronostico_Valvulas.csv, intentar generarlo desde Predicciones_Con_Balance.csv\n",
    "if not os.path.exists('Resumen_Pronostico_Valvulas.csv'):\n",
    "    try:\n",
    "        df_bal = pd.read_csv('Predicciones_Con_Balance.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "        for col in ['VOLUMEN_ENTRADA_FINAL','VOLUMEN_SALIDA_FINAL','PERDIDAS_FINAL','INDICE_PERDIDAS_FINAL']:\n",
    "            if col in df_bal.columns:\n",
    "                df_bal[col] = pd.to_numeric(df_bal[col], errors='coerce')\n",
    "        df_pred = df_bal[df_bal.get('PERIODO_A_PREDECIR', False) == True].copy()\n",
    "        if not df_pred.empty:\n",
    "            resumen = df_pred.groupby('VALVULA').agg({\n",
    "                'PERIODO': 'count',\n",
    "                'VOLUMEN_ENTRADA_FINAL': ['sum','mean'],\n",
    "                'VOLUMEN_SALIDA_FINAL': ['sum','mean'],\n",
    "                'PERDIDAS_FINAL': ['sum','mean'],\n",
    "                'INDICE_PERDIDAS_FINAL': 'mean'\n",
    "            }).reset_index()\n",
    "            resumen.columns = ['_'.join(col).strip('_') for col in resumen.columns.values]\n",
    "            resumen.rename(columns={'PERIODO_count':'NUM_PERIODOS'}, inplace=True)\n",
    "            resumen.to_csv('Resumen_Pronostico_Valvulas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "            print(\"‚úì Resumen_Pronostico_Valvulas.csv generado desde Predicciones_Con_Balance.csv\")\n",
    "        else:\n",
    "            print(\"‚ö† No hay periodos a predecir para generar el resumen.\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö† No se pudo generar el resumen autom√°ticamente: {e}\")\n",
    "\n",
    "# Cargar resumen de pron√≥stico\n",
    "df_res = pd.read_csv('Resumen_Pronostico_Valvulas.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "df_res.rename(columns={\n",
    "    'VALVULA':'VALVULA',\n",
    "    'NUM_PERIODOS':'NUM_PERIODOS',\n",
    "    'VOLUMEN_ENTRADA_FINAL_sum':'ENTRADA_SUM',\n",
    "    'VOLUMEN_ENTRADA_FINAL_mean':'ENTRADA_MEAN',\n",
    "    'VOLUMEN_SALIDA_FINAL_sum':'SALIDA_SUM',\n",
    "    'VOLUMEN_SALIDA_FINAL_mean':'SALIDA_MEAN',\n",
    "    'PERDIDAS_FINAL_sum':'PERDIDAS_SUM',\n",
    "    'PERDIDAS_FINAL_mean':'PERDIDAS_MEAN',\n",
    "    'INDICE_PERDIDAS_FINAL_mean':'INDICE_PERDIDAS_MEAN'\n",
    "}, inplace=True)\n",
    "\n",
    "# Intentar cargar m√©tricas de LightGBM si existen\n",
    "try:\n",
    "    df_metrics = pd.read_csv('Metrics.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "    df_metrics = df_metrics[df_metrics['MODELO']=='LightGBM'].copy()\n",
    "    df_metrics = df_metrics.groupby('VALVULA').agg({'MAE':'mean','RMSE':'mean','MAPE':'mean','MASE':'mean','N_TEST':'sum'}).reset_index()\n",
    "except Exception:\n",
    "    df_metrics = None\n",
    "\n",
    "# Construir comparativo base\n",
    "cmp = df_res.copy()\n",
    "cmp['PERDIDAS_%_SOBRE_ENTRADA'] = np.where(cmp['ENTRADA_SUM']>0, (cmp['PERDIDAS_SUM']/cmp['ENTRADA_SUM'])*100, np.nan)\n",
    "cmp['RELACION_SALIDA_ENTRADA'] = np.where(cmp['ENTRADA_SUM']>0, cmp['SALIDA_SUM']/cmp['ENTRADA_SUM'], np.nan)\n",
    "\n",
    "# Rankings (mejor = menor p√©rdidas %)\n",
    "cmp['RANK_PERDIDAS_%'] = cmp['PERDIDAS_%_SOBRE_ENTRADA'].rank(method='min', ascending=True)\n",
    "cmp['RANK_INDICE_PERDIDAS_MEAN'] = cmp['INDICE_PERDIDAS_MEAN'].rank(method='min', ascending=True)\n",
    "\n",
    "# Unir m√©tricas si est√°n disponibles\n",
    "if df_metrics is not None and not df_metrics.empty:\n",
    "    cmp = cmp.merge(df_metrics, on='VALVULA', how='left')\n",
    "\n",
    "# Orden sugerido: por p√©rdidas % asc\n",
    "cmp = cmp.sort_values(['PERDIDAS_%_SOBRE_ENTRADA','INDICE_PERDIDAS_MEAN']).reset_index(drop=True)\n",
    "\n",
    "# Guardar y mostrar\n",
    "cmp.to_csv('Comparativo_Valvulas.csv', index=False, sep=';', decimal=',', encoding='latin-1')\n",
    "print(f\"‚úì Tabla comparativa guardada: Comparativo_Valvulas.csv ({cmp.shape})\")\n",
    "print(cmp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard Consolidado\n",
    "Genera un dashboard HTML con la tabla comparativa y las gr√°ficas por v√°lvula."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úì Dashboard generado: graficas_valvulas\\dashboard.html\n"
     ]
    }
   ],
   "source": [
    "# Generar dashboard HTML consolidado\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Cargar comparativo\n",
    "df_cmp = pd.read_csv('Comparativo_Valvulas.csv', sep=';', decimal=',', encoding='latin-1')\n",
    "os.makedirs('graficas_valvulas', exist_ok=True)\n",
    "dashboard_path = os.path.join('graficas_valvulas', 'dashboard.html')\n",
    "\n",
    "# Construir tabla HTML\n",
    "tabla_html = df_cmp.to_html(index=False, float_format=lambda x: f\"{x:,.3f}\")\n",
    "\n",
    "# Construir secciones de gr√°ficas\n",
    "grafs = []\n",
    "for v in df_cmp['VALVULA'].dropna().tolist():\n",
    "    graf1 = f\"<h3>{v} - Entrada vs Salida</h3><iframe src='{v}_entrada_salida.html' width='100%' height='400' frameborder='0'></iframe>\"\n",
    "    graf2 = f\"<h3>{v} - √çndice de P√©rdidas</h3><iframe src='{v}_indice_perdidas.html' width='100%' height='400' frameborder='0'></iframe>\"\n",
    "    grafs.append(graf1)\n",
    "    grafs.append(graf2)\n",
    "\n",
    "# HTML completo (evitar expresiones entre llaves con f-string)\n",
    "style_block = \"\"\"\n",
    "    body { font-family: Arial, sans-serif; margin: 20px; }\n",
    "    table { border-collapse: collapse; width: 100%; }\n",
    "    th, td { border: 1px solid #ddd; padding: 8px; }\n",
    "    th { background-color: #f2f2f2; }\n",
    "    h1, h2 { margin-top: 24px; }\n",
    "    h3 { margin-top: 18px; }\n",
    "\"\"\"\n",
    "\n",
    "html = \"\"\"\n",
    "<!DOCTYPE html>\n",
    "<html lang='es'>\n",
    "<head>\n",
    "  <meta charset='utf-8'/>\n",
    "  <title>Dashboard Balance Virtual</title>\n",
    "  <style>\n",
    "{style}\n",
    "  </style>\n",
    "</head>\n",
    "<body>\n",
    "  <h1>Dashboard Balance Virtual</h1>\n",
    "  <h2>Tabla Comparativa por V√°lvula</h2>\n",
    "  {tabla}\n",
    "  <h2>Gr√°ficas por V√°lvula</h2>\n",
    "  {graficas}\n",
    "</body>\n",
    "</html>\n",
    "\"\"\".format(style=style_block, tabla=tabla_html, graficas=''.join(grafs))\n",
    "\n",
    "with open(dashboard_path, 'w', encoding='utf-8') as f:\n",
    "    f.write(html)\n",
    "print(f\"‚úì Dashboard generado: {dashboard_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza opcional de derivados\n",
    "Activa `MODO_LIMPIEZA = True` para borrar archivos generados (pron√≥sticos, m√©tricas, datasets derivados y gr√°ficas), conservando solo los datasets iniciales."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
